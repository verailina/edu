{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная 3: Рекомендации и категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выполнила: Егорова Вера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных\n",
    "\n",
    "В этой лабораторной работе будет рассмотрена задача предсказания оценки, которую поставит пользователь фильму. Особенность этой задачи в том, что вам предстоит работать с объектами обучающей выборки, которые описаны категориальными признаками, принимающими большое число значений (пример: идентификатор пользователя, идентификатор фильма).\n",
    "\n",
    "![](http://i.imgur.com/vHUVoWw.png)\n",
    "\n",
    "Мы будем работать с датасетом [MovieLens + IMDb/Rotten Tomatoes](http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-2k-v2.zip) ([описание](http://files.grouplens.org/datasets/hetrec2011/hetrec2011-movielens-readme.txt)). Набор содержит данные о предпочтениях пользователей сервиса рекомендации кинофильмов [MovieLens](http://www.movielens.org/). Пользователь ставит рейтинг фильму в интервале от 1 до 5. Оценки записаны в файле *user_ratedmovies.dat*, остальные файлы содержат дополнительную информацию о фильмах, которую можно использовать как признаки. Заметьте: кроме оценок (и тегов), про пользователя ничего не известно.\n",
    "\n",
    "На основании этих данных необходимо построить модель, предсказывающую оценку пользователя фильму, который он еще не смотрел."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества\n",
    "\n",
    "Выберем некоторого пользователя $u$ и обозначим известные для него рейтинги за $R^u$. В качестве тестовых рейтингов этого пользователя $R^u_{test}$ рассмотрим три рейтинга, поставленные последними по времени. Остальные известные рейтинги будут составлять обучающую выборку $R^u_{train}$. Тогда все известные рейтинги можно представить как $R^u=R^u_{train}\\cup R^u_{test}$. Отсутствующие оценки обозначим за $R^u_{unknown}$. Объединив эти наборы для всех пользователей, получим наборы $R_{train}$, $R_{test}$ и $R_{unknown}$.\n",
    "\n",
    "Для измерения качества рекомендаций используйте две метрики, описанные ниже.\n",
    "\n",
    "#### RMSE\n",
    "\n",
    "Метрика [RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation) вычисляется следующим образом:\n",
    "$$ RMSE = \\sqrt{ \\frac{1}{\\left|R_{test}\\right|} \\sum_{(u,i) \\in R_{test}} (r_{ui} - \\hat{r}_{ui})^2 },$$\n",
    "где $r_{ui}$ — наблюдаемая (правильная) оценка, а $\\hat{r}_{ui}$ — оценка, предсказанная моделью.\n",
    "\n",
    "Метрика RMSE предназначена для оценки точности предсказания, ее удобно оптимизировать напрямую. Однако RMSE не совсем правильно использовать при оценке качества рекомендаций: RMSE одинаково штрафует точность предсказания оценок фильмам с большим значением предпочтения (которые попадут в блок рекомендаций) и фильмам с малым значением предпочтения (длинный хвост из нерелевантных фильмов).\n",
    "\n",
    "#### MAP\n",
    "\n",
    "Для оценки качества рекомендаций можно использовать метрику качества ранжирования. Для этого для каждого пользователя $u$ предскажем оценку для всех фильмов из $R^u_{test}$ и $R^u_{unknown}$ и отсортируем эти фильмы по убыванию предсказанного рейтинга. Ожидается, что хороший алгоритм должен выдать релевантные фильмы вверху списка. Обозначим позиции объектов в этом списке за $k^u_i$.\n",
    "\n",
    "Назовем релевантными те фильмы, которые входят в $R^u_{test}$ и имеют оценку $\\ge 3$. Обозначим их за $Rel^u$. Тогда можно считать следующую метрику качества рекомендаций для одного пользователя:\n",
    "\n",
    "$$AP^u=\\frac{1}{|Rel^u|} \\sum_{(u,i) \\in Rel^u} \\frac{1}{k^u_i}.$$\n",
    "\n",
    "Усреднив значение этой метрики по всем пользователями, мы получим окончательное значение метрики $MAP$. Пользователей без релевантных фильмов в тестовой выборке можно не учитывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Коллаборативная фильтрация (4 балла)\n",
    "\n",
    "Для построения рекомендаций будем использовать алгоритмы на основе матричных разложений, в том числе предоставляемые библиотекой [Graphlab Create](https://dato.com/products/create/). Для оценки качества используйте две метрики, описанные выше. Не забывайте делать аргументированные выводы на основании полученных результатов.\n",
    " 1. Постройте рекомендации с помощью PureSVD. Для этого создайте разреженную матрицу пользователи-фильмы, где в каждой ячейке стоит рейтинг, если он известен, или ноль, если неизвестен. Разложив эту матрицу с помощью разреженного SVD и восстановив ее, можно получить предсказания рейтингов для всех пар пользователь-объект. Оцените качество работы  алгоритма в зависимости от выбранного ранга разложения.\n",
    " 2. Далее будем рассматривать как работают рекомендации из библиотеки Graphlab Create:\n",
    "  - Проведите аналогичный эксперимент для [алгоритма рекомендаций из GraphLab Create](https://dato.com/products/create/docs/generated/graphlab.recommender.ranking_factorization_recommender.RankingFactorizationRecommender.html), сравните его с PureSVD.\n",
    "  - Попробуйте использовать этот метод не с квадратичными потерями, а логистическими, т.е. решая задачу бинарной классификации (отделение хороших фильмов от плохих). Для этого надо использовать параметр *binary_target*. Дало ли это прирост в качестве?\n",
    "  - Поэксперементируйте с другими параметрами алгоритма и сделайте выводы, как их изменение влияет на качество предсказания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим базу данных со всеми оценками фильмов, проставленными различными пользователями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import graphlab\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies db size: 10197\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>imdbID</th>\n",
       "      <th>spanishTitle</th>\n",
       "      <th>imdbPictureURL</th>\n",
       "      <th>year</th>\n",
       "      <th>rtID</th>\n",
       "      <th>rtAllCriticsRating</th>\n",
       "      <th>rtAllCriticsNumReviews</th>\n",
       "      <th>rtAllCriticsNumFresh</th>\n",
       "      <th>...</th>\n",
       "      <th>rtAllCriticsScore</th>\n",
       "      <th>rtTopCriticsRating</th>\n",
       "      <th>rtTopCriticsNumReviews</th>\n",
       "      <th>rtTopCriticsNumFresh</th>\n",
       "      <th>rtTopCriticsNumRotten</th>\n",
       "      <th>rtTopCriticsScore</th>\n",
       "      <th>rtAudienceRating</th>\n",
       "      <th>rtAudienceNumRatings</th>\n",
       "      <th>rtAudienceScore</th>\n",
       "      <th>rtPictureURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>114709</td>\n",
       "      <td>Toy story (juguetes)</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMTMwNDU0...</td>\n",
       "      <td>1995</td>\n",
       "      <td>toy_story</td>\n",
       "      <td>9</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>8.5</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.7</td>\n",
       "      <td>102338</td>\n",
       "      <td>81</td>\n",
       "      <td>http://content7.flixster.com/movie/10/93/63/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>113497</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMzM5NjE1...</td>\n",
       "      <td>1995</td>\n",
       "      <td>1068044-jumanji</td>\n",
       "      <td>5.6</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>3.2</td>\n",
       "      <td>44587</td>\n",
       "      <td>61</td>\n",
       "      <td>http://content8.flixster.com/movie/56/79/73/56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpy Old Men</td>\n",
       "      <td>107050</td>\n",
       "      <td>Dos viejos gru�ones</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMTI5MTgy...</td>\n",
       "      <td>1993</td>\n",
       "      <td>grumpy_old_men</td>\n",
       "      <td>5.9</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10489</td>\n",
       "      <td>66</td>\n",
       "      <td>http://content6.flixster.com/movie/25/60/25602...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>114885</td>\n",
       "      <td>Esperando un respiro</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMTczMTMy...</td>\n",
       "      <td>1995</td>\n",
       "      <td>waiting_to_exhale</td>\n",
       "      <td>5.6</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>5.5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5666</td>\n",
       "      <td>79</td>\n",
       "      <td>http://content9.flixster.com/movie/10/94/17/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>113041</td>\n",
       "      <td>Vuelve el padre de la novia (Ahora tambi�n abu...</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMTg1NDc2...</td>\n",
       "      <td>1995</td>\n",
       "      <td>father_of_the_bride_part_ii</td>\n",
       "      <td>5.3</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>13761</td>\n",
       "      <td>64</td>\n",
       "      <td>http://content8.flixster.com/movie/25/54/25542...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        title  imdbID  \\\n",
       "0   1                    Toy story  114709   \n",
       "1   2                      Jumanji  113497   \n",
       "2   3               Grumpy Old Men  107050   \n",
       "3   4            Waiting to Exhale  114885   \n",
       "4   5  Father of the Bride Part II  113041   \n",
       "\n",
       "                                        spanishTitle  \\\n",
       "0                               Toy story (juguetes)   \n",
       "1                                            Jumanji   \n",
       "2                                Dos viejos gru�ones   \n",
       "3                               Esperando un respiro   \n",
       "4  Vuelve el padre de la novia (Ahora tambi�n abu...   \n",
       "\n",
       "                                      imdbPictureURL  year  \\\n",
       "0  http://ia.media-imdb.com/images/M/MV5BMTMwNDU0...  1995   \n",
       "1  http://ia.media-imdb.com/images/M/MV5BMzM5NjE1...  1995   \n",
       "2  http://ia.media-imdb.com/images/M/MV5BMTI5MTgy...  1993   \n",
       "3  http://ia.media-imdb.com/images/M/MV5BMTczMTMy...  1995   \n",
       "4  http://ia.media-imdb.com/images/M/MV5BMTg1NDc2...  1995   \n",
       "\n",
       "                          rtID rtAllCriticsRating rtAllCriticsNumReviews  \\\n",
       "0                    toy_story                  9                     73   \n",
       "1              1068044-jumanji                5.6                     28   \n",
       "2               grumpy_old_men                5.9                     36   \n",
       "3            waiting_to_exhale                5.6                     25   \n",
       "4  father_of_the_bride_part_ii                5.3                     19   \n",
       "\n",
       "  rtAllCriticsNumFresh                        ...                          \\\n",
       "0                   73                        ...                           \n",
       "1                   13                        ...                           \n",
       "2                   24                        ...                           \n",
       "3                   14                        ...                           \n",
       "4                    9                        ...                           \n",
       "\n",
       "  rtAllCriticsScore rtTopCriticsRating rtTopCriticsNumReviews  \\\n",
       "0               100                8.5                     17   \n",
       "1                46                5.8                      5   \n",
       "2                66                  7                      6   \n",
       "3                56                5.5                     11   \n",
       "4                47                5.4                      5   \n",
       "\n",
       "  rtTopCriticsNumFresh rtTopCriticsNumRotten rtTopCriticsScore  \\\n",
       "0                   17                     0               100   \n",
       "1                    2                     3                40   \n",
       "2                    5                     1                83   \n",
       "3                    5                     6                45   \n",
       "4                    1                     4                20   \n",
       "\n",
       "  rtAudienceRating rtAudienceNumRatings rtAudienceScore  \\\n",
       "0              3.7               102338              81   \n",
       "1              3.2                44587              61   \n",
       "2              3.2                10489              66   \n",
       "3              3.3                 5666              79   \n",
       "4                3                13761              64   \n",
       "\n",
       "                                        rtPictureURL  \n",
       "0  http://content7.flixster.com/movie/10/93/63/10...  \n",
       "1  http://content8.flixster.com/movie/56/79/73/56...  \n",
       "2  http://content6.flixster.com/movie/25/60/25602...  \n",
       "3  http://content9.flixster.com/movie/10/94/17/10...  \n",
       "4  http://content8.flixster.com/movie/25/54/25542...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv(\"data/movies.dat\", sep = '\\t')\n",
    "print 'Movies db size: {}'.format(len(movies_df))\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rated movies db size: 855598\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_minute</th>\n",
       "      <th>date_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>4.5</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>163</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  date_day  date_month  date_year  date_hour  \\\n",
       "0      75        3     1.0        29          10       2006         23   \n",
       "1      75       32     4.5        29          10       2006         23   \n",
       "2      75      110     4.0        29          10       2006         23   \n",
       "3      75      160     2.0        29          10       2006         23   \n",
       "4      75      163     4.0        29          10       2006         23   \n",
       "\n",
       "   date_minute  date_second  \n",
       "0           17           16  \n",
       "1           23           44  \n",
       "2           30            8  \n",
       "3           16           52  \n",
       "4           29           30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv(\"data/movies.dat\", sep = '\\t')\n",
    "rated_movies = pd.read_csv(\"data/user_ratedmovies.dat\", sep = '\\t')\n",
    "\n",
    "print 'Rated movies db size: {}'.format(len(rated_movies))\n",
    "movies_df.fillna(0, inplace=True)\n",
    "rated_movies.fillna(0, inplace=True)\n",
    "rated_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждой оценки сформируем временную метку timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_day</th>\n",
       "      <th>date_month</th>\n",
       "      <th>date_year</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>date_minute</th>\n",
       "      <th>date_second</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>1162142236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>32</td>\n",
       "      <td>4.5</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>44</td>\n",
       "      <td>1162142624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>1162143008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>160</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "      <td>1162142212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>163</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>1162142970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating  date_day  date_month  date_year  date_hour  \\\n",
       "0      75        3     1.0        29          10       2006         23   \n",
       "1      75       32     4.5        29          10       2006         23   \n",
       "2      75      110     4.0        29          10       2006         23   \n",
       "3      75      160     2.0        29          10       2006         23   \n",
       "4      75      163     4.0        29          10       2006         23   \n",
       "\n",
       "   date_minute  date_second   timestamp  \n",
       "0           17           16  1162142236  \n",
       "1           23           44  1162142624  \n",
       "2           30            8  1162143008  \n",
       "3           16           52  1162142212  \n",
       "4           29           30  1162142970  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime, time\n",
    "def timestamp(x):\n",
    "    date = datetime.datetime(int(x['date_year']), int(x['date_month']), \n",
    "                 int(x['date_day']), int(x['date_hour']), \n",
    "                 int(x['date_minute']), int(x['date_second']))\n",
    "    stamp = time.mktime(date.timetuple())\n",
    "    return int(stamp)\n",
    "\n",
    "rated_movies['timestamp'] = rated_movies.apply(timestamp, axis=1)\n",
    "rated_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим множества $R_{train}$ и $R_{test}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    userID  movieID  rating  date_day  date_month  date_year  date_hour  \\\n",
      "39      75     4993     3.5        29          10       2006         23   \n",
      "34      75     2959     4.5        29          10       2006         23   \n",
      "2       75      110     4.0        29          10       2006         23   \n",
      "18      75     1233     4.0        29          10       2006         23   \n",
      "41      75     5833     2.5        29          10       2006         23   \n",
      "\n",
      "    date_minute  date_second   timestamp  \n",
      "39           30           34  1162143034  \n",
      "34           30           12  1162143012  \n",
      "2            30            8  1162143008  \n",
      "18           30            5  1162143005  \n",
      "41           29           51  1162142991  \n",
      "    userID  movieID  rating  date_day  date_month  date_year  date_hour  \\\n",
      "29      75     2571     4.5        29          10       2006         23   \n",
      "42      75     5952     3.5        29          10       2006         23   \n",
      "48      75     7153     3.5        29          10       2006         23   \n",
      "\n",
      "    date_minute  date_second   timestamp  \n",
      "29           30           50  1162143050  \n",
      "42           30           40  1162143040  \n",
      "48           30           36  1162143036  \n",
      "[2571, 5952, 7153, 4993, 2959, 110, 1233, 5833, 45722, 2490, 163, 2058, 3793, 1215, 1127, 33437, 39052, 589, 6333, 6213, 996, 5107, 3258, 1917, 45431, 3994, 32029, 165, 1370, 7000, 2762, 32587, 296, 1036, 7007, 1527, 32, 3889, 2688, 6225, 2640, 2700, 832, 1485, 173, 2054, 1374, 3, 920, 653, 353, 1304, 160, 420, 2011]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "test_df = {}\n",
    "train_df = {}\n",
    "ranked_df = defaultdict(list)\n",
    "users = rated_movies['userID'].unique()\n",
    "movies = movies_df['id']\n",
    "mean_user_rating = {}\n",
    "grouped_df = rated_movies.groupby('userID')\n",
    "for user_id in users:\n",
    "    group_df = grouped_df.get_group(user_id).sort('timestamp', ascending=False)\n",
    "    test_df[user_id] = group_df[:3]\n",
    "    train_df[user_id] = group_df[3:]\n",
    "    ranked_df[user_id] = list(group_df['movieID'])\n",
    "\n",
    "print train_df[75].head()\n",
    "print test_df[75]\n",
    "print ranked_df[75]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем средний рейтинг для каждого фильма и отцентрируем все рейтинги в множестве $R_{train}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PureSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем разреженную матрицу пользователи-фильмы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies number: 10197\n",
      "Users number: 2113\n"
     ]
    }
   ],
   "source": [
    "movies = {}\n",
    "inverse_movies = {}\n",
    "for movie in movies_df['id'].unique():\n",
    "    movies[movie] = len(movies)\n",
    "\n",
    "users = {}\n",
    "inverse_users = {}\n",
    "for user in rated_movies['userID'].unique():\n",
    "    users[user] = len(users)\n",
    "\n",
    "print 'Movies number: {}'.format(len(movies))\n",
    "print 'Users number: {}'.format(len(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "matrix = np.zeros((len(users), len(movies)))\n",
    "for user, data in train_df.items():\n",
    "    for row in data.iterrows():\n",
    "        userID = users[user]\n",
    "        movieID = movies[row[1].movieID]\n",
    "        matrix[userID][movieID] = row[1].rating\n",
    "sparse_matrix = scipy.sparse.dok_matrix(matrix)\n",
    "print sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разложим полученную матрицу с помощью SVD разложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2113L, 30L) (30L,) (30L, 10197L)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.sparse.linalg import svds\n",
    "U, s, V = svds(sparse_matrix, k=30)\n",
    "print U.shape, s.shape, V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.214\n",
      "Wall time: 52.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def train(marix, rank):\n",
    "    U, s, V = svds(sparse_matrix, rank)\n",
    "    return np.matrix(U) * np.diag(s) * np.matrix(V)\n",
    "\n",
    "def calculate_RMSE(test_df, result_mat):\n",
    "    RMSE = 0.0\n",
    "    total = 0\n",
    "    for user, data in test_df.items():\n",
    "        for row in data.iterrows():\n",
    "            userID = users[user]\n",
    "            movieID = movies[row[1].movieID]\n",
    "            real_rating = row[1].rating\n",
    "            predicted_rating = result_mat[userID, movieID]\n",
    "            RMSE += (real_rating - predicted_rating)**2\n",
    "            total += 2\n",
    "    return (RMSE / total)**(0.5)\n",
    "   \n",
    "res_mat = train(sparse_matrix, 15)\n",
    "print 'RMSE: {0:.3f}'.format(calculate_RMSE(test_df, res_mat))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.456\n"
     ]
    }
   ],
   "source": [
    "def calculate_MAP(train_df, test_df, result_mat, movies, users):\n",
    "    all_moives = set(movies_df['id'])\n",
    "    ap = []\n",
    "    total = 0\n",
    "    for user in rated_movies['userID'].unique():\n",
    "        userID = users[user]\n",
    "        predicted = []\n",
    "        for movie in all_moives-set(train_df[user]['movieID']):\n",
    "            movieID = movies[movie]\n",
    "            predicted.append((movie, result_mat[userID, movieID]))\n",
    "        position = {x[0]: k for k, x in enumerate(sorted(predicted, key=lambda x:x[1], reverse=True)) if x[1] >= 3.}\n",
    "        rel = [1./(position[x] + 1) for x in test_df[user]['movieID'] if x in position.keys()]\n",
    "        if len(rel) > 0:\n",
    "            ap.append(sum(rel)/len(rel))\n",
    "    return np.mean(ap)\n",
    "            \n",
    "    grouped_df = test_df.groupby('userID')\n",
    "\n",
    "print 'MAP: {0:.3f}'.format(calculate_MAP(train_df, test_df, res_mat,  movies, users))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по значениям метрик, это не самы лучший алгоритм. Меня долго смущала такая большая ошибка RMSE, я перепробовала разные алгоритмы для SVD разложения, делала различные преобразования с матрицей пользователей-фильмов (учитывала средние оценки пользователей и фильмов), но в итоге лучше результата для Pure SVD я не получила."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.226473</td>\n",
       "      <td>0.4563842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.214206</td>\n",
       "      <td>0.5094019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.202443</td>\n",
       "      <td>0.5138819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2.202367</td>\n",
       "      <td>0.5593529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2.228019</td>\n",
       "      <td>0.6127663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rmse        map\n",
       "10   2.226473  0.4563842\n",
       "15   2.214206  0.5094019\n",
       "25   2.202443  0.5138819\n",
       "50   2.202367  0.5593529\n",
       "100  2.228019  0.6127663"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = [10, 15, 25, 50, 100]\n",
    "df = pd.DataFrame(columns=['rmse', 'map'], index=ranks)\n",
    "for rank in ranks:\n",
    "    res_mat = train(sparse_matrix, rank)\n",
    "    rmse_score = calculate_RMSE(test_df, res_mat)\n",
    "    map_score = calculate_MAP(train_df, test_df, res_mat, movies, users)\n",
    "    df.loc[rank] = pd.Series({'rmse':rmse_score, 'map':map_score})\n",
    "df = pd.DataFrame.from_csv('pure_svd.res', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендации из библиотеки Graphlab Create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Далее будем рассматривать как работают рекомендации из библиотеки Graphlab Create:\n",
    "  - Проведите аналогичный эксперимент для [алгоритма рекомендаций из GraphLab Create](https://dato.com/products/create/docs/generated/graphlab.recommender.ranking_factorization_recommender.RankingFactorizationRecommender.html), сравните его с PureSVD.\n",
    "  - Попробуйте использовать этот метод не с квадратичными потерями, а логистическими, т.е. решая задачу бинарной классификации (отделение хороших фильмов от плохих). Для этого надо использовать параметр *binary_target*. Дало ли это прирост в качестве?\n",
    "  - Поэксперементируйте с другими параметрами алгоритма и сделайте выводы, как их изменение влияет на качество предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User id: [8194, 8194, 8194, 8194, 8194]\n",
      "Movie id: [3793, 49647, 49793, 48774, 224]\n",
      "Rating: [4.0, 4.0, 3.5, 4.0, 2.5]\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(data, with_rating=True, verbose=False, binary=False):\n",
    "    frame_data = defaultdict(list)\n",
    "    for user, data in data.items():\n",
    "        frame_data['item_id'] += list(data['movieID'])\n",
    "        if with_rating:\n",
    "            frame_data['rating'] += list(data['rating']) if not binary else ([1.] *len(data['movieID']))\n",
    "        frame_data['user_id'] += ([user] * len(data['movieID']))\n",
    "        \n",
    "    if verbose:\n",
    "        print 'User id:', frame_data['user_id'][:5]\n",
    "        print 'Movie id:', frame_data['item_id'][:5]\n",
    "        if with_rating:\n",
    "            print 'Rating:', frame_data['rating'][:5]\n",
    "    return graphlab.SFrame(frame_data)\n",
    "train_data = prepare_data(train_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Recsys training: model = ranking_factorization_recommender\n"
     ]
    }
   ],
   "source": [
    "def train_model(sf, rank):\n",
    "    model = graphlab.ranking_factorization_recommender.create(sf, target='rating',solver='sgd',\n",
    "                                                              num_factors=rank, max_iterations=100, verbose=False)\n",
    "    return model\n",
    "model=train_model(train_data, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В логе обучения видим, что на обучающей выборке метрика $RMSE=0.749001$. Посмотрим, как наша модель предсказывает неизвестные рейтинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User id: [8194, 8194, 8194, 16389, 16389]\n",
      "Movie id: [44191, 5349, 2640, 57223, 3702]\n",
      "Rating: [3.0, 4.0, 3.5, 3.5, 3.0]\n",
      "Predicted rating: [2.8196000247740742, 4.149938800885677, 3.8065895825171467, 1.6796073704504964, 2.8953903294646737]\n",
      "RMSE: 1.23401262484\n"
     ]
    }
   ],
   "source": [
    "test_data=prepare_data(test_df, verbose=True)\n",
    "result = model.predict(test_data)\n",
    "print 'Predicted rating:',result[:5]\n",
    "print 'RMSE:', model.evaluate_rmse(test_data, target='rating')['rmse_overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выобрки ошибка модели больше. Но она до сих пор работает значительно лучше предыдущего метода. Теперь посмотрим, что покажет метрика MAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP: 0.399657188642\n"
     ]
    }
   ],
   "source": [
    "def calculate_map(model, test_df, ranked_df, movies, users, verbose=False):\n",
    "    ap = []\n",
    "    for user in users:\n",
    "        test_movies = list(test_df[user]['movieID'])\n",
    "        movies = [movie for movie in movies if movie not in ranked_df[user]] + test_movies\n",
    "        test_data = prepare_data({user:{'movieID': movies}}, with_rating=False, verbose=verbose)\n",
    "        predicted = {movie: (i, rank) for i, (movie, rank) in enumerate\n",
    "                             (sorted(zip(movies, model.predict(test_data)), key=lambda x: x[1], reverse=True))}\n",
    "        rel = [1./(predicted[x][0]+1) for x in test_movies if predicted[x][1] >=3]\n",
    "        if verbose: print rel\n",
    "        ap_u = 0 if not rel else sum(rel)/len(rel)\n",
    "        if verbose: print ap_u\n",
    "        ap.append(ap_u)\n",
    "    return sum(ap) / len(ap)\n",
    "        \n",
    "\n",
    "users = rated_movies['userID'].unique()\n",
    "movies = movies_df['id']\n",
    "MAP = calculate_map(model, test_df, ranked_df, movies, users, verbose=False)\n",
    "print 'MAP:', MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика MAP подтверждает, что модель от graphlab работает лучше pure svd. Для чистой совести проведем еще один эксперимент (как и для pure svd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>map</th>\n",
       "      <th>g_rmse</th>\n",
       "      <th>g_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.226473</td>\n",
       "      <td>0.4563842</td>\n",
       "      <td>1.165691</td>\n",
       "      <td>0.3961264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.214206</td>\n",
       "      <td>0.5094019</td>\n",
       "      <td>1.227364</td>\n",
       "      <td>0.401565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.202443</td>\n",
       "      <td>0.5138819</td>\n",
       "      <td>1.240567</td>\n",
       "      <td>0.4113039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2.202367</td>\n",
       "      <td>0.5593529</td>\n",
       "      <td>1.408441</td>\n",
       "      <td>0.4087704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2.228019</td>\n",
       "      <td>0.6127663</td>\n",
       "      <td>1.658263</td>\n",
       "      <td>0.4106842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rmse        map    g_rmse      g_map\n",
       "10   2.226473  0.4563842  1.165691  0.3961264\n",
       "15   2.214206  0.5094019  1.227364   0.401565\n",
       "25   2.202443  0.5138819  1.240567  0.4113039\n",
       "50   2.202367  0.5593529  1.408441  0.4087704\n",
       "100  2.228019  0.6127663  1.658263  0.4106842"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = [10, 15, 25, 50, 100]\n",
    "df_1 = pd.DataFrame(columns=['g_rmse', 'g_map'], index=ranks)\n",
    "train_data = prepare_data(train_df)\n",
    "test_data = prepare_data(test_df)\n",
    "for rank in ranks:\n",
    "    print rank\n",
    "    model = train_model(train_data, rank)\n",
    "    rmse_score = model.evaluate_rmse(test_data, target='rating')['rmse_overall']\n",
    "    map_score = calculate_map(model, test_df, ranked_df, movies, users)\n",
    "    df_1.loc[rank] = pd.Series({'g_rmse':rmse_score, 'g_map':map_score})\n",
    "\n",
    "pd.concat([df, df_1], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице выше приведено сравнение алгоритмов Pure SVD и Graphlab Create. Наилучшие показатели метрик наблюдаются у второго алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как повлияет на качетсво использование тогоже метода но с логистическими потерями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Recsys training: model = ranking_factorization_recommender\n",
      "PROGRESS: Preparing data set.\n",
      "PROGRESS:     Data has 849259 observations with 2113 users and 10084 items.\n",
      "PROGRESS:     Data prepared in: 0.655065s\n",
      "PROGRESS: Training ranking_factorization_recommender for recommendations.\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | Parameter                      | Description                                      | Value    |\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | num_factors                    | Factor Dimension                                 | 15       |\n",
      "PROGRESS: | regularization                 | L2 Regularization on Factors                     | 1e-009   |\n",
      "PROGRESS: | solver                         | Solver used for training                         | sgd      |\n",
      "PROGRESS: | linear_regularization          | L2 Regularization on Linear Coefficients         | 1e-009   |\n",
      "PROGRESS: | ranking_regularization         | Rank-based Regularization Weight                 | 0.25     |\n",
      "PROGRESS: | binary_target                  | Assume Binary Targets                            | True     |\n",
      "PROGRESS: | max_iterations                 | Maximum Number of Iterations                     | 100      |\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS:   Optimizing model using SGD; tuning step size.\n",
      "PROGRESS:   Using 106157 / 849259 points for tuning the step size.\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | Attempt | Initial Step Size | Estimated Objective Value                |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | 0       | 25                | Not Viable                               |\n",
      "PROGRESS: | 1       | 6.25              | Not Viable                               |\n",
      "PROGRESS: | 2       | 1.5625            | No Decrease (11.3792 >= 1.62674)         |\n",
      "PROGRESS: | 3       | 0.390625          | 1.22284                                  |\n",
      "PROGRESS: | 4       | 0.195312          | 1.2813                                   |\n",
      "PROGRESS: | 5       | 0.0976562         | 1.27884                                  |\n",
      "PROGRESS: | 6       | 0.0488281         | 1.28209                                  |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | Final   | 0.390625          | 1.22284                                  |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: Starting Optimization.\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: | Iter.   | Elapsed Time | Approx. Objective | Approx. Training Predictive Error | Step Size   |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: | Initial | 0us          | 1.62674           | 0.313261                          |             |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: | 1       | 846.598ms    | 1.47051           | 0.739362                          | 0.390625    |\n",
      "PROGRESS: | 2       | 1.69s        | 1.16548           | 0.580644                          | 0.232267    |\n",
      "PROGRESS: | 3       | 2.55s        | 1.06335           | 0.53166                           | 0.171364    |\n",
      "PROGRESS: | 4       | 3.41s        | 1.02494           | 0.514609                          | 0.138107    |\n",
      "PROGRESS: | 5       | 4.25s        | 0.998162          | 0.502069                          | 0.116824    |\n",
      "PROGRESS: | 6       | 5.14s        | 0.978225          | 0.491987                          | 0.101894    |\n",
      "PROGRESS: | 10      | 8.65s        | 0.935802          | 0.46993                           | 0.069464    |\n",
      "PROGRESS: | 11      | 9.49s        | 0.930572          | 0.467243                          | 0.0646719   |\n",
      "PROGRESS: | 15      | 12.81s       | 0.914171          | 0.458248                          | 0.0512497   |\n",
      "PROGRESS: | 20      | 17.05s       | 0.900689          | 0.45124                           | 0.0413036   |\n",
      "PROGRESS: | 25      | 21.35s       | 0.891976          | 0.446183                          | 0.0349386   |\n",
      "PROGRESS: | 30      | 25.80s       | 0.887058          | 0.443757                          | 0.0304733   |\n",
      "PROGRESS: | 35      | 30.12s       | 0.867712          | 0.433349                          | 0.0161412   |\n",
      "PROGRESS: | 40      | 34.34s       | 0.858771          | 0.428787                          | 0.008683    |\n",
      "PROGRESS: | 45      | 38.59s       | 0.852185          | 0.425089                          | 0.00472643  |\n",
      "PROGRESS: | 50      | 42.76s       | 0.849041          | 0.42343                           | 0.00259682  |\n",
      "PROGRESS: | 51      | 43.59s       | 0.847051          | 0.422198                          | 0.00215147  |\n",
      "PROGRESS: | 55      | 46.97s       | 0.845686          | 0.421514                          | 0.00101651  |\n",
      "PROGRESS: | 60      | 51.18s       | 0.844516          | 0.421023                          | 0.000566235 |\n",
      "PROGRESS: | 65      | 55.46s       | 0.844774          | 0.421026                          | 0.000149932 |\n",
      "PROGRESS: | 70      | 59.70s       | 0.844946          | 0.421015                          |             |\n",
      "PROGRESS: | 75      | 1m 4s        | 0.84364           | 0.420513                          |             |\n",
      "PROGRESS: | 80      | 1m 8s        | 0.843863          | 0.420757                          |             |\n",
      "PROGRESS: | 85      | 1m 12s       | 0.84533           | 0.42077                           |             |\n",
      "PROGRESS: | 90      | 1m 16s       | 0.843711          | 0.420792                          |             |\n",
      "PROGRESS: | 95      | 1m 21s       | 0.845024          | 0.420793                          |             |\n",
      "PROGRESS: | 100     | 1m 25s       | 0.844297          | 0.420795                          |             |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: Optimization Complete: Maximum number of passes through the data reached.\n",
      "PROGRESS: Computing final objective value and training Predictive Error.\n",
      "PROGRESS:        Final objective value: 0.883783\n",
      "PROGRESS:        Final training Predictive Error: 0.420795\n"
     ]
    }
   ],
   "source": [
    "train_data = prepare_data(train_df, binary=True) \n",
    "model = graphlab.ranking_factorization_recommender.create(train_data, target='rating',solver='sgd',\n",
    "                                                           num_factors=15, max_iterations=100, \n",
    "                                                           verbose=True, binary_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что на тренировочных данных ошибка меньше чем во всех предыдущих экспериментах и состовляет $0.42$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.531227890484\n"
     ]
    }
   ],
   "source": [
    "test_data=prepare_data(test_df, verbose=False, binary=True)\n",
    "print 'RMSE:', model.evaluate_rmse(test_data, target='rating')['rmse_overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовых данных ошибка тоже мала. На данных момент это самая удачная модель из всех обученных. Теперь посмотрим, как влияют на качество предсказания другие параметры алгоримта. Сначала испробуем все возможные решатели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Recsys training: model = ranking_factorization_recommender\n",
      "PROGRESS: Preparing data set.\n",
      "PROGRESS:     Data has 849259 observations with 2113 users and 10084 items.\n",
      "PROGRESS:     Data prepared in: 0.738904s\n",
      "PROGRESS: Training ranking_factorization_recommender for recommendations.\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | Parameter                      | Description                                      | Value    |\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | num_factors                    | Factor Dimension                                 | 15       |\n",
      "PROGRESS: | regularization                 | L2 Regularization on Factors                     | 1e-009   |\n",
      "PROGRESS: | solver                         | Solver used for training                         | adagrad  |\n",
      "PROGRESS: | linear_regularization          | L2 Regularization on Linear Coefficients         | 1e-009   |\n",
      "PROGRESS: | ranking_regularization         | Rank-based Regularization Weight                 | 0.25     |\n",
      "PROGRESS: | max_iterations                 | Maximum Number of Iterations                     | 100      |\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS:   Optimizing model using SGD; tuning step size.\n",
      "PROGRESS:   Using 106157 / 849259 points for tuning the step size.\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | Attempt | Initial Step Size | Estimated Objective Value                |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | 0       | 25                | Not Viable                               |\n",
      "PROGRESS: | 1       | 6.25              | Not Viable                               |\n",
      "PROGRESS: | 2       | 1.5625            | 1.45472                                  |\n",
      "PROGRESS: | 3       | 0.78125           | 1.15821                                  |\n",
      "PROGRESS: | 4       | 0.390625          | 0.910245                                 |\n",
      "PROGRESS: | 5       | 0.195312          | 0.900933                                 |\n",
      "PROGRESS: | 6       | 0.0976562         | 0.991078                                 |\n",
      "PROGRESS: | 7       | 0.0488281         | 1.16504                                  |\n",
      "PROGRESS: | 8       | 0.0244141         | 1.36627                                  |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | Final   | 0.195312          | 0.900933                                 |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: Starting Optimization.\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------+-------------+\n",
      "PROGRESS: | Iter.   | Elapsed Time | Approx. Objective | Approx. Training RMSE | Step Size   |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------+-------------+\n",
      "PROGRESS: | Initial | 0us          | 1.97049           | 1.0025                |             |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------+-------------+\n",
      "PROGRESS: | 1       | 1.02s        | 1.23285           | 0.893577              | 0.195312    |\n",
      "PROGRESS: | 2       | 2.06s        | 1.09868           | 0.832542              | 0.195312    |\n",
      "PROGRESS: | 3       | 3.03s        | 1.04676           | 0.815838              | 0.195312    |\n",
      "PROGRESS: | 4       | 4.02s        | 1.01867           | 0.805845              | 0.195312    |\n",
      "PROGRESS: | 5       | 5.06s        | 1.00097           | 0.798979              | 0.195312    |\n",
      "PROGRESS: | 6       | 6.33s        | 0.988008          | 0.794085              | 0.195312    |\n",
      "PROGRESS: | 7       | 7.52s        | 0.979656          | 0.79079               | 0.195312    |\n",
      "PROGRESS: | 8       | 8.75s        | 0.972593          | 0.787609              | 0.195312    |\n",
      "PROGRESS: | 9       | 10.08s       | 0.965899          | 0.785317              | 0.195312    |\n",
      "PROGRESS: | 10      | 11.08s       | 0.961975          | 0.783381              | 0.195312    |\n",
      "PROGRESS: | 11      | 12.10s       | 0.957247          | 0.781407              | 0.195312    |\n",
      "PROGRESS: | 12      | 13.09s       | 0.953931          | 0.780316              | 0.195312    |\n",
      "PROGRESS: | 13      | 14.09s       | 0.950966          | 0.778835              | 0.195312    |\n",
      "PROGRESS: | 14      | 15.10s       | 0.948675          | 0.777868              | 0.195312    |\n",
      "PROGRESS: | 15      | 16.06s       | 0.946048          | 0.77692               | 0.195312    |\n",
      "PROGRESS: | 16      | 17.01s       | 0.943578          | 0.77598               | 0.195312    |\n",
      "PROGRESS: | 17      | 18.05s       | 0.941846          | 0.775144              | 0.195312    |\n",
      "PROGRESS: | 18      | 19.05s       | 0.940873          | 0.774539              | 0.195312    |\n",
      "PROGRESS: | 19      | 19.99s       | 0.938872          | 0.77385               | 0.195312    |\n",
      "PROGRESS: | 20      | 21.00s       | 0.93741           | 0.773571              | 0.195312    |\n",
      "PROGRESS: | 21      | 21.99s       | 0.936127          | 0.772489              | 0.195312    |\n",
      "PROGRESS: | 22      | 22.96s       | 0.935495          | 0.772437              | 0.195312    |\n",
      "PROGRESS: | 23      | 23.98s       | 0.933797          | 0.771582              | 0.195312    |\n",
      "PROGRESS: | 24      | 25.11s       | 0.932717          | 0.771313              | 0.195312    |\n",
      "PROGRESS: | 25      | 26.07s       | 0.931225          | 0.770813              | 0.195312    |\n",
      "PROGRESS: | 26      | 27.03s       | 0.930529          | 0.770459              | 0.195312    |\n",
      "PROGRESS: | 27      | 28.11s       | 0.929749          | 0.770093              | 0.195312    |\n",
      "PROGRESS: | 28      | 29.08s       | 0.929208          | 0.769587              | 0.195312    |\n",
      "PROGRESS: | 29      | 30.03s       | 0.928309          | 0.769251              | 0.195312    |\n",
      "PROGRESS: | 30      | 31.06s       | 0.926721          | 0.768862              | 0.195312    |\n",
      "PROGRESS: | 31      | 32.06s       | 0.926973          | 0.768696              | 0.195312    |\n",
      "PROGRESS: | 32      | 33.03s       | 0.925901          | 0.768282              | 0.195312    |\n",
      "PROGRESS: | 33      | 34.02s       | 0.925487          | 0.768175              | 0.195312    |\n",
      "PROGRESS: | 34      | 35.03s       | 0.925108          | 0.767918              | 0.195312    |\n",
      "PROGRESS: | 35      | 36.00s       | 0.92433           | 0.767551              | 0.195312    |\n",
      "PROGRESS: | 36      | 37.01s       | 0.923807          | 0.767512              | 0.195312    |\n",
      "PROGRESS: | 37      | 38.07s       | 0.923047          | 0.767005              | 0.195312    |\n",
      "PROGRESS: | 38      | 39.13s       | 0.922839          | 0.766902              | 0.195312    |\n",
      "PROGRESS: | 39      | 40.11s       | 0.922105          | 0.766584              | 0.195312    |\n",
      "PROGRESS: | 40      | 41.19s       | 0.922433          | 0.766472              | 0.195312    |\n",
      "PROGRESS: | 41      | 42.54s       | 0.921582          | 0.766401              | 0.195312    |\n",
      "PROGRESS: | 42      | 43.66s       | 0.920929          | 0.766084              | 0.195312    |\n",
      "PROGRESS: | 43      | 44.63s       | 0.920534          | 0.765957              | 0.195312    |\n",
      "PROGRESS: | 44      | 45.58s       | 0.919814          | 0.7656                | 0.195312    |\n",
      "PROGRESS: | 45      | 46.67s       | 0.919659          | 0.765606              | 0.195312    |\n",
      "PROGRESS: | 46      | 47.69s       | 0.919131          | 0.765209              | 0.195312    |\n",
      "PROGRESS: | 47      | 48.67s       | 0.91868           | 0.765101              | 0.195312    |\n",
      "PROGRESS: | 48      | 49.72s       | 0.918745          | 0.76523               | 0.195312    |\n",
      "PROGRESS: | 49      | 50.69s       | 0.91789           | 0.764893              | 0.195312    |\n",
      "PROGRESS: | 50      | 51.63s       | 0.917403          | 0.764583              | 0.195312    |\n",
      "PROGRESS: | 51      | 52.61s       | 0.917595          | 0.764553              | 0.195312    |\n",
      "PROGRESS: | 52      | 53.92s       | 0.916828          | 0.764392              | 0.195312    |\n",
      "PROGRESS: | 53      | 54.98s       | 0.916982          | 0.76421               | 0.195312    |\n",
      "PROGRESS: | 54      | 56.03s       | 0.916428          | 0.764122              | 0.195312    |\n",
      "PROGRESS: | 55      | 57.07s       | 0.916023          | 0.76384               | 0.195312    |\n",
      "PROGRESS: | 56      | 58.09s       | 0.915589          | 0.763864              | 0.195312    |\n",
      "PROGRESS: | 57      | 59.19s       | 0.915933          | 0.763634              | 0.195312    |\n",
      "PROGRESS: | 58      | 1m 0s        | 0.915438          | 0.76349               | 0.195312    |\n",
      "PROGRESS: | 59      | 1m 1s        | 0.915491          | 0.763533              | 0.195312    |\n",
      "PROGRESS: | 60      | 1m 2s        | 0.915056          | 0.763307              | 0.195312    |\n",
      "PROGRESS: | 61      | 1m 3s        | 0.91444           | 0.763313              | 0.195312    |\n",
      "PROGRESS: | 62      | 1m 4s        | 0.914069          | 0.762978              | 0.195312    |\n",
      "PROGRESS: | 63      | 1m 5s        | 0.91443           | 0.762937              | 0.195312    |\n",
      "PROGRESS: | 64      | 1m 6s        | 0.913458          | 0.762898              | 0.195312    |\n",
      "PROGRESS: | 65      | 1m 7s        | 0.913469          | 0.762641              | 0.195312    |\n",
      "PROGRESS: | 66      | 1m 8s        | 0.913487          | 0.76279               | 0.195312    |\n",
      "PROGRESS: | 67      | 1m 9s        | 0.912887          | 0.762466              | 0.195312    |\n",
      "PROGRESS: | 68      | 1m 10s       | 0.912098          | 0.762366              | 0.195312    |\n",
      "PROGRESS: | 69      | 1m 11s       | 0.912888          | 0.762447              | 0.195312    |\n",
      "PROGRESS: | 70      | 1m 12s       | 0.911929          | 0.762171              | 0.195312    |\n",
      "PROGRESS: | 71      | 1m 13s       | 0.912431          | 0.762169              | 0.195312    |\n",
      "PROGRESS: | 72      | 1m 14s       | 0.912242          | 0.761948              | 0.195312    |\n",
      "PROGRESS: | 73      | 1m 16s       | 0.911407          | 0.762045              | 0.195312    |\n",
      "PROGRESS: | 74      | 1m 17s       | 0.912162          | 0.761914              | 0.195312    |\n",
      "PROGRESS: | 75      | 1m 18s       | 0.910597          | 0.761755              | 0.195312    |\n",
      "PROGRESS: | 76      | 1m 19s       | 0.911267          | 0.76162               | 0.195312    |\n",
      "PROGRESS: | 77      | 1m 20s       | 0.910812          | 0.761545              | 0.195312    |\n",
      "PROGRESS: | 78      | 1m 21s       | 0.910533          | 0.761469              | 0.195312    |\n",
      "PROGRESS: | 79      | 1m 22s       | 0.910673          | 0.761279              | 0.195312    |\n",
      "PROGRESS: | 80      | 1m 23s       | 0.910707          | 0.761377              | 0.195312    |\n",
      "PROGRESS: | 81      | 1m 24s       | 0.91048           | 0.761241              | 0.195312    |\n",
      "PROGRESS: | 82      | 1m 25s       | 0.909549          | 0.761133              | 0.195312    |\n",
      "PROGRESS: | 83      | 1m 26s       | 0.90951           | 0.761114              | 0.195312    |\n",
      "PROGRESS: | 84      | 1m 27s       | 0.909437          | 0.76099               | 0.195312    |\n",
      "PROGRESS: | 85      | 1m 28s       | 0.909355          | 0.760776              | 0.195312    |\n",
      "PROGRESS: | 86      | 1m 29s       | 0.909383          | 0.760886              | 0.195312    |\n",
      "PROGRESS: | 87      | 1m 30s       | 0.909272          | 0.760771              | 0.195312    |\n",
      "PROGRESS: | 88      | 1m 31s       | 0.908803          | 0.760811              | 0.195312    |\n",
      "PROGRESS: | 89      | 1m 32s       | 0.909283          | 0.760711              | 0.195312    |\n",
      "PROGRESS: | 90      | 1m 33s       | 0.90807           | 0.760478              | 0.195312    |\n",
      "PROGRESS: | 91      | 1m 34s       | 0.908553          | 0.760535              | 0.195312    |\n",
      "PROGRESS: | 92      | 1m 35s       | 0.908419          | 0.760464              | 0.195312    |\n",
      "PROGRESS: | 93      | 1m 36s       | 0.908206          | 0.760335              | 0.195312    |\n",
      "PROGRESS: | 94      | 1m 37s       | 0.90833           | 0.760191              | 0.195312    |\n",
      "PROGRESS: | 95      | 1m 38s       | 0.908055          | 0.760144              | 0.195312    |\n",
      "PROGRESS: | 96      | 1m 39s       | 0.908147          | 0.760249              | 0.195312    |\n",
      "PROGRESS: | 97      | 1m 40s       | 0.907568          | 0.760026              | 0.195312    |\n",
      "PROGRESS: | 98      | 1m 41s       | 0.908013          | 0.75993               | 0.195312    |\n",
      "PROGRESS: | 99      | 1m 42s       | 0.907426          | 0.759976              | 0.195312    |\n",
      "PROGRESS: | 100     | 1m 43s       | 0.907336          | 0.760023              | 0.195312    |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------+-------------+\n",
      "PROGRESS: Optimization Complete: Maximum number of passes through the data reached.\n",
      "PROGRESS: Computing final objective value and training RMSE.\n",
      "PROGRESS:        Final objective value: 0.922019\n",
      "PROGRESS:        Final training RMSE: 0.750861\n"
     ]
    }
   ],
   "source": [
    "train_data = prepare_data(train_df) \n",
    "model = graphlab.ranking_factorization_recommender.create(train_data, target='rating',solver='adagrad',\n",
    "                                                           num_factors=15, max_iterations=100, \n",
    "                                                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.23432813831\n"
     ]
    }
   ],
   "source": [
    "test_data=prepare_data(test_df, verbose=False)\n",
    "print 'RMSE:', model.evaluate_rmse(test_data, target='rating')['rmse_overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: Решатели adagrad и sgd дают примерно одинаковое качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Recsys training: model = ranking_factorization_recommender\n",
      "PROGRESS: Preparing data set.\n",
      "PROGRESS:     Data has 849259 observations with 2113 users and 10084 items.\n",
      "PROGRESS:     Data prepared in: 0.869604s\n",
      "PROGRESS: Training ranking_factorization_recommender for recommendations.\n",
      "PROGRESS: +------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | Parameter                    | Description                                      | Value    |\n",
      "PROGRESS: +------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | num_factors                  | Factor Dimension                                 | 15       |\n",
      "PROGRESS: | regularization               | L2 Regularization on Factors                     | 1e-009   |\n",
      "PROGRESS: | max_iterations               | Maximum Number of Iterations                     | 100      |\n",
      "PROGRESS: | solver                       | Solver used for training                         | ials     |\n",
      "PROGRESS: +------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: +---------+--------------+---------------------------+\n",
      "PROGRESS: | Iter.   | Elapsed time | Estimated Objective Value |\n",
      "PROGRESS: +---------+--------------+---------------------------+\n",
      "PROGRESS: | Initial | 0us          | NA                        |\n",
      "PROGRESS: +---------+--------------+---------------------------+\n",
      "PROGRESS: | 0       | 1.11s        | 3.10532                   |\n",
      "PROGRESS: | 1       | 2.13s        | 2.95414                   |\n",
      "PROGRESS: | 2       | 3.11s        | 2.94523                   |\n",
      "PROGRESS: | 3       | 3.98s        | 2.9427                    |\n",
      "PROGRESS: | 4       | 4.83s        | 2.94158                   |\n",
      "PROGRESS: | 5       | 5.67s        | 2.94094                   |\n",
      "PROGRESS: | 6       | 6.50s        | 2.94055                   |\n",
      "PROGRESS: | 7       | 7.36s        | 2.94033                   |\n",
      "PROGRESS: | 8       | 8.21s        | 2.9402                    |\n",
      "PROGRESS: | 9       | 9.08s        | 2.94013                   |\n",
      "PROGRESS: | 10      | 9.94s        | 2.9401                    |\n",
      "PROGRESS: | 11      | 10.81s       | 2.94007                   |\n",
      "PROGRESS: | 12      | 11.64s       | 2.94006                   |\n",
      "PROGRESS: | 13      | 12.48s       | 2.94005                   |\n",
      "PROGRESS: | 14      | 13.37s       | 2.94004                   |\n",
      "PROGRESS: | 15      | 14.32s       | 2.94003                   |\n",
      "PROGRESS: | 16      | 15.33s       | 2.94003                   |\n",
      "PROGRESS: | 17      | 16.19s       | 2.94002                   |\n",
      "PROGRESS: | 18      | 17.06s       | 2.94002                   |\n",
      "PROGRESS: | 19      | 17.92s       | 2.94002                   |\n",
      "PROGRESS: | 20      | 18.82s       | 2.94002                   |\n",
      "PROGRESS: | 21      | 19.68s       | 2.94001                   |\n",
      "PROGRESS: | 22      | 20.59s       | 2.94001                   |\n",
      "PROGRESS: | 23      | 21.77s       | 2.94001                   |\n",
      "PROGRESS: | 24      | 22.80s       | 2.94001                   |\n",
      "PROGRESS: | 25      | 23.77s       | 2.94001                   |\n",
      "PROGRESS: | 26      | 24.76s       | 2.94001                   |\n",
      "PROGRESS: | 27      | 25.97s       | 2.94001                   |\n",
      "PROGRESS: | 28      | 27.05s       | 2.94001                   |\n",
      "PROGRESS: | 29      | 28.21s       | 2.94001                   |\n",
      "PROGRESS: | 30      | 29.09s       | 2.94001                   |\n",
      "PROGRESS: | 31      | 29.96s       | 2.94001                   |\n",
      "PROGRESS: | 32      | 30.90s       | 2.94001                   |\n",
      "PROGRESS: | 33      | 31.79s       | 2.94001                   |\n",
      "PROGRESS: | 34      | 32.66s       | 2.94                      |\n",
      "PROGRESS: | 35      | 33.51s       | 2.94                      |\n",
      "PROGRESS: | 36      | 34.39s       | 2.94                      |\n",
      "PROGRESS: | 37      | 35.22s       | 2.94                      |\n",
      "PROGRESS: | 38      | 36.10s       | 2.94                      |\n",
      "PROGRESS: | 39      | 36.96s       | 2.94                      |\n",
      "PROGRESS: | 40      | 37.83s       | 2.94                      |\n",
      "PROGRESS: | 41      | 38.75s       | 2.94                      |\n",
      "PROGRESS: | 42      | 39.59s       | 2.94                      |\n",
      "PROGRESS: | 43      | 40.44s       | 2.94                      |\n",
      "PROGRESS: | 44      | 41.29s       | 2.94                      |\n",
      "PROGRESS: | 45      | 42.16s       | 2.94                      |\n",
      "PROGRESS: | 46      | 43.04s       | 2.94                      |\n",
      "PROGRESS: | 47      | 43.90s       | 2.94                      |\n",
      "PROGRESS: | 48      | 44.78s       | 2.94                      |\n",
      "PROGRESS: | 49      | 45.64s       | 2.94                      |\n",
      "PROGRESS: | 50      | 46.53s       | 2.94                      |\n",
      "PROGRESS: | 51      | 47.64s       | 2.94                      |\n",
      "PROGRESS: | 52      | 48.75s       | 2.94                      |\n",
      "PROGRESS: | 53      | 49.85s       | 2.94                      |\n",
      "PROGRESS: | 54      | 50.73s       | 2.94                      |\n",
      "PROGRESS: | 55      | 51.57s       | 2.94                      |\n",
      "PROGRESS: | 56      | 52.52s       | 2.94                      |\n",
      "PROGRESS: | 57      | 53.64s       | 2.94                      |\n",
      "PROGRESS: | 58      | 54.66s       | 2.94                      |\n",
      "PROGRESS: | 59      | 55.57s       | 2.94                      |\n",
      "PROGRESS: | 60      | 56.48s       | 2.94                      |\n",
      "PROGRESS: | 61      | 57.35s       | 2.94                      |\n",
      "PROGRESS: | 62      | 58.25s       | 2.94                      |\n",
      "PROGRESS: | 63      | 59.13s       | 2.94                      |\n",
      "PROGRESS: | 64      | 1m 0s        | 2.94                      |\n",
      "PROGRESS: | 65      | 1m 1s        | 2.94                      |\n",
      "PROGRESS: | 66      | 1m 2s        | 2.94                      |\n",
      "PROGRESS: | 67      | 1m 3s        | 2.94                      |\n",
      "PROGRESS: | 68      | 1m 4s        | 2.94                      |\n",
      "PROGRESS: | 69      | 1m 4s        | 2.94                      |\n",
      "PROGRESS: | 70      | 1m 5s        | 2.94                      |\n",
      "PROGRESS: | 71      | 1m 6s        | 2.94                      |\n",
      "PROGRESS: | 72      | 1m 7s        | 2.94                      |\n",
      "PROGRESS: | 73      | 1m 8s        | 2.94                      |\n",
      "PROGRESS: | 74      | 1m 9s        | 2.94                      |\n",
      "PROGRESS: | 75      | 1m 10s       | 2.94                      |\n",
      "PROGRESS: | 76      | 1m 11s       | 2.94                      |\n",
      "PROGRESS: | 77      | 1m 12s       | 2.94                      |\n",
      "PROGRESS: | 78      | 1m 12s       | 2.94                      |\n",
      "PROGRESS: | 79      | 1m 13s       | 2.94                      |\n",
      "PROGRESS: | 80      | 1m 14s       | 2.94                      |\n",
      "PROGRESS: | 81      | 1m 15s       | 2.94                      |\n",
      "PROGRESS: | 82      | 1m 16s       | 2.94                      |\n",
      "PROGRESS: | 83      | 1m 17s       | 2.94                      |\n",
      "PROGRESS: | 84      | 1m 18s       | 2.94                      |\n",
      "PROGRESS: | 85      | 1m 19s       | 2.94                      |\n",
      "PROGRESS: | 86      | 1m 19s       | 2.94                      |\n",
      "PROGRESS: | 87      | 1m 20s       | 2.94                      |\n",
      "PROGRESS: | 88      | 1m 21s       | 2.94                      |\n",
      "PROGRESS: | 89      | 1m 22s       | 2.94                      |\n",
      "PROGRESS: | 90      | 1m 23s       | 2.94                      |\n",
      "PROGRESS: | 91      | 1m 24s       | 2.94                      |\n",
      "PROGRESS: | 92      | 1m 25s       | 2.94                      |\n",
      "PROGRESS: | 93      | 1m 26s       | 2.94                      |\n",
      "PROGRESS: | 94      | 1m 27s       | 2.94                      |\n",
      "PROGRESS: | 95      | 1m 27s       | 2.94                      |\n",
      "PROGRESS: | 96      | 1m 28s       | 2.94                      |\n",
      "PROGRESS: | 97      | 1m 29s       | 2.94                      |\n",
      "PROGRESS: | 98      | 1m 30s       | 2.94                      |\n",
      "PROGRESS: | 99      | 1m 31s       | 2.94                      |\n",
      "PROGRESS: | FINAL   | 1m 31s       | 2.94                      |\n",
      "PROGRESS: +---------+--------------+---------------------------+\n",
      "PROGRESS: Optimization Complete: Iteration limit reached.\n"
     ]
    }
   ],
   "source": [
    "model = graphlab.ranking_factorization_recommender.create(train_data, target='rating',solver='ials',\n",
    "                                                           num_factors=15, max_iterations=100, \n",
    "                                                           verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решателю ials не хватило 100 итераций:( Качество даже хуже, чем у нашего Pure svd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.38621657772\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE:', model.evaluate_rmse(test_data, target='rating')['rmse_overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А что если установить binary_target=True?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Recsys training: model = ranking_factorization_recommender\n",
      "PROGRESS: Preparing data set.\n",
      "PROGRESS:     Data has 849259 observations with 2113 users and 10084 items.\n",
      "PROGRESS:     Data prepared in: 0.756288s\n",
      "PROGRESS: Training ranking_factorization_recommender for recommendations.\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | Parameter                      | Description                                      | Value    |\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | num_factors                    | Factor Dimension                                 | 15       |\n",
      "PROGRESS: | regularization                 | L2 Regularization on Factors                     | 1e-009   |\n",
      "PROGRESS: | solver                         | Solver used for training                         | adagrad  |\n",
      "PROGRESS: | linear_regularization          | L2 Regularization on Linear Coefficients         | 1e-009   |\n",
      "PROGRESS: | ranking_regularization         | Rank-based Regularization Weight                 | 0.25     |\n",
      "PROGRESS: | binary_target                  | Assume Binary Targets                            | True     |\n",
      "PROGRESS: | max_iterations                 | Maximum Number of Iterations                     | 100      |\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS:   Optimizing model using SGD; tuning step size.\n",
      "PROGRESS:   Using 106157 / 849259 points for tuning the step size.\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | Attempt | Initial Step Size | Estimated Objective Value                |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | 0       | 25                | No Decrease (20.1024 >= 1.62674)         |\n",
      "PROGRESS: | 1       | 6.25              | No Decrease (3.74558 >= 1.62674)         |\n",
      "PROGRESS: | 2       | 1.5625            | 1.24024                                  |\n",
      "PROGRESS: | 3       | 0.78125           | 1.10275                                  |\n",
      "PROGRESS: | 4       | 0.390625          | 1.04808                                  |\n",
      "PROGRESS: | 5       | 0.195312          | 1.0761                                   |\n",
      "PROGRESS: | 6       | 0.0976562         | 1.1461                                   |\n",
      "PROGRESS: | 7       | 0.0488281         | 1.21848                                  |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | Final   | 0.390625          | 1.04808                                  |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: Starting Optimization.\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: | Iter.   | Elapsed Time | Approx. Objective | Approx. Training Predictive Error | Step Size   |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: | Initial | 501us        | 1.62674           | 0.313264                          |             |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: | 1       | 1.21s        | 1.05036           | 0.519603                          | 0.390625    |\n",
      "PROGRESS: | 2       | 2.40s        | 0.974266          | 0.49322                           | 0.390625    |\n",
      "PROGRESS: | 3       | 3.61s        | 0.945459          | 0.476816                          | 0.390625    |\n",
      "PROGRESS: | 4       | 4.79s        | 0.927389          | 0.46842                           | 0.390625    |\n",
      "PROGRESS: | 5       | 5.99s        | 0.916808          | 0.461874                          | 0.390625    |\n",
      "PROGRESS: | 6       | 7.22s        | 0.909237          | 0.457901                          | 0.390625    |\n",
      "PROGRESS: | 7       | 8.42s        | 0.902616          | 0.454128                          | 0.390625    |\n",
      "PROGRESS: | 8       | 9.71s        | 0.898384          | 0.451877                          | 0.390625    |\n",
      "PROGRESS: | 9       | 11.18s       | 0.89454           | 0.449552                          | 0.390625    |\n",
      "PROGRESS: | 10      | 12.57s       | 0.889824          | 0.447327                          | 0.390625    |\n",
      "PROGRESS: | 11      | 14.16s       | 0.888751          | 0.446197                          | 0.390625    |\n",
      "PROGRESS: | 12      | 15.54s       | 0.886183          | 0.444744                          | 0.390625    |\n",
      "PROGRESS: | 13      | 17.01s       | 0.884564          | 0.443705                          | 0.390625    |\n",
      "PROGRESS: | 14      | 18.32s       | 0.882979          | 0.442796                          | 0.390625    |\n",
      "PROGRESS: | 15      | 19.70s       | 0.881251          | 0.441782                          | 0.390625    |\n",
      "PROGRESS: | 16      | 20.83s       | 0.87935           | 0.440738                          | 0.390625    |\n",
      "PROGRESS: | 17      | 21.99s       | 0.878734          | 0.440542                          | 0.390625    |\n",
      "PROGRESS: | 18      | 23.13s       | 0.877762          | 0.43973                           | 0.390625    |\n",
      "PROGRESS: | 19      | 24.26s       | 0.876609          | 0.438971                          | 0.390625    |\n",
      "PROGRESS: | 20      | 25.46s       | 0.87517           | 0.438071                          | 0.390625    |\n",
      "PROGRESS: | 21      | 26.57s       | 0.874218          | 0.438019                          | 0.390625    |\n",
      "PROGRESS: | 22      | 27.68s       | 0.87337           | 0.437271                          | 0.390625    |\n",
      "PROGRESS: | 23      | 28.79s       | 0.872776          | 0.437177                          | 0.390625    |\n",
      "PROGRESS: | 24      | 29.90s       | 0.872326          | 0.4366                            | 0.390625    |\n",
      "PROGRESS: | 25      | 31.03s       | 0.871732          | 0.435908                          | 0.390625    |\n",
      "PROGRESS: | 26      | 32.17s       | 0.870531          | 0.43605                           | 0.390625    |\n",
      "PROGRESS: | 27      | 33.28s       | 0.870259          | 0.435413                          | 0.390625    |\n",
      "PROGRESS: | 28      | 34.38s       | 0.869861          | 0.435398                          | 0.390625    |\n",
      "PROGRESS: | 29      | 35.53s       | 0.869267          | 0.434684                          | 0.390625    |\n",
      "PROGRESS: | 30      | 36.76s       | 0.868734          | 0.434643                          | 0.390625    |\n",
      "PROGRESS: | 31      | 37.90s       | 0.867014          | 0.433721                          | 0.390625    |\n",
      "PROGRESS: | 32      | 38.99s       | 0.868484          | 0.434286                          | 0.390625    |\n",
      "PROGRESS: | 33      | 40.22s       | 0.86798           | 0.433883                          | 0.390625    |\n",
      "PROGRESS: | 34      | 41.46s       | 0.866914          | 0.433636                          | 0.390625    |\n",
      "PROGRESS: | 35      | 42.54s       | 0.866566          | 0.433539                          | 0.390625    |\n",
      "PROGRESS: | 36      | 43.71s       | 0.865938          | 0.433171                          | 0.390625    |\n",
      "PROGRESS: | 37      | 44.84s       | 0.867147          | 0.43321                           | 0.390625    |\n",
      "PROGRESS: | 38      | 45.97s       | 0.865227          | 0.432577                          | 0.390625    |\n",
      "PROGRESS: | 39      | 47.06s       | 0.86559           | 0.432833                          | 0.390625    |\n",
      "PROGRESS: | 40      | 48.16s       | 0.865813          | 0.432899                          | 0.390625    |\n",
      "PROGRESS: | 41      | 49.36s       | 0.864666          | 0.432109                          | 0.390625    |\n",
      "PROGRESS: | 42      | 50.47s       | 0.86509           | 0.432135                          | 0.390625    |\n",
      "PROGRESS: | 43      | 51.58s       | 0.863738          | 0.431873                          | 0.390625    |\n",
      "PROGRESS: | 44      | 52.69s       | 0.863806          | 0.431784                          | 0.390625    |\n",
      "PROGRESS: | 45      | 53.86s       | 0.863061          | 0.431286                          | 0.390625    |\n",
      "PROGRESS: | 46      | 55.01s       | 0.863965          | 0.431821                          | 0.390625    |\n",
      "PROGRESS: | 47      | 56.32s       | 0.862365          | 0.430746                          | 0.390625    |\n",
      "PROGRESS: | 48      | 57.69s       | 0.862232          | 0.430584                          | 0.390625    |\n",
      "PROGRESS: | 49      | 59.13s       | 0.862266          | 0.430858                          | 0.390625    |\n",
      "PROGRESS: | 50      | 1m 0s        | 0.862471          | 0.430371                          | 0.390625    |\n",
      "PROGRESS: | 51      | 1m 1s        | 0.862252          | 0.430829                          | 0.390625    |\n",
      "PROGRESS: | 52      | 1m 2s        | 0.862209          | 0.43043                           | 0.390625    |\n",
      "PROGRESS: | 53      | 1m 3s        | 0.861729          | 0.4305                            | 0.390625    |\n",
      "PROGRESS: | 54      | 1m 5s        | 0.86173           | 0.430481                          | 0.390625    |\n",
      "PROGRESS: | 55      | 1m 6s        | 0.86131           | 0.430397                          | 0.390625    |\n",
      "PROGRESS: | 56      | 1m 7s        | 0.860361          | 0.429559                          | 0.390625    |\n",
      "PROGRESS: | 57      | 1m 9s        | 0.861718          | 0.429818                          | 0.390625    |\n",
      "PROGRESS: | 58      | 1m 10s       | 0.861003          | 0.430202                          | 0.390625    |\n",
      "PROGRESS: | 59      | 1m 11s       | 0.859725          | 0.429099                          | 0.390625    |\n",
      "PROGRESS: | 60      | 1m 12s       | 0.859875          | 0.429107                          | 0.390625    |\n",
      "PROGRESS: | 61      | 1m 14s       | 0.858796          | 0.428794                          | 0.390625    |\n",
      "PROGRESS: | 62      | 1m 15s       | 0.860905          | 0.429388                          | 0.390625    |\n",
      "PROGRESS: | 63      | 1m 16s       | 0.859179          | 0.429115                          | 0.390625    |\n",
      "PROGRESS: | 64      | 1m 18s       | 0.8591            | 0.428782                          | 0.390625    |\n",
      "PROGRESS: | 65      | 1m 19s       | 0.859418          | 0.429193                          | 0.390625    |\n",
      "PROGRESS: | 66      | 1m 20s       | 0.858524          | 0.428529                          | 0.390625    |\n",
      "PROGRESS: | 67      | 1m 21s       | 0.85879           | 0.428515                          | 0.390625    |\n",
      "PROGRESS: | 68      | 1m 23s       | 0.859117          | 0.428446                          | 0.390625    |\n",
      "PROGRESS: | 69      | 1m 24s       | 0.85905           | 0.428957                          | 0.390625    |\n",
      "PROGRESS: | 70      | 1m 25s       | 0.858872          | 0.428704                          | 0.390625    |\n",
      "PROGRESS: | 71      | 1m 26s       | 0.858464          | 0.428444                          | 0.390625    |\n",
      "PROGRESS: | 72      | 1m 28s       | 0.85837           | 0.428551                          | 0.390625    |\n",
      "PROGRESS: | 73      | 1m 29s       | 0.859339          | 0.428406                          | 0.390625    |\n",
      "PROGRESS: | 74      | 1m 30s       | 0.857724          | 0.428195                          | 0.390625    |\n",
      "PROGRESS: | 75      | 1m 32s       | 0.856848          | 0.427645                          | 0.390625    |\n",
      "PROGRESS: | 76      | 1m 33s       | 0.857108          | 0.427501                          | 0.390625    |\n",
      "PROGRESS: | 77      | 1m 34s       | 0.857838          | 0.428178                          | 0.390625    |\n",
      "PROGRESS: | 78      | 1m 35s       | 0.857976          | 0.427996                          | 0.390625    |\n",
      "PROGRESS: | 79      | 1m 36s       | 0.857861          | 0.427853                          | 0.390625    |\n",
      "PROGRESS: | 80      | 1m 38s       | 0.857601          | 0.427716                          | 0.390625    |\n",
      "PROGRESS: | 81      | 1m 39s       | 0.856134          | 0.427276                          | 0.390625    |\n",
      "PROGRESS: | 82      | 1m 40s       | 0.856807          | 0.427246                          | 0.390625    |\n",
      "PROGRESS: | 83      | 1m 42s       | 0.85725           | 0.427619                          | 0.390625    |\n",
      "PROGRESS: | 84      | 1m 43s       | 0.8561            | 0.427284                          | 0.390625    |\n",
      "PROGRESS: | 85      | 1m 44s       | 0.856268          | 0.426997                          | 0.390625    |\n",
      "PROGRESS: | 86      | 1m 45s       | 0.857522          | 0.427537                          | 0.390625    |\n",
      "PROGRESS: | 87      | 1m 47s       | 0.856756          | 0.427348                          | 0.390625    |\n",
      "PROGRESS: | 88      | 1m 48s       | 0.85612           | 0.427285                          | 0.390625    |\n",
      "PROGRESS: | 89      | 1m 49s       | 0.857128          | 0.42758                           | 0.390625    |\n",
      "PROGRESS: | 90      | 1m 50s       | 0.856103          | 0.427227                          | 0.390625    |\n",
      "PROGRESS: | 91      | 1m 52s       | 0.856054          | 0.426888                          | 0.390625    |\n",
      "PROGRESS: | 92      | 1m 53s       | 0.855849          | 0.426683                          | 0.390625    |\n",
      "PROGRESS: | 93      | 1m 54s       | 0.856108          | 0.42681                           | 0.390625    |\n",
      "PROGRESS: | 94      | 1m 55s       | 0.856548          | 0.427356                          | 0.390625    |\n",
      "PROGRESS: | 95      | 1m 56s       | 0.85572           | 0.42667                           | 0.390625    |\n",
      "PROGRESS: | 96      | 1m 58s       | 0.856185          | 0.426867                          | 0.390625    |\n",
      "PROGRESS: | 97      | 1m 59s       | 0.85602           | 0.426683                          | 0.390625    |\n",
      "PROGRESS: | 98      | 2m 0s        | 0.855912          | 0.426915                          | 0.390625    |\n",
      "PROGRESS: | 99      | 2m 2s        | 0.854664          | 0.426076                          | 0.390625    |\n",
      "PROGRESS: | 100     | 2m 3s        | 0.855738          | 0.42636                           | 0.390625    |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: Optimization Complete: Maximum number of passes through the data reached.\n",
      "PROGRESS: Computing final objective value and training Predictive Error.\n",
      "PROGRESS:        Final objective value: 0.885066\n",
      "PROGRESS:        Final training Predictive Error: 0.418521\n"
     ]
    }
   ],
   "source": [
    "train_data = prepare_data(train_df, binary=True) \n",
    "model = graphlab.ranking_factorization_recommender.create(train_data, target='rating',solver='adagrad',\n",
    "                                                           num_factors=15, max_iterations=100, \n",
    "                                                           verbose=True, binary_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.564590083264\n"
     ]
    }
   ],
   "source": [
    "test_data=prepare_data(test_df, verbose=False, binary=True)\n",
    "print 'RMSE:', model.evaluate_rmse(test_data, target='rating')['rmse_overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдение: adagrad незначительно превзашел в качестве sgd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Recsys training: model = ranking_factorization_recommender\n",
      "PROGRESS: Preparing data set.\n",
      "PROGRESS:     Data has 849259 observations with 2113 users and 10084 items.\n",
      "PROGRESS:     Data prepared in: 0.796311s\n",
      "PROGRESS: Training ranking_factorization_recommender for recommendations.\n",
      "PROGRESS: +------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | Parameter                    | Description                                      | Value    |\n",
      "PROGRESS: +------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | num_factors                  | Factor Dimension                                 | 15       |\n",
      "PROGRESS: | regularization               | L2 Regularization on Factors                     | 1e-009   |\n",
      "PROGRESS: | max_iterations               | Maximum Number of Iterations                     | 100      |\n",
      "PROGRESS: | solver                       | Solver used for training                         | ials     |\n",
      "PROGRESS: +------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: +---------+--------------+---------------------------+\n",
      "PROGRESS: | Iter.   | Elapsed time | Estimated Objective Value |\n",
      "PROGRESS: +---------+--------------+---------------------------+\n",
      "PROGRESS: | Initial | 500us        | NA                        |\n",
      "PROGRESS: +---------+--------------+---------------------------+\n",
      "PROGRESS: | 0       | 892.096ms    | 0.683325                  |\n",
      "PROGRESS: | 1       | 1.80s        | 0.552587                  |\n",
      "PROGRESS: | 2       | 2.70s        | 0.543996                  |\n",
      "PROGRESS: | 3       | 3.62s        | 0.542094                  |\n",
      "PROGRESS: | 4       | 4.56s        | 0.54142                   |\n",
      "PROGRESS: | 5       | 5.50s        | 0.541076                  |\n",
      "PROGRESS: | 6       | 6.47s        | 0.54088                   |\n",
      "PROGRESS: | 7       | 7.42s        | 0.54077                   |\n",
      "PROGRESS: | 8       | 8.51s        | 0.54071                   |\n",
      "PROGRESS: | 9       | 9.49s        | 0.540678                  |\n",
      "PROGRESS: | 10      | 10.39s       | 0.540661                  |\n",
      "PROGRESS: | 11      | 11.34s       | 0.540651                  |\n",
      "PROGRESS: | 12      | 12.28s       | 0.540647                  |\n",
      "PROGRESS: | 13      | 13.23s       | 0.540644                  |\n",
      "PROGRESS: | 14      | 14.18s       | 0.540643                  |\n",
      "PROGRESS: | 15      | 15.21s       | 0.540643                  |\n",
      "PROGRESS: | 16      | 16.21s       | 0.540643                  |\n",
      "PROGRESS: | 17      | 17.17s       | 0.540643                  |\n",
      "PROGRESS: | 18      | 18.06s       | 0.540643                  |\n",
      "PROGRESS: | 19      | 18.92s       | 0.540644                  |\n",
      "PROGRESS: | 20      | 19.82s       | 0.540644                  |\n",
      "PROGRESS: | 21      | 20.74s       | 0.540644                  |\n",
      "PROGRESS: | 22      | 21.66s       | 0.540644                  |\n",
      "PROGRESS: | 23      | 22.57s       | 0.540644                  |\n",
      "PROGRESS: | 24      | 23.70s       | 0.540645                  |\n",
      "PROGRESS: | 25      | 24.71s       | 0.540645                  |\n",
      "PROGRESS: | 26      | 25.59s       | 0.540645                  |\n",
      "PROGRESS: | 27      | 26.54s       | 0.540645                  |\n",
      "PROGRESS: | 28      | 27.44s       | 0.540645                  |\n",
      "PROGRESS: | 29      | 28.33s       | 0.540645                  |\n",
      "PROGRESS: | 30      | 29.28s       | 0.540645                  |\n",
      "PROGRESS: | 31      | 30.22s       | 0.540645                  |\n",
      "PROGRESS: | 32      | 31.08s       | 0.540645                  |\n",
      "PROGRESS: | 33      | 31.94s       | 0.540645                  |\n",
      "PROGRESS: | 34      | 32.81s       | 0.540645                  |\n",
      "PROGRESS: | 35      | 33.67s       | 0.540644                  |\n",
      "PROGRESS: | 36      | 34.52s       | 0.540644                  |\n",
      "PROGRESS: | 37      | 35.38s       | 0.540644                  |\n",
      "PROGRESS: | 38      | 36.25s       | 0.540644                  |\n",
      "PROGRESS: | 39      | 37.23s       | 0.540644                  |\n",
      "PROGRESS: | 40      | 38.14s       | 0.540644                  |\n",
      "PROGRESS: | 41      | 39.01s       | 0.540644                  |\n",
      "PROGRESS: | 42      | 39.89s       | 0.540644                  |\n",
      "PROGRESS: | 43      | 40.80s       | 0.540644                  |\n",
      "PROGRESS: | 44      | 41.69s       | 0.540643                  |\n",
      "PROGRESS: | 45      | 42.58s       | 0.540643                  |\n",
      "PROGRESS: | 46      | 43.45s       | 0.540643                  |\n",
      "PROGRESS: | 47      | 44.36s       | 0.540643                  |\n",
      "PROGRESS: | 48      | 45.28s       | 0.540643                  |\n",
      "PROGRESS: | 49      | 46.26s       | 0.540643                  |\n",
      "PROGRESS: | 50      | 47.25s       | 0.540643                  |\n",
      "PROGRESS: | 51      | 48.21s       | 0.540643                  |\n",
      "PROGRESS: | 52      | 49.06s       | 0.540643                  |\n",
      "PROGRESS: | 53      | 50.08s       | 0.540643                  |\n",
      "PROGRESS: | 54      | 51.02s       | 0.540642                  |\n",
      "PROGRESS: | 55      | 51.94s       | 0.540642                  |\n",
      "PROGRESS: | 56      | 52.88s       | 0.540642                  |\n",
      "PROGRESS: | 57      | 53.78s       | 0.540642                  |\n",
      "PROGRESS: | 58      | 54.65s       | 0.540642                  |\n",
      "PROGRESS: | 59      | 55.55s       | 0.540642                  |\n",
      "PROGRESS: | 60      | 56.66s       | 0.540642                  |\n",
      "PROGRESS: | 61      | 57.87s       | 0.540642                  |\n",
      "PROGRESS: | 62      | 59.03s       | 0.540642                  |\n",
      "PROGRESS: | 63      | 1m 0s        | 0.540642                  |\n",
      "PROGRESS: | 64      | 1m 0s        | 0.540642                  |\n",
      "PROGRESS: | 65      | 1m 1s        | 0.540641                  |\n",
      "PROGRESS: | 66      | 1m 2s        | 0.540641                  |\n",
      "PROGRESS: | 67      | 1m 3s        | 0.540641                  |\n",
      "PROGRESS: | 68      | 1m 4s        | 0.540641                  |\n",
      "PROGRESS: | 69      | 1m 5s        | 0.540641                  |\n",
      "PROGRESS: | 70      | 1m 6s        | 0.540641                  |\n",
      "PROGRESS: | 71      | 1m 7s        | 0.540641                  |\n",
      "PROGRESS: | 72      | 1m 8s        | 0.540641                  |\n",
      "PROGRESS: | 73      | 1m 9s        | 0.540641                  |\n",
      "PROGRESS: | 74      | 1m 10s       | 0.540641                  |\n",
      "PROGRESS: | 75      | 1m 11s       | 0.540641                  |\n",
      "PROGRESS: | 76      | 1m 11s       | 0.540641                  |\n",
      "PROGRESS: | 77      | 1m 12s       | 0.540641                  |\n",
      "PROGRESS: | 78      | 1m 13s       | 0.54064                   |\n",
      "PROGRESS: | 79      | 1m 14s       | 0.54064                   |\n",
      "PROGRESS: | 80      | 1m 15s       | 0.54064                   |\n",
      "PROGRESS: | 81      | 1m 16s       | 0.54064                   |\n",
      "PROGRESS: | 82      | 1m 17s       | 0.54064                   |\n",
      "PROGRESS: | 83      | 1m 18s       | 0.54064                   |\n",
      "PROGRESS: | 84      | 1m 19s       | 0.54064                   |\n",
      "PROGRESS: | 85      | 1m 20s       | 0.54064                   |\n",
      "PROGRESS: | 86      | 1m 21s       | 0.54064                   |\n",
      "PROGRESS: | 87      | 1m 22s       | 0.54064                   |\n",
      "PROGRESS: | 88      | 1m 23s       | 0.54064                   |\n",
      "PROGRESS: | 89      | 1m 24s       | 0.54064                   |\n",
      "PROGRESS: | 90      | 1m 25s       | 0.54064                   |\n",
      "PROGRESS: | 91      | 1m 26s       | 0.54064                   |\n",
      "PROGRESS: | 92      | 1m 27s       | 0.54064                   |\n",
      "PROGRESS: | 93      | 1m 28s       | 0.540639                  |\n",
      "PROGRESS: | 94      | 1m 28s       | 0.540639                  |\n",
      "PROGRESS: | 95      | 1m 29s       | 0.540639                  |\n",
      "PROGRESS: | 96      | 1m 30s       | 0.540639                  |\n",
      "PROGRESS: | 97      | 1m 31s       | 0.540639                  |\n",
      "PROGRESS: | 98      | 1m 32s       | 0.540639                  |\n",
      "PROGRESS: | 99      | 1m 33s       | 0.540639                  |\n",
      "PROGRESS: | FINAL   | 1m 33s       | 0.540639                  |\n",
      "PROGRESS: +---------+--------------+---------------------------+\n",
      "PROGRESS: Optimization Complete: Iteration limit reached.\n"
     ]
    }
   ],
   "source": [
    "model = graphlab.ranking_factorization_recommender.create(train_data, target='rating',solver='ials',\n",
    "                                                           num_factors=15, max_iterations=100, \n",
    "                                                           verbose=True, binary_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.775337538264\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE:', model.evaluate_rmse(test_data, target='rating')['rmse_overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решателю ials снова не хватает итераций. Но качество уже значительно лучше, чем в случае квадратичных потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А как влияет регуляризация?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Recsys training: model = ranking_factorization_recommender\n",
      "PROGRESS: Preparing data set.\n",
      "PROGRESS:     Data has 849259 observations with 2113 users and 10084 items.\n",
      "PROGRESS:     Data prepared in: 0.736513s\n",
      "PROGRESS: Training ranking_factorization_recommender for recommendations.\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | Parameter                      | Description                                      | Value    |\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS: | num_factors                    | Factor Dimension                                 | 15       |\n",
      "PROGRESS: | regularization                 | L2 Regularization on Factors                     | 0.001    |\n",
      "PROGRESS: | solver                         | Solver used for training                         | adagrad  |\n",
      "PROGRESS: | linear_regularization          | L2 Regularization on Linear Coefficients         | 1e-009   |\n",
      "PROGRESS: | ranking_regularization         | Rank-based Regularization Weight                 | 0.25     |\n",
      "PROGRESS: | binary_target                  | Assume Binary Targets                            | True     |\n",
      "PROGRESS: | max_iterations                 | Maximum Number of Iterations                     | 100      |\n",
      "PROGRESS: +--------------------------------+--------------------------------------------------+----------+\n",
      "PROGRESS:   Optimizing model using SGD; tuning step size.\n",
      "PROGRESS:   Using 106157 / 849259 points for tuning the step size.\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | Attempt | Initial Step Size | Estimated Objective Value                |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | 0       | 0.0867574         | No Decrease (1.74004 >= 1.62674)         |\n",
      "PROGRESS: | 1       | 0.0216894         | 1.33919                                  |\n",
      "PROGRESS: | 2       | 0.0108447         | 1.37889                                  |\n",
      "PROGRESS: | 3       | 0.00542234        | 1.44175                                  |\n",
      "PROGRESS: | 4       | 0.00271117        | 1.51186                                  |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: | Final   | 0.0216894         | 1.33919                                  |\n",
      "PROGRESS: +---------+-------------------+------------------------------------------+\n",
      "PROGRESS: Starting Optimization.\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: | Iter.   | Elapsed Time | Approx. Objective | Approx. Training Predictive Error | Step Size   |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: | Initial | 0us          | 1.62674           | 0.313263                          |             |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: | 1       | 1.20s        | 1.51479           | 0.543858                          | 0.0216894   |\n",
      "PROGRESS: | 2       | 2.41s        | 1.50384           | 0.629376                          | 0.0216894   |\n",
      "PROGRESS: | 3       | 3.63s        | 1.47852           | 0.607908                          | 0.0216894   |\n",
      "PROGRESS: | 4       | 4.90s        | 1.46438           | 0.601578                          | 0.0216894   |\n",
      "PROGRESS: | 5       | 6.12s        | 1.45413           | 0.598239                          | 0.0216894   |\n",
      "PROGRESS: | 6       | 7.34s        | 1.44712           | 0.595121                          | 0.0216894   |\n",
      "PROGRESS: | 7       | 8.56s        | 1.44169           | 0.593209                          | 0.0216894   |\n",
      "PROGRESS: | 8       | 9.81s        | 1.43734           | 0.591721                          | 0.0216894   |\n",
      "PROGRESS: | 9       | 11.04s       | 1.43369           | 0.590471                          | 0.0216894   |\n",
      "PROGRESS: | 10      | 12.30s       | 1.43007           | 0.589438                          | 0.0216894   |\n",
      "PROGRESS: | 11      | 13.51s       | 1.42733           | 0.588316                          | 0.0216894   |\n",
      "PROGRESS: | 12      | 14.81s       | 1.42558           | 0.587364                          | 0.0216894   |\n",
      "PROGRESS: | 13      | 16.05s       | 1.42395           | 0.586767                          | 0.0216894   |\n",
      "PROGRESS: | 14      | 17.31s       | 1.42125           | 0.586165                          | 0.0216894   |\n",
      "PROGRESS: | 15      | 18.64s       | 1.4204            | 0.58573                           | 0.0216894   |\n",
      "PROGRESS: | 16      | 19.82s       | 1.41886           | 0.585143                          | 0.0216894   |\n",
      "PROGRESS: | 17      | 21.01s       | 1.41714           | 0.584569                          | 0.0216894   |\n",
      "PROGRESS: | 18      | 22.30s       | 1.41688           | 0.584345                          | 0.0216894   |\n",
      "PROGRESS: | 19      | 23.59s       | 1.41588           | 0.584074                          | 0.0216894   |\n",
      "PROGRESS: | 20      | 24.81s       | 1.41485           | 0.583653                          | 0.0216894   |\n",
      "PROGRESS: | 21      | 26.01s       | 1.41394           | 0.583297                          | 0.0216894   |\n",
      "PROGRESS: | 22      | 27.22s       | 1.41374           | 0.5831                            | 0.0216894   |\n",
      "PROGRESS: | 23      | 28.43s       | 1.41291           | 0.582925                          | 0.0216894   |\n",
      "PROGRESS: | 24      | 29.61s       | 1.41235           | 0.582626                          | 0.0216894   |\n",
      "PROGRESS: | 25      | 30.78s       | 1.41158           | 0.582509                          | 0.0216894   |\n",
      "PROGRESS: | 26      | 31.98s       | 1.41096           | 0.582159                          | 0.0216894   |\n",
      "PROGRESS: | 27      | 33.19s       | 1.41056           | 0.581999                          | 0.0216894   |\n",
      "PROGRESS: | 28      | 34.39s       | 1.4096            | 0.581929                          | 0.0216894   |\n",
      "PROGRESS: | 29      | 35.58s       | 1.40909           | 0.581651                          | 0.0216894   |\n",
      "PROGRESS: | 30      | 36.77s       | 1.40847           | 0.581409                          | 0.0216894   |\n",
      "PROGRESS: | 31      | 37.97s       | 1.4085            | 0.581221                          | 0.0216894   |\n",
      "PROGRESS: | 32      | 39.16s       | 1.40825           | 0.581131                          | 0.0216894   |\n",
      "PROGRESS: | 33      | 40.44s       | 1.40753           | 0.58099                           | 0.0216894   |\n",
      "PROGRESS: | 34      | 41.60s       | 1.40787           | 0.581007                          | 0.0216894   |\n",
      "PROGRESS: | 35      | 42.88s       | 1.40682           | 0.580857                          | 0.0216894   |\n",
      "PROGRESS: | 36      | 44.07s       | 1.40651           | 0.580747                          | 0.0216894   |\n",
      "PROGRESS: | 37      | 45.28s       | 1.40685           | 0.58063                           | 0.0216894   |\n",
      "PROGRESS: | 38      | 46.46s       | 1.4062            | 0.580533                          | 0.0216894   |\n",
      "PROGRESS: | 39      | 47.68s       | 1.40632           | 0.580461                          | 0.0216894   |\n",
      "PROGRESS: | 40      | 48.94s       | 1.40614           | 0.580418                          | 0.0216894   |\n",
      "PROGRESS: | 41      | 50.22s       | 1.40557           | 0.580326                          | 0.0216894   |\n",
      "PROGRESS: | 42      | 51.44s       | 1.40554           | 0.580297                          | 0.0216894   |\n",
      "PROGRESS: | 43      | 52.69s       | 1.40501           | 0.580181                          | 0.0216894   |\n",
      "PROGRESS: | 44      | 53.94s       | 1.40494           | 0.580255                          | 0.0216894   |\n",
      "PROGRESS: | 45      | 55.23s       | 1.40495           | 0.580171                          | 0.0216894   |\n",
      "PROGRESS: | 46      | 56.43s       | 1.4039            | 0.580057                          | 0.0216894   |\n",
      "PROGRESS: | 47      | 57.65s       | 1.40403           | 0.579856                          | 0.0216894   |\n",
      "PROGRESS: | 48      | 59.03s       | 1.40366           | 0.579822                          | 0.0216894   |\n",
      "PROGRESS: | 49      | 1m 0s        | 1.40442           | 0.579805                          | 0.0216894   |\n",
      "PROGRESS: | 50      | 1m 1s        | 1.40365           | 0.579811                          | 0.0216894   |\n",
      "PROGRESS: | 51      | 1m 2s        | 1.40372           | 0.579754                          | 0.0216894   |\n",
      "PROGRESS: | 52      | 1m 3s        | 1.40362           | 0.579873                          | 0.0216894   |\n",
      "PROGRESS: | 53      | 1m 5s        | 1.40352           | 0.579861                          | 0.0216894   |\n",
      "PROGRESS: | 54      | 1m 6s        | 1.40389           | 0.5798                            | 0.0216894   |\n",
      "PROGRESS: | 55      | 1m 7s        | 1.40338           | 0.579703                          | 0.0216894   |\n",
      "PROGRESS: | 56      | 1m 8s        | 1.40324           | 0.579741                          | 0.0216894   |\n",
      "PROGRESS: | 57      | 1m 9s        | 1.40296           | 0.579726                          | 0.0216894   |\n",
      "PROGRESS: | 58      | 1m 11s       | 1.40323           | 0.57975                           | 0.0216894   |\n",
      "PROGRESS: | 59      | 1m 12s       | 1.40256           | 0.579671                          | 0.0216894   |\n",
      "PROGRESS: | 60      | 1m 14s       | 1.40281           | 0.579581                          | 0.0216894   |\n",
      "PROGRESS: | 61      | 1m 15s       | 1.40229           | 0.579591                          | 0.0216894   |\n",
      "PROGRESS: | 62      | 1m 16s       | 1.40245           | 0.579448                          | 0.0216894   |\n",
      "PROGRESS: | 63      | 1m 18s       | 1.40273           | 0.579438                          | 0.0216894   |\n",
      "PROGRESS: | 64      | 1m 19s       | 1.40263           | 0.579452                          | 0.0216894   |\n",
      "PROGRESS: | 65      | 1m 20s       | 1.40225           | 0.579457                          | 0.0216894   |\n",
      "PROGRESS: | 66      | 1m 21s       | 1.40263           | 0.579393                          | 0.0216894   |\n",
      "PROGRESS: | 67      | 1m 23s       | 1.40224           | 0.57945                           | 0.0216894   |\n",
      "PROGRESS: | 68      | 1m 24s       | 1.40194           | 0.57947                           | 0.0216894   |\n",
      "PROGRESS: | 69      | 1m 25s       | 1.40305           | 0.579518                          | 0.0216894   |\n",
      "PROGRESS: | 70      | 1m 26s       | 1.40163           | 0.579543                          | 0.0216894   |\n",
      "PROGRESS: | 71      | 1m 27s       | 1.40249           | 0.579463                          | 0.0216894   |\n",
      "PROGRESS: | 72      | 1m 29s       | 1.40119           | 0.579496                          | 0.0216894   |\n",
      "PROGRESS: | 73      | 1m 30s       | 1.40169           | 0.579379                          | 0.0216894   |\n",
      "PROGRESS: | 74      | 1m 31s       | 1.40147           | 0.579388                          | 0.0216894   |\n",
      "PROGRESS: | 75      | 1m 32s       | 1.40124           | 0.579269                          | 0.0216894   |\n",
      "PROGRESS: | 76      | 1m 33s       | 1.40144           | 0.579229                          | 0.0216894   |\n",
      "PROGRESS: | 77      | 1m 35s       | 1.40158           | 0.579284                          | 0.0216894   |\n",
      "PROGRESS: | 78      | 1m 36s       | 1.40226           | 0.579368                          | 0.0216894   |\n",
      "PROGRESS: | 79      | 1m 37s       | 1.40171           | 0.579424                          | 0.0216894   |\n",
      "PROGRESS: | 80      | 1m 38s       | 1.40095           | 0.5794                            | 0.0216894   |\n",
      "PROGRESS: | 81      | 1m 39s       | 1.40155           | 0.579336                          | 0.0216894   |\n",
      "PROGRESS: | 82      | 1m 41s       | 1.40065           | 0.579321                          | 0.0216894   |\n",
      "PROGRESS: | 83      | 1m 42s       | 1.40141           | 0.579287                          | 0.0216894   |\n",
      "PROGRESS: | 84      | 1m 43s       | 1.40114           | 0.579375                          | 0.0216894   |\n",
      "PROGRESS: | 85      | 1m 45s       | 1.4014            | 0.57938                           | 0.0216894   |\n",
      "PROGRESS: | 86      | 1m 46s       | 1.40062           | 0.57932                           | 0.0216894   |\n",
      "PROGRESS: | 87      | 1m 47s       | 1.40106           | 0.579212                          | 0.0216894   |\n",
      "PROGRESS: | 88      | 1m 48s       | 1.40093           | 0.57923                           | 0.0216894   |\n",
      "PROGRESS: | 89      | 1m 50s       | 1.40115           | 0.579252                          | 0.0216894   |\n",
      "PROGRESS: | 90      | 1m 51s       | 1.40026           | 0.579238                          | 0.0216894   |\n",
      "PROGRESS: | 91      | 1m 52s       | 1.40053           | 0.579208                          | 0.0216894   |\n",
      "PROGRESS: | 92      | 1m 53s       | 1.4016            | 0.579208                          | 0.0216894   |\n",
      "PROGRESS: | 93      | 1m 55s       | 1.4012            | 0.579217                          | 0.0216894   |\n",
      "PROGRESS: | 94      | 1m 56s       | 1.40082           | 0.579271                          | 0.0216894   |\n",
      "PROGRESS: | 95      | 1m 57s       | 1.40123           | 0.579245                          | 0.0216894   |\n",
      "PROGRESS: | 96      | 1m 58s       | 1.40099           | 0.579263                          | 0.0216894   |\n",
      "PROGRESS: | 97      | 2m 0s        | 1.4007            | 0.579244                          | 0.0216894   |\n",
      "PROGRESS: | 98      | 2m 1s        | 1.40073           | 0.579207                          | 0.0216894   |\n",
      "PROGRESS: | 99      | 2m 2s        | 1.40058           | 0.579198                          | 0.0216894   |\n",
      "PROGRESS: | 100     | 2m 3s        | 1.40029           | 0.5792                            | 0.0216894   |\n",
      "PROGRESS: +---------+--------------+-------------------+-----------------------------------+-------------+\n",
      "PROGRESS: Optimization Complete: Maximum number of passes through the data reached.\n",
      "PROGRESS: Computing final objective value and training Predictive Error.\n",
      "PROGRESS:        Final objective value: 1.42451\n",
      "PROGRESS:        Final training Predictive Error: 0.579077\n"
     ]
    }
   ],
   "source": [
    "train_data = prepare_data(train_df, binary=True) \n",
    "model = graphlab.ranking_factorization_recommender.create(train_data, target='rating',solver='adagrad',\n",
    "                                                           num_factors=15, max_iterations=100, \n",
    "                                                           verbose=True, binary_target=True,\n",
    "                                                           regularization = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.531227890484\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE:', model.evaluate_rmse(test_data, target='rating')['rmse_overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularisation=1e-3 позволила снизить ошибку модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И как завершающий эксперимент с graphlab create, посмотрим как влияют на качество дополнительные признаки фильмов. Для этого нужно подготовить новую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>imdbID</th>\n",
       "      <th>spanishTitle</th>\n",
       "      <th>imdbPictureURL</th>\n",
       "      <th>year</th>\n",
       "      <th>rtID</th>\n",
       "      <th>rtAllCriticsRating</th>\n",
       "      <th>rtAllCriticsNumReviews</th>\n",
       "      <th>rtAllCriticsNumFresh</th>\n",
       "      <th>...</th>\n",
       "      <th>rtAllCriticsScore</th>\n",
       "      <th>rtTopCriticsRating</th>\n",
       "      <th>rtTopCriticsNumReviews</th>\n",
       "      <th>rtTopCriticsNumFresh</th>\n",
       "      <th>rtTopCriticsNumRotten</th>\n",
       "      <th>rtTopCriticsScore</th>\n",
       "      <th>rtAudienceRating</th>\n",
       "      <th>rtAudienceNumRatings</th>\n",
       "      <th>rtAudienceScore</th>\n",
       "      <th>rtPictureURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>114709</td>\n",
       "      <td>Toy story (juguetes)</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMTMwNDU0...</td>\n",
       "      <td>1995</td>\n",
       "      <td>toy_story</td>\n",
       "      <td>9</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>8.5</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3.7</td>\n",
       "      <td>102338</td>\n",
       "      <td>81</td>\n",
       "      <td>http://content7.flixster.com/movie/10/93/63/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>113497</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMzM5NjE1...</td>\n",
       "      <td>1995</td>\n",
       "      <td>1068044-jumanji</td>\n",
       "      <td>5.6</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>3.2</td>\n",
       "      <td>44587</td>\n",
       "      <td>61</td>\n",
       "      <td>http://content8.flixster.com/movie/56/79/73/56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpy Old Men</td>\n",
       "      <td>107050</td>\n",
       "      <td>Dos viejos gru�ones</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMTI5MTgy...</td>\n",
       "      <td>1993</td>\n",
       "      <td>grumpy_old_men</td>\n",
       "      <td>5.9</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10489</td>\n",
       "      <td>66</td>\n",
       "      <td>http://content6.flixster.com/movie/25/60/25602...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>114885</td>\n",
       "      <td>Esperando un respiro</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMTczMTMy...</td>\n",
       "      <td>1995</td>\n",
       "      <td>waiting_to_exhale</td>\n",
       "      <td>5.6</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>5.5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5666</td>\n",
       "      <td>79</td>\n",
       "      <td>http://content9.flixster.com/movie/10/94/17/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>113041</td>\n",
       "      <td>Vuelve el padre de la novia (Ahora tambi�n abu...</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMTg1NDc2...</td>\n",
       "      <td>1995</td>\n",
       "      <td>father_of_the_bride_part_ii</td>\n",
       "      <td>5.3</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>13761</td>\n",
       "      <td>64</td>\n",
       "      <td>http://content8.flixster.com/movie/25/54/25542...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        title  imdbID  \\\n",
       "0   1                    Toy story  114709   \n",
       "1   2                      Jumanji  113497   \n",
       "2   3               Grumpy Old Men  107050   \n",
       "3   4            Waiting to Exhale  114885   \n",
       "4   5  Father of the Bride Part II  113041   \n",
       "\n",
       "                                        spanishTitle  \\\n",
       "0                               Toy story (juguetes)   \n",
       "1                                            Jumanji   \n",
       "2                                Dos viejos gru�ones   \n",
       "3                               Esperando un respiro   \n",
       "4  Vuelve el padre de la novia (Ahora tambi�n abu...   \n",
       "\n",
       "                                      imdbPictureURL  year  \\\n",
       "0  http://ia.media-imdb.com/images/M/MV5BMTMwNDU0...  1995   \n",
       "1  http://ia.media-imdb.com/images/M/MV5BMzM5NjE1...  1995   \n",
       "2  http://ia.media-imdb.com/images/M/MV5BMTI5MTgy...  1993   \n",
       "3  http://ia.media-imdb.com/images/M/MV5BMTczMTMy...  1995   \n",
       "4  http://ia.media-imdb.com/images/M/MV5BMTg1NDc2...  1995   \n",
       "\n",
       "                          rtID rtAllCriticsRating rtAllCriticsNumReviews  \\\n",
       "0                    toy_story                  9                     73   \n",
       "1              1068044-jumanji                5.6                     28   \n",
       "2               grumpy_old_men                5.9                     36   \n",
       "3            waiting_to_exhale                5.6                     25   \n",
       "4  father_of_the_bride_part_ii                5.3                     19   \n",
       "\n",
       "  rtAllCriticsNumFresh                        ...                          \\\n",
       "0                   73                        ...                           \n",
       "1                   13                        ...                           \n",
       "2                   24                        ...                           \n",
       "3                   14                        ...                           \n",
       "4                    9                        ...                           \n",
       "\n",
       "  rtAllCriticsScore rtTopCriticsRating rtTopCriticsNumReviews  \\\n",
       "0               100                8.5                     17   \n",
       "1                46                5.8                      5   \n",
       "2                66                  7                      6   \n",
       "3                56                5.5                     11   \n",
       "4                47                5.4                      5   \n",
       "\n",
       "  rtTopCriticsNumFresh rtTopCriticsNumRotten rtTopCriticsScore  \\\n",
       "0                   17                     0               100   \n",
       "1                    2                     3                40   \n",
       "2                    5                     1                83   \n",
       "3                    5                     6                45   \n",
       "4                    1                     4                20   \n",
       "\n",
       "  rtAudienceRating rtAudienceNumRatings rtAudienceScore  \\\n",
       "0              3.7               102338              81   \n",
       "1              3.2                44587              61   \n",
       "2              3.2                10489              66   \n",
       "3              3.3                 5666              79   \n",
       "4                3                13761              64   \n",
       "\n",
       "                                        rtPictureURL  \n",
       "0  http://content7.flixster.com/movie/10/93/63/10...  \n",
       "1  http://content8.flixster.com/movie/56/79/73/56...  \n",
       "2  http://content6.flixster.com/movie/25/60/25602...  \n",
       "3  http://content9.flixster.com/movie/10/94/17/10...  \n",
       "4  http://content8.flixster.com/movie/25/54/25542...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame_data = defaultdict(list)\n",
    "movie_data = defaultdict(list)\n",
    "for user, data in train_df.items():\n",
    "    frame_data['item_id'] += list(data['movieID'])\n",
    "    frame_data['rating'] += list(data['rating'])\n",
    "    frame_data['user_id'] += ([user] * len(data['movieID']))\n",
    "    \n",
    "genres_df = pd.read_csv('data/movie_genres.dat', sep='\\t')\n",
    "genres_df.head()\n",
    "\n",
    "for movie in frame_data['item_id']:\n",
    "    data = movies_df[movies_df['id']==movie]\n",
    "    movie_data['item_id'].append(movie)\n",
    "    movie_data['title'].append(data['title'])\n",
    "    movie_data['year'].append(data['year'])\n",
    "    for genre in genres_df[genres_df['movieID']==movie]['genre']:\n",
    "        movie_data['ganres'].append({movie:genre})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "genres_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Категориальные и разреженные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Для этой части задания вам необходимо будет создать несколько выборок с разным набором признаков:\n",
    " - id-пользователя + id-фильма\n",
    " - id-пользователя + id-фильма + оценки пользователя за каждый просмотренный фильм\n",
    " - id-пользователя + id-фильма + жанры фильма\n",
    " - id-пользователя + id-фильма + жанры фильма + киноперсоны\n",
    " - набор признаков по вашему усмотрению (отличный от вышеперечисленных)\n",
    " \n",
    "О том, как задавать выборки для конкретной библиотеки можно почитать в разделе \"**В помощь**\".\n",
    "\n",
    "Со всеми полученными выборками проделайте следующие эксперименты:\n",
    " - Обучите **квадратичную модель** c помощью [Vopwal Wabbit](https://github.com/JohnLangford/vowpal_wabbit/wiki).\n",
    " - Постройте предсказания оценок при помощи факторизационных машин, используя библиотеку [LibFM](http://libfm.org). Попробуйте различные режимы работы: ALS, MCMC.\n",
    " \n",
    "После этого:\n",
    " - Приведите сравнение качества всех моделей, используя две описанные метрики.\n",
    " - Какой набор признаков оказался более удачным? Как можно это обосновать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vopwal Wabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id-пользователя + id-фильма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_first_sample(df, file_name):\n",
    "    results = []\n",
    "    with open(file_name, 'w') as fsampl:\n",
    "        for user, data in df.items():\n",
    "            for row in data.iterrows():\n",
    "                example = '{0} |f user:{1} movie:{2}\\n'.format(row[1]['rating'], user, row[1]['movieID'])\n",
    "                fsampl.write(example)\n",
    "                results.append(row[1]['rating'])\n",
    "        return results\n",
    "    \n",
    "get_first_sample(train_df, 'first_train.txt')\n",
    "test_results = get_first_sample(test_df, 'first_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: :: \n",
      "WARNING: duplicate namespace interactions were found. Removed: 4278.\n",
      "You can use --leave_duplicate_interactions to disable this behaviour.\n",
      "final_regressor = vw.model\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = first_train.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "16.000000 16.000000            1            1.0   4.0000   0.0000        6\n",
      "8.000000 0.000000            2            2.0   4.0000   4.0000        6\n",
      "6.798813 5.597626            4            4.0   4.0000   0.6916        6\n",
      "4.705214 2.611616            8            8.0   3.5000   1.3001        6\n",
      "3.395658 2.086102           16           16.0   2.0000   2.0602        6\n",
      "2.325738 1.255818           32           32.0   3.0000   3.5978        6\n",
      "1.465429 0.605121           64           64.0   4.0000   3.3284        6\n",
      "1.076400 0.687371          128          128.0   4.0000   3.4549        6\n",
      "0.758605 0.440809          256          256.0   3.5000   3.7535        6\n",
      "0.752277 0.745950          512          512.0   3.0000   3.4068        6\n",
      "0.908621 1.064965         1024         1024.0   2.5000   3.7210        6\n",
      "0.992359 1.076096         2048         2048.0   5.0000   3.7524        6\n",
      "0.834054 0.675749         4096         4096.0   4.0000   3.7368        6\n",
      "0.840800 0.847547         8192         8192.0   2.0000   3.2748        6\n",
      "0.961131 1.081461        16384        16384.0   3.0000   3.6266        6\n",
      "0.898496 0.835861        32768        32768.0   4.0000   3.5965        6\n",
      "0.872821 0.847147        65536        65536.0   5.0000   3.5776        6\n",
      "0.891196 0.909570       131072       131072.0   2.0000   3.1150        6\n",
      "0.889723 0.888251       262144       262144.0   2.5000   3.7395        6\n",
      "0.914148 0.938573       524288       524288.0   3.0000   3.3086        6\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 849259\n",
      "passes used = 1\n",
      "weighted example sum = 849259.000000\n",
      "weighted label sum = 2918658.500000\n",
      "average loss = 0.944709\n",
      "best constant = 3.436712\n",
      "total feature number = 5095554\n"
     ]
    }
   ],
   "source": [
    "!vw first_train.txt -q :: -f vw.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: model file has set of {-q, --cubic, --interactions} settings stored, but they'll be OVERRIDEN by set of {-q, --cubic, --interactions} settings from command line.\n",
      "creating quadratic features for pairs: :: \n",
      "WARNING: duplicate namespace interactions were found. Removed: 4278.\n",
      "You can use --leave_duplicate_interactions to disable this behaviour.\n",
      "only testing\n",
      "predictions = first_test_result.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = first_test.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.096111 0.096111            1            1.0   3.0000   3.3100        6\n",
      "0.281105 0.466098            2            2.0   4.0000   3.3173        6\n",
      "0.153014 0.024924            4            4.0   3.5000   3.3705        6\n",
      "0.229506 0.305998            8            8.0   3.0000   3.4183        6\n",
      "0.456294 0.683081           16           16.0   3.5000   3.3188        6\n",
      "0.680011 0.903728           32           32.0   5.0000   3.6031        6\n",
      "0.780809 0.881607           64           64.0   5.0000   3.3124        6\n",
      "0.908739 1.036668          128          128.0   4.5000   3.7033        6\n",
      "0.968906 1.029072          256          256.0   5.0000   3.4349        6\n",
      "1.004427 1.039948          512          512.0   0.5000   3.4820        6\n",
      "1.053208 1.101990         1024         1024.0   3.0000   3.6259        6\n",
      "1.025614 0.998019         2048         2048.0   4.5000   3.2927        6\n",
      "1.006457 0.987301         4096         4096.0   4.0000   3.3432        6\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 6339\n",
      "passes used = 1\n",
      "weighted example sum = 6339.000000\n",
      "weighted label sum = 22840.500000\n",
      "average loss = 1.031002\n",
      "best constant = 3.603171\n",
      "total feature number = 38034\n"
     ]
    }
   ],
   "source": [
    "! vw  first_test.txt -t -q :: -p first_test_result.txt -i vw.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, теперь можно и измерить качество полученной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.015\n"
     ]
    }
   ],
   "source": [
    "def read_results(result_file):\n",
    "    with open(result_file, 'r') as fin:\n",
    "        results = fin.read().split()\n",
    "    return map(float, results)\n",
    "        \n",
    "def calculate_RMSE(real_results, test_results):\n",
    "    rmse = 0.0\n",
    "    for real, test in zip(real_results, test_results):\n",
    "        rmse += (real-test)**2\n",
    "    return (rmse / len(real_results))**0.5\n",
    "\n",
    "print 'RMSE: {:.3f}'.format(calculate_RMSE(test_results, read_results('first_test_result.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id-пользователя + id-фильма + оценки пользователя за каждый просмотренный фильм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если брать все оценки все пользователей, тренировочный файл получается огромный (до нескольких Gb). Так и не дождалась, пока модель на нем обучтся:( Возьмем только первые 10 рейтингов по величине, то есть будем учитывать только самые любимые фильмы каждого пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_first_sample(df, file_name):\n",
    "    results = []\n",
    "    with open(file_name, 'w') as fsampl:\n",
    "        for user, data in df.items():\n",
    "            ratings = ' '.join(['ranked-{0}:{1}'.format(movie,rating) for movie, rating in \n",
    "                                sorted(zip(list(data['movieID']), list(data['rating'])), \n",
    "                                       key=lambda x: x[1], reverse=True)[:10]])\n",
    "            for row in data.iterrows():\n",
    "                example = '{0} |f user:{1} movie:{2} {3}\\n'.format(row[1]['rating'], user, int(row[1]['movieID']), ratings)\n",
    "                fsampl.write(example)\n",
    "                results.append(row[1]['rating'])\n",
    "        return results\n",
    "    \n",
    "get_first_sample(train_df, 'second_train.txt')\n",
    "test_results = get_first_sample(test_df, 'second_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: :: \n",
      "WARNING: duplicate namespace interactions were found. Removed: 4278.\n",
      "You can use --leave_duplicate_interactions to disable this behaviour.\n",
      "final_regressor = vw.model\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = second_train.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "16.000000 16.000000            1            1.0   4.0000   0.0000       91\n",
      "8.000000 0.000000            2            2.0   4.0000   4.0000       91\n",
      "4.752882 1.505764            4            4.0   4.0000   2.3382       91\n",
      "2.668049 0.583216            8            8.0   3.5000   2.2287       91\n",
      "2.371038 2.074027           16           16.0   2.0000   2.2080       91\n",
      "2.108972 1.846907           32           32.0   3.0000   3.7544       91\n",
      "1.302356 0.495741           64           64.0   4.0000   2.9349       91\n",
      "1.043651 0.784945          128          128.0   4.0000   3.7971       91\n",
      "0.781952 0.520253          256          256.0   3.5000   4.0223       91\n",
      "0.796794 0.811636          512          512.0   3.0000   3.3103       91\n",
      "0.803124 0.809455         1024         1024.0   2.5000   4.3046       91\n",
      "0.811913 0.820702         2048         2048.0   5.0000   4.3334       91\n",
      "0.721524 0.631136         4096         4096.0   4.0000   3.7464       91\n",
      "0.771329 0.821133         8192         8192.0   2.0000   3.6888       91\n",
      "0.902261 1.033192        16384        16384.0   3.0000   3.2334       91\n",
      "0.861971 0.821681        32768        32768.0   4.0000   3.9546       91\n",
      "0.808357 0.754743        65536        65536.0   5.0000   3.8244       91\n",
      "0.794886 0.781416       131072       131072.0   2.0000   3.3544       91\n",
      "0.786471 0.778056       262144       262144.0   2.5000   3.5034       91\n",
      "0.784962 0.783453       524288       524288.0   3.0000   2.8995       91\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 849259\n",
      "passes used = 1\n",
      "weighted example sum = 849259.000000\n",
      "weighted label sum = 2918658.500000\n",
      "average loss = 0.790098\n",
      "best constant = 3.436712\n",
      "total feature number = 77282569\n"
     ]
    }
   ],
   "source": [
    "!vw second_train.txt -q :: -f vw.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: model file has set of {-q, --cubic, --interactions} settings stored, but they'll be OVERRIDEN by set of {-q, --cubic, --interactions} settings from command line.\n",
      "creating quadratic features for pairs: :: \n",
      "WARNING: duplicate namespace interactions were found. Removed: 4278.\n",
      "You can use --leave_duplicate_interactions to disable this behaviour.\n",
      "only testing\n",
      "predictions = second_test_result.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = second_test.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "4.646172 4.646172            1            1.0   3.0000   0.8445       21\n",
      "7.291660 9.937148            2            2.0   4.0000   0.8477       21\n",
      "5.968593 4.645526            4            4.0   3.5000   5.0000       21\n",
      "5.265547 4.562500            8            8.0   3.0000   5.0000       21\n",
      "4.759983 4.254420           16           16.0   3.5000   0.8860       21\n",
      "7.036342 9.312700           32           32.0   5.0000   1.5436       21\n",
      "6.754849 6.473357           64           64.0   5.0000   0.8931       21\n",
      "6.745057 6.735265          128          128.0   4.5000   5.0000       21\n",
      "6.734097 6.723138          256          256.0   5.0000   1.3215       21\n",
      "6.691766 6.649434          512          512.0   0.5000   0.9147       21\n",
      "6.572120 6.452474         1024         1024.0   3.0000   1.0961       21\n",
      "6.443410 6.314700         2048         2048.0   4.5000   0.8104       21\n",
      "6.461484 6.479558         4096         4096.0   4.0000   5.0000       21\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 6339\n",
      "passes used = 1\n",
      "weighted example sum = 6339.000000\n",
      "weighted label sum = 22840.500000\n",
      "average loss = 6.523649\n",
      "best constant = 3.603171\n",
      "total feature number = 133119\n"
     ]
    }
   ],
   "source": [
    "! vw  second_test.txt -t -q :: -p second_test_result.txt -i vw.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.554\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE: {:.3f}'.format(calculate_RMSE(test_results, read_results('second_test_result.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по данной метрики, такая выборка не подходит для данной задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id-пользователя + id-фильма + жанры фильма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genres_df = pd.read_csv('data/movie_genres.dat', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_third_sample(df, file_name):\n",
    "    results = []\n",
    "    with open(file_name, 'w') as fsampl:\n",
    "        for user, data in df.items():\n",
    "            for row in data.iterrows():\n",
    "                movie = int(row[1]['movieID'])\n",
    "                genres = ' '.join([genre+':1.0' for genre in genres_df[genres_df['movieID']==movie]['genre']])\n",
    "                example = '{0} |f user:{1} movie:{2} {3}\\n'.format(row[1]['rating'], user, movie, genres)\n",
    "                fsampl.write(example)\n",
    "                results.append(row[1]['rating'])\n",
    "        return results\n",
    "    \n",
    "get_third_sample(train_df, 'third_train.txt')\n",
    "test_results = get_third_sample(test_df, 'third_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: :: \n",
      "WARNING: duplicate namespace interactions were found. Removed: 4278.\n",
      "You can use --leave_duplicate_interactions to disable this behaviour.\n",
      "final_regressor = vw.model\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = third_train.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "16.000000 16.000000            1            1.0   4.0000   0.0000       21\n",
      "8.000000 0.000000            2            2.0   4.0000   4.0000       28\n",
      "4.062500 0.125000            4            4.0   4.0000   4.0000       36\n",
      "3.445129 2.827758            8            8.0   3.5000   3.1284       45\n",
      "3.320817 3.196505           16           16.0   2.0000   2.6723       28\n",
      "2.550123 1.779429           32           32.0   3.0000   3.2398       28\n",
      "2.027723 1.505324           64           64.0   4.0000   3.4296       28\n",
      "1.467080 0.906437          128          128.0   4.0000   4.4414       28\n",
      "1.125848 0.784615          256          256.0   3.5000   4.4391       28\n",
      "0.959279 0.792710          512          512.0   3.0000   3.1286       15\n",
      "1.005408 1.051537         1024         1024.0   2.5000   3.7258       15\n",
      "0.992259 0.979110         2048         2048.0   5.0000   5.0000       28\n",
      "0.812699 0.633139         4096         4096.0   4.0000   4.2783       21\n",
      "0.831259 0.849820         8192         8192.0   2.0000   2.7607       15\n",
      "0.938379 1.045499        16384        16384.0   3.0000   3.5819       15\n",
      "0.868213 0.798047        32768        32768.0   4.0000   3.5317       28\n",
      "0.822118 0.776023        65536        65536.0   5.0000   3.5901       21\n",
      "0.835458 0.848797       131072       131072.0   2.0000   2.5745       21\n",
      "0.834106 0.832753       262144       262144.0   2.5000   3.2452       21\n",
      "0.855611 0.877115       524288       524288.0   3.0000   3.5038       21\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 849259\n",
      "passes used = 1\n",
      "weighted example sum = 849259.000000\n",
      "weighted label sum = 2918658.500000\n",
      "average loss = 0.880863\n",
      "best constant = 3.436712\n",
      "total feature number = 16365134\n"
     ]
    }
   ],
   "source": [
    "!vw third_train.txt -q :: -f vw.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: model file has set of {-q, --cubic, --interactions} settings stored, but they'll be OVERRIDEN by set of {-q, --cubic, --interactions} settings from command line.\n",
      "creating quadratic features for pairs: :: \n",
      "WARNING: duplicate namespace interactions were found. Removed: 4278.\n",
      "You can use --leave_duplicate_interactions to disable this behaviour.\n",
      "only testing\n",
      "predictions = third_test_result.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = third_test.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.026550 0.026550            1            1.0   3.0000   3.1629       10\n",
      "0.388303 0.750057            2            2.0   4.0000   3.1339       28\n",
      "0.243537 0.098771            4            4.0   3.5000   3.3987       36\n",
      "0.193888 0.144239            8            8.0   3.0000   3.0385       45\n",
      "0.469969 0.746049           16           16.0   3.5000   3.8798       21\n",
      "0.535967 0.601966           32           32.0   5.0000   3.8420       28\n",
      "0.744027 0.952087           64           64.0   5.0000   3.7850       10\n",
      "0.881777 1.019528          128          128.0   4.5000   3.5720       15\n",
      "0.960172 1.038566          256          256.0   5.0000   4.1234       28\n",
      "1.008466 1.056761          512          512.0   0.5000   3.7698       10\n",
      "1.009145 1.009823         1024         1024.0   3.0000   3.4949       15\n",
      "0.989738 0.970332         2048         2048.0   4.5000   3.7568       28\n",
      "0.981188 0.972639         4096         4096.0   4.0000   3.5684       15\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 6339\n",
      "passes used = 1\n",
      "weighted example sum = 6339.000000\n",
      "weighted label sum = 22840.500000\n",
      "average loss = 0.996368\n",
      "best constant = 3.603171\n",
      "total feature number = 126510\n"
     ]
    }
   ],
   "source": [
    "! vw  third_test.txt -t -q :: -p third_test_result.txt -i vw.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.998\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE: {:.3f}'.format(calculate_RMSE(test_results, read_results('third_test_result.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жанры повышают качество модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id-пользователя + id-фильма + жанры фильма + киноперсоны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actors_df = pd.read_csv('data/movie_actors.dat', sep='\\t') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_fourth_sample(df, file_name):\n",
    "    results = []\n",
    "    with open(file_name, 'w') as fsampl:\n",
    "        for user, data in df.items():\n",
    "            for row in data.iterrows():\n",
    "                movie = int(row[1]['movieID'])\n",
    "                genres = ' '.join([genre+':1.0' for genre in genres_df[genres_df['movieID']==movie]['genre']])\n",
    "                actors = ' '.join(['{}:1.0'.format(actor) for actor in actors_df[actors_df['movieID']==movie]['actorID']])\n",
    "                example = '{0} |f user:{1} movie:{2} {3} {4}\\n'.format(row[1]['rating'], user, movie, actors, genres)\n",
    "                fsampl.write(example)\n",
    "                results.append(row[1]['rating'])\n",
    "        return results\n",
    "    \n",
    "get_fourth_sample(train_df, 'fourth_train.txt')\n",
    "test_results = get_fourth_sample(test_df, 'fourth_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: :: \n",
      "WARNING: duplicate namespace interactions were found. Removed: 4278.\n",
      "You can use --leave_duplicate_interactions to disable this behaviour.\n",
      "final_regressor = vw.model\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = fourth_train.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "16.000000 16.000000            1            1.0   4.0000   0.0000      231\n",
      "8.000000 0.000000            2            2.0   4.0000   4.0000     1128\n",
      "6.542069 5.084138            4            4.0   4.0000   0.8486      231\n",
      "4.708262 2.874456            8            8.0   3.5000   4.0000      231\n",
      "3.873983 3.039704           16           16.0   2.0000   0.1958      120\n",
      "4.559501 5.245018           32           32.0   3.0000   5.0000     4851\n",
      "5.204352 5.849202           64           64.0   4.0000   0.0000       91\n",
      "6.337539 7.470726          128          128.0   4.0000   0.0000      253\n",
      "6.499887 6.662236          256          256.0   3.5000   5.0000      253\n",
      "6.619944 6.740001          512          512.0   3.0000   5.0000      351\n",
      "6.006162 5.392380         1024         1024.0   2.5000   5.0000      171\n",
      "5.523387 5.040613         2048         2048.0   5.0000   4.4200      171\n",
      "4.809299 4.095210         4096         4096.0   4.0000   5.0000     1326\n",
      "3.911112 3.012926         8192         8192.0   2.0000   4.2132      435\n",
      "3.396355 2.881598        16384        16384.0   3.0000   4.1869     2556\n",
      "2.657614 1.918874        32768        32768.0   4.0000   3.6484      276\n",
      "2.035633 1.413651        65536        65536.0   5.0000   1.6339    10440\n",
      "1.647894 1.260156       131072       131072.0   2.0000   2.7006      435\n",
      "1.373739 1.099584       262144       262144.0   2.5000   3.2003      300\n",
      "1.174498 0.975256       524288       524288.0   3.0000   3.7444      406\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 849259\n",
      "passes used = 1\n",
      "weighted example sum = 849259.000000\n",
      "weighted label sum = 2918658.500000\n",
      "average loss = 1.088554\n",
      "best constant = 3.436712\n",
      "total feature number = 675126989\n"
     ]
    }
   ],
   "source": [
    "!vw fourth_train.txt -q :: -f vw.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: model file has set of {-q, --cubic, --interactions} settings stored, but they'll be OVERRIDEN by set of {-q, --cubic, --interactions} settings from command line.\n",
      "creating quadratic features for pairs: :: \n",
      "WARNING: duplicate namespace interactions were found. Removed: 4278.\n",
      "You can use --leave_duplicate_interactions to disable this behaviour.\n",
      "only testing\n",
      "predictions = fourth_test_result.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = fourth_test.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.788322 0.788322            1            1.0   3.0000   3.8879     3160\n",
      "0.589952 0.391583            2            2.0   4.0000   3.3742       45\n",
      "0.718040 0.846128            4            4.0   3.5000   2.2037      171\n",
      "0.615429 0.512818            8            8.0   3.0000   2.8281      300\n",
      "0.706269 0.797109           16           16.0   3.5000   4.0778      465\n",
      "0.717080 0.727892           32           32.0   5.0000   3.3696     2211\n",
      "0.873704 1.030328           64           64.0   5.0000   3.3881       91\n",
      "0.972330 1.070955          128          128.0   4.5000   4.2138     1128\n",
      "0.985792 0.999254          256          256.0   5.0000   4.7229     4851\n",
      "0.955655 0.925517          512          512.0   0.5000   3.4647       91\n",
      "0.984714 1.013774         1024         1024.0   3.0000   4.2717       66\n",
      "0.992294 0.999873         2048         2048.0   4.5000   3.7423     1275\n",
      "1.014932 1.037571         4096         4096.0   4.0000   4.1019      378\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 6339\n",
      "passes used = 1\n",
      "weighted example sum = 6339.000000\n",
      "weighted label sum = 22840.500000\n",
      "average loss = 1.031899\n",
      "best constant = 3.603171\n",
      "total feature number = 5353017\n"
     ]
    }
   ],
   "source": [
    "! vw  fourth_test.txt -t -q :: -p fourth_test_result.txt -i vw.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.016\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE: {:.3f}'.format(calculate_RMSE(test_results, read_results('fourth_test_result.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Актеры никак не повлияли на качество модели. Можно обойтись и без них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## id-пользователя + id-фильма + год + страна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_df = pd.DataFrame.from_csv('data/movie_countries.dat', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_my_sample(df, file_name):\n",
    "    results = []\n",
    "    lines = []\n",
    "    with open(file_name, 'w') as fsampl:\n",
    "        for user, data in df.items():\n",
    "            for row in data.iterrows():\n",
    "                movie = int(row[1]['movieID'])\n",
    "                country = country_df.loc[movie]['country']\n",
    "                year = movies_df.iloc[movies[movie]]['year']\n",
    "                example = '{0} |f user:{1} movie:{2} year:{3} {4}'.format(row[1]['rating'], user, \n",
    "                                                                   movie, year, country)\n",
    "                lines.append(example)\n",
    "                results.append(row[1]['rating'])\n",
    "        fsampl.write('\\n'.join(lines))\n",
    "        return results\n",
    "    \n",
    "get_my_sample(train_df, 'my_train.txt')\n",
    "test_results = get_my_sample(test_df, 'my_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating quadratic features for pairs: :: \n",
      "WARNING: duplicate namespace interactions were found. Removed: 4278.\n",
      "You can use --leave_duplicate_interactions to disable this behaviour.\n",
      "final_regressor = vw.model\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = my_train.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "16.000000 16.000000            1            1.0   4.0000   0.0000       15\n",
      "8.000000 0.000000            2            2.0   4.0000   4.0000       15\n",
      "6.098874 4.197749            4            4.0   4.0000   1.1460       15\n",
      "3.583344 1.067814            8            8.0   3.5000   2.0511       15\n",
      "2.507625 1.431906           16           16.0   2.0000   2.5980       15\n",
      "1.808298 1.108972           32           32.0   3.0000   4.0162       15\n",
      "1.299444 0.790589           64           64.0   4.0000   3.2998       15\n",
      "1.046178 0.792912          128          128.0   4.0000   3.5218       15\n",
      "0.776925 0.507672          256          256.0   3.5000   3.8296       15\n",
      "0.778909 0.780893          512          512.0   3.0000   3.3972       15\n",
      "0.802356 0.825804         1024         1024.0   2.5000   3.8750       15\n",
      "0.865717 0.929078         2048         2048.0   5.0000   4.1009       15\n",
      "0.762328 0.658938         4096         4096.0   4.0000   3.6583       15\n",
      "0.785016 0.807704         8192         8192.0   2.0000   3.4553       15\n",
      "0.910253 1.035491        16384        16384.0   3.0000   3.5347       15\n",
      "0.862957 0.815661        32768        32768.0   4.0000   3.5769       15\n",
      "0.828591 0.794224        65536        65536.0   5.0000   3.6020       15\n",
      "0.851266 0.873942       131072       131072.0   2.0000   2.9513       15\n",
      "0.856372 0.861478       262144       262144.0   2.5000   3.6795       15\n",
      "0.882665 0.908958       524288       524288.0   3.0000   3.1997       15\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 849259\n",
      "passes used = 1\n",
      "weighted example sum = 849259.000000\n",
      "weighted label sum = 2918658.500000\n",
      "average loss = 0.914074\n",
      "best constant = 3.436712\n",
      "total feature number = 12816649\n"
     ]
    }
   ],
   "source": [
    "!vw my_train.txt -q :: -f vw.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: model file has set of {-q, --cubic, --interactions} settings stored, but they'll be OVERRIDEN by set of {-q, --cubic, --interactions} settings from command line.\n",
      "creating quadratic features for pairs: :: \n",
      "WARNING: duplicate namespace interactions were found. Removed: 4278.\n",
      "You can use --leave_duplicate_interactions to disable this behaviour.\n",
      "only testing\n",
      "predictions = my_test_result.txt\n",
      "Num weight bits = 18\n",
      "learning rate = 10\n",
      "initial_t = 1\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = my_test.txt\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.103268 0.103268            1            1.0   3.0000   3.3214       15\n",
      "0.268555 0.433841            2            2.0   4.0000   3.3413       15\n",
      "0.149584 0.030614            4            4.0   3.5000   3.7473       21\n",
      "0.238285 0.326985            8            8.0   3.0000   3.4107       15\n",
      "0.456621 0.674957           16           16.0   3.5000   3.3414       15\n",
      "0.651561 0.846501           32           32.0   5.0000   3.5660       15\n",
      "0.739690 0.827819           64           64.0   5.0000   3.3145       15\n",
      "0.872303 1.004917          128          128.0   4.5000   3.6182       15\n",
      "0.973935 1.075566          256          256.0   5.0000   3.4512       15\n",
      "0.989039 1.004143          512          512.0   0.5000   3.8215       15\n",
      "1.035647 1.082256         1024         1024.0   3.0000   3.5913       15\n",
      "1.008465 0.981282         2048         2048.0   4.5000   3.3176       15\n",
      "0.980700 0.952936         4096         4096.0   4.0000   3.3437       15\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 6339\n",
      "passes used = 1\n",
      "weighted example sum = 6339.000000\n",
      "weighted label sum = 22840.500000\n",
      "average loss = 1.004464\n",
      "best constant = 3.603171\n",
      "total feature number = 95803\n"
     ]
    }
   ],
   "source": [
    "! vw  my_test.txt -t -q :: -p my_test_result.txt -i vw.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.002\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE: {:.3f}'.format(calculate_RMSE(test_results, read_results('my_test_result.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Страны и года немного повысили качество модели, но жанры все равно работают лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIbFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь пришла очередь библиотеки LIbFM. Действовать будем аналогично. Только закодируем данные в соответствующем формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "movies_id = {}\n",
    "for movie in movies_df['id'].unique():\n",
    "    movies_id[movie] = len(movies_id) + start_index\n",
    "start_index += len(movies_id)\n",
    "users_id = {}\n",
    "for user in rated_movies['userID'].unique():\n",
    "    users_id[user] = len(users_id) + start_index\n",
    "start_index +=len(users_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id-пользователя + id-фильма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_first_sample(df, file_name):\n",
    "    results = []\n",
    "    with open(file_name, 'w') as fsampl:\n",
    "        for user, data in df.items():\n",
    "            for row in data.iterrows():\n",
    "                example = '{0} {1}:1.0 {2}:1.0\\n'.format(row[1]['rating'], users_id[user], movies_id[row[1]['movieID']])\n",
    "                fsampl.write(example)\n",
    "                results.append(row[1]['rating'])\n",
    "        return results\n",
    "    \n",
    "get_first_sample(train_df, 'first_train.txt')\n",
    "test_results = get_first_sample(test_df, 'first_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=1698518\tnum_features=12310\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=12678\tnum_features=12310\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.927721\tTest=0.966066\n",
      "#Iter=  1\tTrain=0.825262\tTest=0.909677\n",
      "#Iter=  2\tTrain=0.803978\tTest=0.88292\n",
      "#Iter=  3\tTrain=0.797963\tTest=0.871065\n",
      "#Iter=  4\tTrain=0.790678\tTest=0.864292\n",
      "#Iter=  5\tTrain=0.781681\tTest=0.859693\n",
      "#Iter=  6\tTrain=0.774546\tTest=0.855662\n",
      "#Iter=  7\tTrain=0.76886\tTest=0.851957\n",
      "#Iter=  8\tTrain=0.76242\tTest=0.848541\n",
      "#Iter=  9\tTrain=0.755235\tTest=0.845441\n",
      "#Iter= 10\tTrain=0.749478\tTest=0.843028\n",
      "#Iter= 11\tTrain=0.744166\tTest=0.8403\n",
      "#Iter= 12\tTrain=0.739706\tTest=0.83828\n",
      "#Iter= 13\tTrain=0.735564\tTest=0.836404\n",
      "#Iter= 14\tTrain=0.73197\tTest=0.834832\n",
      "#Iter= 15\tTrain=0.729891\tTest=0.833153\n",
      "#Iter= 16\tTrain=0.728218\tTest=0.831497\n",
      "#Iter= 17\tTrain=0.727221\tTest=0.829474\n",
      "#Iter= 18\tTrain=0.7265\tTest=0.828014\n",
      "#Iter= 19\tTrain=0.72588\tTest=0.82688\n",
      "#Iter= 20\tTrain=0.72545\tTest=0.82616\n",
      "#Iter= 21\tTrain=0.724982\tTest=0.825223\n",
      "#Iter= 22\tTrain=0.72438\tTest=0.824496\n",
      "#Iter= 23\tTrain=0.723501\tTest=0.823608\n",
      "#Iter= 24\tTrain=0.722526\tTest=0.822917\n",
      "#Iter= 25\tTrain=0.721403\tTest=0.822263\n",
      "#Iter= 26\tTrain=0.720744\tTest=0.821421\n",
      "#Iter= 27\tTrain=0.720066\tTest=0.820749\n",
      "#Iter= 28\tTrain=0.719909\tTest=0.820026\n",
      "#Iter= 29\tTrain=0.719111\tTest=0.819435\n",
      "#Iter= 30\tTrain=0.719011\tTest=0.819172\n",
      "#Iter= 31\tTrain=0.718376\tTest=0.818997\n",
      "#Iter= 32\tTrain=0.718593\tTest=0.818531\n",
      "#Iter= 33\tTrain=0.718109\tTest=0.818141\n",
      "#Iter= 34\tTrain=0.717766\tTest=0.817717\n",
      "#Iter= 35\tTrain=0.717149\tTest=0.817235\n",
      "#Iter= 36\tTrain=0.716377\tTest=0.816986\n",
      "#Iter= 37\tTrain=0.715373\tTest=0.816698\n",
      "#Iter= 38\tTrain=0.714618\tTest=0.81659\n",
      "#Iter= 39\tTrain=0.713084\tTest=0.816201\n",
      "#Iter= 40\tTrain=0.711672\tTest=0.815986\n",
      "#Iter= 41\tTrain=0.71048\tTest=0.815702\n",
      "#Iter= 42\tTrain=0.70952\tTest=0.815475\n",
      "#Iter= 43\tTrain=0.708634\tTest=0.815267\n",
      "#Iter= 44\tTrain=0.707843\tTest=0.815051\n",
      "#Iter= 45\tTrain=0.707422\tTest=0.814877\n",
      "#Iter= 46\tTrain=0.707167\tTest=0.814592\n",
      "#Iter= 47\tTrain=0.707011\tTest=0.814436\n",
      "#Iter= 48\tTrain=0.706682\tTest=0.814153\n",
      "#Iter= 49\tTrain=0.706173\tTest=0.813858\n",
      "#Iter= 50\tTrain=0.706196\tTest=0.813697\n",
      "#Iter= 51\tTrain=0.70606\tTest=0.813562\n",
      "#Iter= 52\tTrain=0.706467\tTest=0.813463\n",
      "#Iter= 53\tTrain=0.706075\tTest=0.813343\n",
      "#Iter= 54\tTrain=0.70599\tTest=0.813254\n",
      "#Iter= 55\tTrain=0.705712\tTest=0.813034\n",
      "#Iter= 56\tTrain=0.70539\tTest=0.812925\n",
      "#Iter= 57\tTrain=0.705917\tTest=0.812743\n",
      "#Iter= 58\tTrain=0.705597\tTest=0.812623\n",
      "#Iter= 59\tTrain=0.705517\tTest=0.812413\n",
      "#Iter= 60\tTrain=0.705722\tTest=0.812269\n",
      "#Iter= 61\tTrain=0.70587\tTest=0.812004\n",
      "#Iter= 62\tTrain=0.7058\tTest=0.811991\n",
      "#Iter= 63\tTrain=0.705732\tTest=0.811918\n",
      "#Iter= 64\tTrain=0.705894\tTest=0.811823\n",
      "#Iter= 65\tTrain=0.705809\tTest=0.811782\n",
      "#Iter= 66\tTrain=0.705711\tTest=0.811655\n",
      "#Iter= 67\tTrain=0.705897\tTest=0.81166\n",
      "#Iter= 68\tTrain=0.705847\tTest=0.811548\n",
      "#Iter= 69\tTrain=0.705726\tTest=0.811411\n",
      "#Iter= 70\tTrain=0.705886\tTest=0.81133\n",
      "#Iter= 71\tTrain=0.705784\tTest=0.811305\n",
      "#Iter= 72\tTrain=0.705992\tTest=0.811261\n",
      "#Iter= 73\tTrain=0.705533\tTest=0.811229\n",
      "#Iter= 74\tTrain=0.705687\tTest=0.811153\n",
      "#Iter= 75\tTrain=0.705587\tTest=0.811094\n",
      "#Iter= 76\tTrain=0.70571\tTest=0.811095\n",
      "#Iter= 77\tTrain=0.706115\tTest=0.811061\n",
      "#Iter= 78\tTrain=0.70588\tTest=0.811008\n",
      "#Iter= 79\tTrain=0.705722\tTest=0.810915\n",
      "#Iter= 80\tTrain=0.70601\tTest=0.810885\n",
      "#Iter= 81\tTrain=0.705632\tTest=0.810897\n",
      "#Iter= 82\tTrain=0.705603\tTest=0.810807\n",
      "#Iter= 83\tTrain=0.705986\tTest=0.810684\n",
      "#Iter= 84\tTrain=0.705682\tTest=0.810676\n",
      "#Iter= 85\tTrain=0.705752\tTest=0.810656\n",
      "#Iter= 86\tTrain=0.705476\tTest=0.810643\n",
      "#Iter= 87\tTrain=0.705627\tTest=0.810606\n",
      "#Iter= 88\tTrain=0.705761\tTest=0.810623\n",
      "#Iter= 89\tTrain=0.70585\tTest=0.810554\n",
      "#Iter= 90\tTrain=0.705578\tTest=0.810479\n",
      "#Iter= 91\tTrain=0.705874\tTest=0.810389\n",
      "#Iter= 92\tTrain=0.705817\tTest=0.810371\n",
      "#Iter= 93\tTrain=0.705921\tTest=0.810356\n",
      "#Iter= 94\tTrain=0.705824\tTest=0.810307\n",
      "#Iter= 95\tTrain=0.706032\tTest=0.810318\n",
      "#Iter= 96\tTrain=0.70606\tTest=0.810285\n",
      "#Iter= 97\tTrain=0.706069\tTest=0.810243\n",
      "#Iter= 98\tTrain=0.705747\tTest=0.81021\n",
      "#Iter= 99\tTrain=0.705687\tTest=0.810203\n"
     ]
    }
   ],
   "source": [
    "!libFM.exe -task r -train first_train.txt -test first_test.txt -out first_result.txt -method mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.810\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE: {:.3f}'.format(calculate_RMSE(test_results, read_results('first_result.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=1698518\tnum_features=12310\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=12678\tnum_features=12310\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.752214\tTest=0.946868\n",
      "#Iter=  1\tTrain=0.72344\tTest=0.947484\n",
      "#Iter=  2\tTrain=0.705624\tTest=0.947459\n",
      "#Iter=  3\tTrain=0.695947\tTest=0.948411\n",
      "#Iter=  4\tTrain=0.690154\tTest=0.949674\n",
      "#Iter=  5\tTrain=0.686248\tTest=0.951213\n",
      "#Iter=  6\tTrain=0.683417\tTest=0.952617\n",
      "#Iter=  7\tTrain=0.681268\tTest=0.95368\n",
      "#Iter=  8\tTrain=0.679577\tTest=0.954526\n",
      "#Iter=  9\tTrain=0.67821\tTest=0.955211\n",
      "#Iter= 10\tTrain=0.677079\tTest=0.955812\n",
      "#Iter= 11\tTrain=0.676126\tTest=0.956301\n",
      "#Iter= 12\tTrain=0.675309\tTest=0.956564\n",
      "#Iter= 13\tTrain=0.674597\tTest=0.956786\n",
      "#Iter= 14\tTrain=0.673969\tTest=0.957084\n",
      "#Iter= 15\tTrain=0.673408\tTest=0.957309\n",
      "#Iter= 16\tTrain=0.672903\tTest=0.95745\n",
      "#Iter= 17\tTrain=0.672445\tTest=0.957509\n",
      "#Iter= 18\tTrain=0.672026\tTest=0.957491\n",
      "#Iter= 19\tTrain=0.67164\tTest=0.957404\n",
      "#Iter= 20\tTrain=0.671285\tTest=0.957285\n",
      "#Iter= 21\tTrain=0.670958\tTest=0.95715\n",
      "#Iter= 22\tTrain=0.670656\tTest=0.957007\n",
      "#Iter= 23\tTrain=0.670377\tTest=0.956868\n",
      "#Iter= 24\tTrain=0.670118\tTest=0.956731\n",
      "#Iter= 25\tTrain=0.669877\tTest=0.956597\n",
      "#Iter= 26\tTrain=0.669652\tTest=0.956469\n",
      "#Iter= 27\tTrain=0.669443\tTest=0.956349\n",
      "#Iter= 28\tTrain=0.669247\tTest=0.956235\n",
      "#Iter= 29\tTrain=0.669064\tTest=0.956121\n",
      "#Iter= 30\tTrain=0.668893\tTest=0.956007\n",
      "#Iter= 31\tTrain=0.668733\tTest=0.95589\n",
      "#Iter= 32\tTrain=0.668582\tTest=0.955692\n",
      "#Iter= 33\tTrain=0.66844\tTest=0.955499\n",
      "#Iter= 34\tTrain=0.668306\tTest=0.955317\n",
      "#Iter= 35\tTrain=0.66818\tTest=0.955148\n",
      "#Iter= 36\tTrain=0.668061\tTest=0.954978\n",
      "#Iter= 37\tTrain=0.667947\tTest=0.954808\n",
      "#Iter= 38\tTrain=0.66784\tTest=0.954639\n",
      "#Iter= 39\tTrain=0.667737\tTest=0.954478\n",
      "#Iter= 40\tTrain=0.66764\tTest=0.954327\n",
      "#Iter= 41\tTrain=0.667546\tTest=0.954189\n",
      "#Iter= 42\tTrain=0.667458\tTest=0.954065\n",
      "#Iter= 43\tTrain=0.667373\tTest=0.953957\n",
      "#Iter= 44\tTrain=0.667292\tTest=0.953866\n",
      "#Iter= 45\tTrain=0.667215\tTest=0.95379\n",
      "#Iter= 46\tTrain=0.667141\tTest=0.953731\n",
      "#Iter= 47\tTrain=0.667069\tTest=0.953689\n",
      "#Iter= 48\tTrain=0.667001\tTest=0.953662\n",
      "#Iter= 49\tTrain=0.666936\tTest=0.95365\n",
      "#Iter= 50\tTrain=0.666873\tTest=0.953652\n",
      "#Iter= 51\tTrain=0.666812\tTest=0.953666\n",
      "#Iter= 52\tTrain=0.666753\tTest=0.953691\n",
      "#Iter= 53\tTrain=0.666697\tTest=0.953714\n",
      "#Iter= 54\tTrain=0.666642\tTest=0.953718\n",
      "#Iter= 55\tTrain=0.666589\tTest=0.953729\n",
      "#Iter= 56\tTrain=0.666538\tTest=0.953748\n",
      "#Iter= 57\tTrain=0.666488\tTest=0.953773\n",
      "#Iter= 58\tTrain=0.66644\tTest=0.953805\n",
      "#Iter= 59\tTrain=0.666393\tTest=0.953843\n",
      "#Iter= 60\tTrain=0.666348\tTest=0.953887\n",
      "#Iter= 61\tTrain=0.666304\tTest=0.953939\n",
      "#Iter= 62\tTrain=0.666261\tTest=0.953997\n",
      "#Iter= 63\tTrain=0.666219\tTest=0.954061\n",
      "#Iter= 64\tTrain=0.666178\tTest=0.954133\n",
      "#Iter= 65\tTrain=0.666138\tTest=0.95421\n",
      "#Iter= 66\tTrain=0.666099\tTest=0.954292\n",
      "#Iter= 67\tTrain=0.66606\tTest=0.954377\n",
      "#Iter= 68\tTrain=0.666023\tTest=0.954466\n",
      "#Iter= 69\tTrain=0.665986\tTest=0.954559\n",
      "#Iter= 70\tTrain=0.66595\tTest=0.954653\n",
      "#Iter= 71\tTrain=0.665915\tTest=0.954749\n",
      "#Iter= 72\tTrain=0.665882\tTest=0.954847\n",
      "#Iter= 73\tTrain=0.665849\tTest=0.954946\n",
      "#Iter= 74\tTrain=0.665816\tTest=0.955047\n",
      "#Iter= 75\tTrain=0.665785\tTest=0.955149\n",
      "#Iter= 76\tTrain=0.665754\tTest=0.955252\n",
      "#Iter= 77\tTrain=0.665724\tTest=0.955355\n",
      "#Iter= 78\tTrain=0.665695\tTest=0.955452\n",
      "#Iter= 79\tTrain=0.665666\tTest=0.955551\n",
      "#Iter= 80\tTrain=0.665638\tTest=0.955649\n",
      "#Iter= 81\tTrain=0.66561\tTest=0.955748\n",
      "#Iter= 82\tTrain=0.665583\tTest=0.955847\n",
      "#Iter= 83\tTrain=0.665556\tTest=0.955945\n",
      "#Iter= 84\tTrain=0.66553\tTest=0.956046\n",
      "#Iter= 85\tTrain=0.665505\tTest=0.956152\n",
      "#Iter= 86\tTrain=0.665479\tTest=0.956257\n",
      "#Iter= 87\tTrain=0.665454\tTest=0.956361\n",
      "#Iter= 88\tTrain=0.66543\tTest=0.956463\n",
      "#Iter= 89\tTrain=0.665406\tTest=0.956564\n",
      "#Iter= 90\tTrain=0.665383\tTest=0.956664\n",
      "#Iter= 91\tTrain=0.665359\tTest=0.956764\n",
      "#Iter= 92\tTrain=0.665337\tTest=0.956864\n",
      "#Iter= 93\tTrain=0.665315\tTest=0.956963\n",
      "#Iter= 94\tTrain=0.665293\tTest=0.957063\n",
      "#Iter= 95\tTrain=0.665271\tTest=0.957161\n",
      "#Iter= 96\tTrain=0.66525\tTest=0.957259\n",
      "#Iter= 97\tTrain=0.66523\tTest=0.957356\n",
      "#Iter= 98\tTrain=0.665209\tTest=0.957452\n",
      "#Iter= 99\tTrain=0.66519\tTest=0.957547\n"
     ]
    }
   ],
   "source": [
    "!libFM.exe -task r -train first_train.txt -test first_test.txt -out first_result.txt -method als"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На базовой выборке имеем точность: <br>\n",
    "<li>для метода MCMC RMSE = 0.81\n",
    "<li>для метода ALS RMSE = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id-пользователя + id-фильма + оценки пользователя за каждый просмотренный фильм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Снова будем рассматривать только самые высокие оценки пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_rank_id = {}\n",
    "for movie in movies_df['id'].unique():\n",
    "    movies_rank_id[movie] = len(movies_rank_id) + start_index\n",
    "start_index += len(movies_rank_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_second_sample(df, file_name):\n",
    "    results = []\n",
    "    with open(file_name, 'w') as fsampl:\n",
    "        for user, data in df.items():\n",
    "            ratings = ' '.join(['{}:{}'.format(movies_rank_id[movie],rating) for movie, rating in \n",
    "                                       sorted(zip(list(data['movieID']), list(data['rating'])), \n",
    "                                       key=lambda x: x[1], reverse=True)[:10]])\n",
    "            for row in data.iterrows():\n",
    "                example = '{0} {1}:1.0 {2}:1.0 {3}\\n'.format(row[1]['rating'], users_id[user], \n",
    "                                                                   movies_id[int(row[1]['movieID'])], ratings)\n",
    "                results.append(row[1]['rating'])\n",
    "        \n",
    "                fsampl.write(example)\n",
    "        return results\n",
    "    \n",
    "get_second_sample(train_df, 'second_train.txt')\n",
    "test_results = get_second_sample(test_df, 'second_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=10191108\tnum_features=22481\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=31695\tnum_features=22507\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=1.05721\tTest=1.67016\n",
      "#Iter=  1\tTrain=0.818446\tTest=1.61285\n",
      "#Iter=  2\tTrain=0.79483\tTest=1.59143\n",
      "#Iter=  3\tTrain=0.7919\tTest=1.58636\n",
      "#Iter=  4\tTrain=0.790807\tTest=1.57487\n",
      "#Iter=  5\tTrain=0.790478\tTest=1.5709\n",
      "#Iter=  6\tTrain=0.789882\tTest=1.56294\n",
      "#Iter=  7\tTrain=0.789685\tTest=1.56157\n",
      "#Iter=  8\tTrain=0.789358\tTest=1.55951\n",
      "#Iter=  9\tTrain=0.789265\tTest=1.55643\n",
      "#Iter= 10\tTrain=0.789056\tTest=1.55606\n",
      "#Iter= 11\tTrain=0.788614\tTest=1.55353\n",
      "#Iter= 12\tTrain=0.788295\tTest=1.55111\n",
      "#Iter= 13\tTrain=0.788145\tTest=1.54824\n",
      "#Iter= 14\tTrain=0.787688\tTest=1.54784\n",
      "#Iter= 15\tTrain=0.787387\tTest=1.54699\n",
      "#Iter= 16\tTrain=0.787164\tTest=1.54281\n",
      "#Iter= 17\tTrain=0.786768\tTest=1.54159\n",
      "#Iter= 18\tTrain=0.786487\tTest=1.54132\n",
      "#Iter= 19\tTrain=0.786166\tTest=1.53983\n",
      "#Iter= 20\tTrain=0.785904\tTest=1.54018\n",
      "#Iter= 21\tTrain=0.785326\tTest=1.53872\n",
      "#Iter= 22\tTrain=0.785215\tTest=1.53883\n",
      "#Iter= 23\tTrain=0.784969\tTest=1.53781\n",
      "#Iter= 24\tTrain=0.784623\tTest=1.53679\n",
      "#Iter= 25\tTrain=0.784504\tTest=1.5371\n",
      "#Iter= 26\tTrain=0.784548\tTest=1.53758\n",
      "#Iter= 27\tTrain=0.784058\tTest=1.53611\n",
      "#Iter= 28\tTrain=0.783331\tTest=1.53588\n",
      "#Iter= 29\tTrain=0.783301\tTest=1.53456\n",
      "#Iter= 30\tTrain=0.783098\tTest=1.53396\n",
      "#Iter= 31\tTrain=0.783071\tTest=1.53308\n",
      "#Iter= 32\tTrain=0.782583\tTest=1.53215\n",
      "#Iter= 33\tTrain=0.782633\tTest=1.5311\n",
      "#Iter= 34\tTrain=0.782207\tTest=1.53015\n",
      "#Iter= 35\tTrain=0.781764\tTest=1.53066\n",
      "#Iter= 36\tTrain=0.781647\tTest=1.53034\n",
      "#Iter= 37\tTrain=0.781535\tTest=1.52972\n",
      "#Iter= 38\tTrain=0.781483\tTest=1.52894\n",
      "#Iter= 39\tTrain=0.78114\tTest=1.52853\n",
      "#Iter= 40\tTrain=0.78099\tTest=1.52802\n",
      "#Iter= 41\tTrain=0.780751\tTest=1.52797\n",
      "#Iter= 42\tTrain=0.780385\tTest=1.52745\n",
      "#Iter= 43\tTrain=0.78034\tTest=1.52672\n",
      "#Iter= 44\tTrain=0.780331\tTest=1.52596\n",
      "#Iter= 45\tTrain=0.779814\tTest=1.52555\n",
      "#Iter= 46\tTrain=0.77969\tTest=1.52537\n",
      "#Iter= 47\tTrain=0.779618\tTest=1.52509\n",
      "#Iter= 48\tTrain=0.779327\tTest=1.5246\n",
      "#Iter= 49\tTrain=0.779223\tTest=1.52447\n",
      "#Iter= 50\tTrain=0.778891\tTest=1.52438\n",
      "#Iter= 51\tTrain=0.778533\tTest=1.52388\n",
      "#Iter= 52\tTrain=0.778513\tTest=1.52362\n",
      "#Iter= 53\tTrain=0.778359\tTest=1.52331\n",
      "#Iter= 54\tTrain=0.777902\tTest=1.52353\n",
      "#Iter= 55\tTrain=0.777888\tTest=1.52367\n",
      "#Iter= 56\tTrain=0.777495\tTest=1.52307\n",
      "#Iter= 57\tTrain=0.777407\tTest=1.52283\n",
      "#Iter= 58\tTrain=0.77725\tTest=1.52192\n",
      "#Iter= 59\tTrain=0.77681\tTest=1.52159\n",
      "#Iter= 60\tTrain=0.776796\tTest=1.52163\n",
      "#Iter= 61\tTrain=0.776489\tTest=1.52104\n",
      "#Iter= 62\tTrain=0.776346\tTest=1.52067\n",
      "#Iter= 63\tTrain=0.776383\tTest=1.52029\n",
      "#Iter= 64\tTrain=0.776026\tTest=1.51976\n",
      "#Iter= 65\tTrain=0.776241\tTest=1.51943\n",
      "#Iter= 66\tTrain=0.776088\tTest=1.5194\n",
      "#Iter= 67\tTrain=0.775602\tTest=1.51959\n",
      "#Iter= 68\tTrain=0.775556\tTest=1.51937\n",
      "#Iter= 69\tTrain=0.775202\tTest=1.5189\n",
      "#Iter= 70\tTrain=0.775116\tTest=1.51837\n",
      "#Iter= 71\tTrain=0.775044\tTest=1.51829\n",
      "#Iter= 72\tTrain=0.774941\tTest=1.5188\n",
      "#Iter= 73\tTrain=0.775033\tTest=1.51909\n",
      "#Iter= 74\tTrain=0.774379\tTest=1.51898\n",
      "#Iter= 75\tTrain=0.774485\tTest=1.5186\n",
      "#Iter= 76\tTrain=0.774055\tTest=1.51814\n",
      "#Iter= 77\tTrain=0.773975\tTest=1.51785\n",
      "#Iter= 78\tTrain=0.773625\tTest=1.5171\n",
      "#Iter= 79\tTrain=0.773225\tTest=1.51712\n",
      "#Iter= 80\tTrain=0.773279\tTest=1.51678\n",
      "#Iter= 81\tTrain=0.773554\tTest=1.51628\n",
      "#Iter= 82\tTrain=0.773156\tTest=1.51617\n",
      "#Iter= 83\tTrain=0.77296\tTest=1.51564\n",
      "#Iter= 84\tTrain=0.773127\tTest=1.51512\n",
      "#Iter= 85\tTrain=0.772857\tTest=1.51457\n",
      "#Iter= 86\tTrain=0.772705\tTest=1.51407\n",
      "#Iter= 87\tTrain=0.772527\tTest=1.5138\n",
      "#Iter= 88\tTrain=0.772601\tTest=1.51362\n",
      "#Iter= 89\tTrain=0.772455\tTest=1.51371\n",
      "#Iter= 90\tTrain=0.772477\tTest=1.51344\n",
      "#Iter= 91\tTrain=0.772203\tTest=1.51312\n",
      "#Iter= 92\tTrain=0.772082\tTest=1.5127\n",
      "#Iter= 93\tTrain=0.771763\tTest=1.51211\n",
      "#Iter= 94\tTrain=0.771549\tTest=1.51212\n",
      "#Iter= 95\tTrain=0.771472\tTest=1.51195\n",
      "#Iter= 96\tTrain=0.771404\tTest=1.51195\n",
      "#Iter= 97\tTrain=0.770982\tTest=1.51167\n",
      "#Iter= 98\tTrain=0.770885\tTest=1.51145\n",
      "#Iter= 99\tTrain=0.77097\tTest=1.51133\n",
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=10191108\tnum_features=22481\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=31695\tnum_features=22507\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=1.05721\tTest=1.67016\n",
      "#Iter=  1\tTrain=0.818446\tTest=1.61285\n",
      "#Iter=  2\tTrain=0.79483\tTest=1.59143\n",
      "#Iter=  3\tTrain=0.7919\tTest=1.58636\n",
      "#Iter=  4\tTrain=0.790807\tTest=1.57487\n",
      "#Iter=  5\tTrain=0.790478\tTest=1.5709\n",
      "#Iter=  6\tTrain=0.789882\tTest=1.56294\n",
      "#Iter=  7\tTrain=0.789685\tTest=1.56157\n",
      "#Iter=  8\tTrain=0.789358\tTest=1.55951\n",
      "#Iter=  9\tTrain=0.789265\tTest=1.55643\n",
      "#Iter= 10\tTrain=0.789056\tTest=1.55606\n",
      "#Iter= 11\tTrain=0.788614\tTest=1.55353\n",
      "#Iter= 12\tTrain=0.788295\tTest=1.55111\n",
      "#Iter= 13\tTrain=0.788145\tTest=1.54824\n",
      "#Iter= 14\tTrain=0.787688\tTest=1.54784\n",
      "#Iter= 15\tTrain=0.787387\tTest=1.54699\n",
      "#Iter= 16\tTrain=0.787164\tTest=1.54281\n",
      "#Iter= 17\tTrain=0.786768\tTest=1.54159\n",
      "#Iter= 18\tTrain=0.786487\tTest=1.54132\n",
      "#Iter= 19\tTrain=0.786166\tTest=1.53983\n",
      "#Iter= 20\tTrain=0.785904\tTest=1.54018\n",
      "#Iter= 21\tTrain=0.785326\tTest=1.53872\n",
      "#Iter= 22\tTrain=0.785215\tTest=1.53883\n",
      "#Iter= 23\tTrain=0.784969\tTest=1.53781\n",
      "#Iter= 24\tTrain=0.784623\tTest=1.53679\n",
      "#Iter= 25\tTrain=0.784504\tTest=1.5371\n",
      "#Iter= 26\tTrain=0.784548\tTest=1.53758\n",
      "#Iter= 27\tTrain=0.784058\tTest=1.53611\n",
      "#Iter= 28\tTrain=0.783331\tTest=1.53588\n",
      "#Iter= 29\tTrain=0.783301\tTest=1.53456\n",
      "#Iter= 30\tTrain=0.783098\tTest=1.53396\n",
      "#Iter= 31\tTrain=0.783071\tTest=1.53308\n",
      "#Iter= 32\tTrain=0.782583\tTest=1.53215\n",
      "#Iter= 33\tTrain=0.782633\tTest=1.5311\n",
      "#Iter= 34\tTrain=0.782207\tTest=1.53015\n",
      "#Iter= 35\tTrain=0.781764\tTest=1.53066\n",
      "#Iter= 36\tTrain=0.781647\tTest=1.53034\n",
      "#Iter= 37\tTrain=0.781535\tTest=1.52972\n",
      "#Iter= 38\tTrain=0.781483\tTest=1.52894\n",
      "#Iter= 39\tTrain=0.78114\tTest=1.52853\n",
      "#Iter= 40\tTrain=0.78099\tTest=1.52802\n",
      "#Iter= 41\tTrain=0.780751\tTest=1.52797\n",
      "#Iter= 42\tTrain=0.780385\tTest=1.52745\n",
      "#Iter= 43\tTrain=0.78034\tTest=1.52672\n",
      "#Iter= 44\tTrain=0.780331\tTest=1.52596\n",
      "#Iter= 45\tTrain=0.779814\tTest=1.52555\n",
      "#Iter= 46\tTrain=0.77969\tTest=1.52537\n",
      "#Iter= 47\tTrain=0.779618\tTest=1.52509\n",
      "#Iter= 48\tTrain=0.779327\tTest=1.5246\n",
      "#Iter= 49\tTrain=0.779223\tTest=1.52447\n",
      "#Iter= 50\tTrain=0.778891\tTest=1.52438\n",
      "#Iter= 51\tTrain=0.778533\tTest=1.52388\n",
      "#Iter= 52\tTrain=0.778513\tTest=1.52362\n",
      "#Iter= 53\tTrain=0.778359\tTest=1.52331\n",
      "#Iter= 54\tTrain=0.777902\tTest=1.52353\n",
      "#Iter= 55\tTrain=0.777888\tTest=1.52367\n",
      "#Iter= 56\tTrain=0.777495\tTest=1.52307\n",
      "#Iter= 57\tTrain=0.777407\tTest=1.52283\n",
      "#Iter= 58\tTrain=0.77725\tTest=1.52192\n",
      "#Iter= 59\tTrain=0.77681\tTest=1.52159\n",
      "#Iter= 60\tTrain=0.776796\tTest=1.52163\n",
      "#Iter= 61\tTrain=0.776489\tTest=1.52104\n",
      "#Iter= 62\tTrain=0.776346\tTest=1.52067\n",
      "#Iter= 63\tTrain=0.776383\tTest=1.52029\n",
      "#Iter= 64\tTrain=0.776026\tTest=1.51976\n",
      "#Iter= 65\tTrain=0.776241\tTest=1.51943\n",
      "#Iter= 66\tTrain=0.776088\tTest=1.5194\n",
      "#Iter= 67\tTrain=0.775602\tTest=1.51959\n",
      "#Iter= 68\tTrain=0.775556\tTest=1.51937\n",
      "#Iter= 69\tTrain=0.775202\tTest=1.5189\n",
      "#Iter= 70\tTrain=0.775116\tTest=1.51837\n",
      "#Iter= 71\tTrain=0.775044\tTest=1.51829\n",
      "#Iter= 72\tTrain=0.774941\tTest=1.5188\n",
      "#Iter= 73\tTrain=0.775033\tTest=1.51909\n",
      "#Iter= 74\tTrain=0.774379\tTest=1.51898\n",
      "#Iter= 75\tTrain=0.774485\tTest=1.5186\n",
      "#Iter= 76\tTrain=0.774055\tTest=1.51814\n",
      "#Iter= 77\tTrain=0.773975\tTest=1.51785\n",
      "#Iter= 78\tTrain=0.773625\tTest=1.5171\n",
      "#Iter= 79\tTrain=0.773225\tTest=1.51712\n",
      "#Iter= 80\tTrain=0.773279\tTest=1.51678\n",
      "#Iter= 81\tTrain=0.773554\tTest=1.51628\n",
      "#Iter= 82\tTrain=0.773156\tTest=1.51617\n",
      "#Iter= 83\tTrain=0.77296\tTest=1.51564\n",
      "#Iter= 84\tTrain=0.773127\tTest=1.51512\n",
      "#Iter= 85\tTrain=0.772857\tTest=1.51457\n",
      "#Iter= 86\tTrain=0.772705\tTest=1.51407\n",
      "#Iter= 87\tTrain=0.772527\tTest=1.5138\n",
      "#Iter= 88\tTrain=0.772601\tTest=1.51362\n",
      "#Iter= 89\tTrain=0.772455\tTest=1.51371\n",
      "#Iter= 90\tTrain=0.772477\tTest=1.51344\n",
      "#Iter= 91\tTrain=0.772203\tTest=1.51312\n",
      "#Iter= 92\tTrain=0.772082\tTest=1.5127\n",
      "#Iter= 93\tTrain=0.771763\tTest=1.51211\n",
      "#Iter= 94\tTrain=0.771549\tTest=1.51212\n",
      "#Iter= 95\tTrain=0.771472\tTest=1.51195\n",
      "#Iter= 96\tTrain=0.771404\tTest=1.51195\n",
      "#Iter= 97\tTrain=0.770982\tTest=1.51167\n",
      "#Iter= 98\tTrain=0.770885\tTest=1.51145\n",
      "#Iter= 99\tTrain=0.77097\tTest=1.51133\n"
     ]
    }
   ],
   "source": [
    "!libFM.exe -task r -train second_train.txt -test second_test.txt -out second_result.txt -method mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.511\n",
      "RMSE: 1.511\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE: {:.3f}'.format(calculate_RMSE(test_results, read_results('second_result.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=10191108\tnum_features=22481\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=31695\tnum_features=22507\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.837151\tTest=2.1793\n",
      "#Iter=  1\tTrain=0.766909\tTest=2.17627\n",
      "#Iter=  2\tTrain=0.759375\tTest=2.17686\n",
      "#Iter=  3\tTrain=0.755865\tTest=2.17804\n",
      "#Iter=  4\tTrain=0.753175\tTest=2.1799\n",
      "#Iter=  5\tTrain=0.750819\tTest=2.18183\n",
      "#Iter=  6\tTrain=0.748715\tTest=2.18335\n",
      "#Iter=  7\tTrain=0.746846\tTest=2.18497\n",
      "#Iter=  8\tTrain=0.745171\tTest=2.18642\n",
      "#Iter=  9\tTrain=0.74364\tTest=2.18769\n",
      "#Iter= 10\tTrain=0.742227\tTest=2.18892\n",
      "#Iter= 11\tTrain=0.740922\tTest=2.18998\n",
      "#Iter= 12\tTrain=0.7397\tTest=2.19066\n",
      "#Iter= 13\tTrain=0.738572\tTest=2.19122\n",
      "#Iter= 14\tTrain=0.737498\tTest=2.19168\n",
      "#Iter= 15\tTrain=0.736502\tTest=2.1922\n",
      "#Iter= 16\tTrain=0.735579\tTest=2.1927\n",
      "#Iter= 17\tTrain=0.734726\tTest=2.19313\n",
      "#Iter= 18\tTrain=0.733937\tTest=2.19343\n",
      "#Iter= 19\tTrain=0.733203\tTest=2.19362\n",
      "#Iter= 20\tTrain=0.732509\tTest=2.19373\n",
      "#Iter= 21\tTrain=0.731848\tTest=2.19382\n",
      "#Iter= 22\tTrain=0.731204\tTest=2.19389\n",
      "#Iter= 23\tTrain=0.730598\tTest=2.19393\n",
      "#Iter= 24\tTrain=0.730017\tTest=2.19393\n",
      "#Iter= 25\tTrain=0.729451\tTest=2.19398\n",
      "#Iter= 26\tTrain=0.728902\tTest=2.19405\n",
      "#Iter= 27\tTrain=0.728377\tTest=2.19405\n",
      "#Iter= 28\tTrain=0.727869\tTest=2.19404\n",
      "#Iter= 29\tTrain=0.727372\tTest=2.19406\n",
      "#Iter= 30\tTrain=0.72688\tTest=2.19414\n",
      "#Iter= 31\tTrain=0.726395\tTest=2.19426\n",
      "#Iter= 32\tTrain=0.725907\tTest=2.19441\n",
      "#Iter= 33\tTrain=0.725433\tTest=2.19457\n",
      "#Iter= 34\tTrain=0.72497\tTest=2.19474\n",
      "#Iter= 35\tTrain=0.724518\tTest=2.19491\n",
      "#Iter= 36\tTrain=0.724083\tTest=2.19508\n",
      "#Iter= 37\tTrain=0.723665\tTest=2.19523\n",
      "#Iter= 38\tTrain=0.723269\tTest=2.19535\n",
      "#Iter= 39\tTrain=0.722882\tTest=2.19544\n",
      "#Iter= 40\tTrain=0.722518\tTest=2.19551\n",
      "#Iter= 41\tTrain=0.722164\tTest=2.19559\n",
      "#Iter= 42\tTrain=0.721813\tTest=2.19569\n",
      "#Iter= 43\tTrain=0.721474\tTest=2.19578\n",
      "#Iter= 44\tTrain=0.721145\tTest=2.19586\n",
      "#Iter= 45\tTrain=0.720829\tTest=2.19594\n",
      "#Iter= 46\tTrain=0.720517\tTest=2.19602\n",
      "#Iter= 47\tTrain=0.720216\tTest=2.1961\n",
      "#Iter= 48\tTrain=0.719919\tTest=2.19618\n",
      "#Iter= 49\tTrain=0.71963\tTest=2.19624\n",
      "#Iter= 50\tTrain=0.719348\tTest=2.1963\n",
      "#Iter= 51\tTrain=0.719078\tTest=2.19638\n",
      "#Iter= 52\tTrain=0.718815\tTest=2.19647\n",
      "#Iter= 53\tTrain=0.718562\tTest=2.19655\n",
      "#Iter= 54\tTrain=0.718312\tTest=2.19661\n",
      "#Iter= 55\tTrain=0.718069\tTest=2.19669\n",
      "#Iter= 56\tTrain=0.717829\tTest=2.19677\n",
      "#Iter= 57\tTrain=0.717593\tTest=2.19683\n",
      "#Iter= 58\tTrain=0.71736\tTest=2.1969\n",
      "#Iter= 59\tTrain=0.717133\tTest=2.19696\n",
      "#Iter= 60\tTrain=0.716906\tTest=2.19704\n",
      "#Iter= 61\tTrain=0.716676\tTest=2.19712\n",
      "#Iter= 62\tTrain=0.716441\tTest=2.1972\n",
      "#Iter= 63\tTrain=0.716224\tTest=2.19729\n",
      "#Iter= 64\tTrain=0.716019\tTest=2.19738\n",
      "#Iter= 65\tTrain=0.715823\tTest=2.19747\n",
      "#Iter= 66\tTrain=0.715634\tTest=2.19755\n",
      "#Iter= 67\tTrain=0.715449\tTest=2.19763\n",
      "#Iter= 68\tTrain=0.715269\tTest=2.1977\n",
      "#Iter= 69\tTrain=0.715094\tTest=2.19778\n",
      "#Iter= 70\tTrain=0.714924\tTest=2.19786\n",
      "#Iter= 71\tTrain=0.714758\tTest=2.19794\n",
      "#Iter= 72\tTrain=0.714596\tTest=2.19802\n",
      "#Iter= 73\tTrain=0.714438\tTest=2.19811\n",
      "#Iter= 74\tTrain=0.714284\tTest=2.1982\n",
      "#Iter= 75\tTrain=0.714133\tTest=2.1983\n",
      "#Iter= 76\tTrain=0.713985\tTest=2.19842\n",
      "#Iter= 77\tTrain=0.71384\tTest=2.19854\n",
      "#Iter= 78\tTrain=0.713699\tTest=2.19867\n",
      "#Iter= 79\tTrain=0.713559\tTest=2.19881\n",
      "#Iter= 80\tTrain=0.713423\tTest=2.19895\n",
      "#Iter= 81\tTrain=0.713289\tTest=2.19911\n",
      "#Iter= 82\tTrain=0.713158\tTest=2.19926\n",
      "#Iter= 83\tTrain=0.713028\tTest=2.19942\n",
      "#Iter= 84\tTrain=0.712901\tTest=2.19959\n",
      "#Iter= 85\tTrain=0.712776\tTest=2.19976\n",
      "#Iter= 86\tTrain=0.712653\tTest=2.19993\n",
      "#Iter= 87\tTrain=0.712532\tTest=2.20012\n",
      "#Iter= 88\tTrain=0.712412\tTest=2.2003\n",
      "#Iter= 89\tTrain=0.712294\tTest=2.20049\n",
      "#Iter= 90\tTrain=0.712178\tTest=2.20068\n",
      "#Iter= 91\tTrain=0.712064\tTest=2.20087\n",
      "#Iter= 92\tTrain=0.71195\tTest=2.20107\n",
      "#Iter= 93\tTrain=0.711834\tTest=2.20126\n",
      "#Iter= 94\tTrain=0.711719\tTest=2.20145\n",
      "#Iter= 95\tTrain=0.711606\tTest=2.20164\n",
      "#Iter= 96\tTrain=0.711495\tTest=2.20183\n",
      "#Iter= 97\tTrain=0.711386\tTest=2.20201\n",
      "#Iter= 98\tTrain=0.71128\tTest=2.20219\n",
      "#Iter= 99\tTrain=0.711175\tTest=2.20237\n",
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=10191108\tnum_features=22481\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=31695\tnum_features=22507\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.837151\tTest=2.1793\n",
      "#Iter=  1\tTrain=0.766909\tTest=2.17627\n",
      "#Iter=  2\tTrain=0.759375\tTest=2.17686\n",
      "#Iter=  3\tTrain=0.755865\tTest=2.17804\n",
      "#Iter=  4\tTrain=0.753175\tTest=2.1799\n",
      "#Iter=  5\tTrain=0.750819\tTest=2.18183\n",
      "#Iter=  6\tTrain=0.748715\tTest=2.18335\n",
      "#Iter=  7\tTrain=0.746846\tTest=2.18497\n",
      "#Iter=  8\tTrain=0.745171\tTest=2.18642\n",
      "#Iter=  9\tTrain=0.74364\tTest=2.18769\n",
      "#Iter= 10\tTrain=0.742227\tTest=2.18892\n",
      "#Iter= 11\tTrain=0.740922\tTest=2.18998\n",
      "#Iter= 12\tTrain=0.7397\tTest=2.19066\n",
      "#Iter= 13\tTrain=0.738572\tTest=2.19122\n",
      "#Iter= 14\tTrain=0.737498\tTest=2.19168\n",
      "#Iter= 15\tTrain=0.736502\tTest=2.1922\n",
      "#Iter= 16\tTrain=0.735579\tTest=2.1927\n",
      "#Iter= 17\tTrain=0.734726\tTest=2.19313\n",
      "#Iter= 18\tTrain=0.733937\tTest=2.19343\n",
      "#Iter= 19\tTrain=0.733203\tTest=2.19362\n",
      "#Iter= 20\tTrain=0.732509\tTest=2.19373\n",
      "#Iter= 21\tTrain=0.731848\tTest=2.19382\n",
      "#Iter= 22\tTrain=0.731204\tTest=2.19389\n",
      "#Iter= 23\tTrain=0.730598\tTest=2.19393\n",
      "#Iter= 24\tTrain=0.730017\tTest=2.19393\n",
      "#Iter= 25\tTrain=0.729451\tTest=2.19398\n",
      "#Iter= 26\tTrain=0.728902\tTest=2.19405\n",
      "#Iter= 27\tTrain=0.728377\tTest=2.19405\n",
      "#Iter= 28\tTrain=0.727869\tTest=2.19404\n",
      "#Iter= 29\tTrain=0.727372\tTest=2.19406\n",
      "#Iter= 30\tTrain=0.72688\tTest=2.19414\n",
      "#Iter= 31\tTrain=0.726395\tTest=2.19426\n",
      "#Iter= 32\tTrain=0.725907\tTest=2.19441\n",
      "#Iter= 33\tTrain=0.725433\tTest=2.19457\n",
      "#Iter= 34\tTrain=0.72497\tTest=2.19474\n",
      "#Iter= 35\tTrain=0.724518\tTest=2.19491\n",
      "#Iter= 36\tTrain=0.724083\tTest=2.19508\n",
      "#Iter= 37\tTrain=0.723665\tTest=2.19523\n",
      "#Iter= 38\tTrain=0.723269\tTest=2.19535\n",
      "#Iter= 39\tTrain=0.722882\tTest=2.19544\n",
      "#Iter= 40\tTrain=0.722518\tTest=2.19551\n",
      "#Iter= 41\tTrain=0.722164\tTest=2.19559\n",
      "#Iter= 42\tTrain=0.721813\tTest=2.19569\n",
      "#Iter= 43\tTrain=0.721474\tTest=2.19578\n",
      "#Iter= 44\tTrain=0.721145\tTest=2.19586\n",
      "#Iter= 45\tTrain=0.720829\tTest=2.19594\n",
      "#Iter= 46\tTrain=0.720517\tTest=2.19602\n",
      "#Iter= 47\tTrain=0.720216\tTest=2.1961\n",
      "#Iter= 48\tTrain=0.719919\tTest=2.19618\n",
      "#Iter= 49\tTrain=0.71963\tTest=2.19624\n",
      "#Iter= 50\tTrain=0.719348\tTest=2.1963\n",
      "#Iter= 51\tTrain=0.719078\tTest=2.19638\n",
      "#Iter= 52\tTrain=0.718815\tTest=2.19647\n",
      "#Iter= 53\tTrain=0.718562\tTest=2.19655\n",
      "#Iter= 54\tTrain=0.718312\tTest=2.19661\n",
      "#Iter= 55\tTrain=0.718069\tTest=2.19669\n",
      "#Iter= 56\tTrain=0.717829\tTest=2.19677\n",
      "#Iter= 57\tTrain=0.717593\tTest=2.19683\n",
      "#Iter= 58\tTrain=0.71736\tTest=2.1969\n",
      "#Iter= 59\tTrain=0.717133\tTest=2.19696\n",
      "#Iter= 60\tTrain=0.716906\tTest=2.19704\n",
      "#Iter= 61\tTrain=0.716676\tTest=2.19712\n",
      "#Iter= 62\tTrain=0.716441\tTest=2.1972\n",
      "#Iter= 63\tTrain=0.716224\tTest=2.19729\n",
      "#Iter= 64\tTrain=0.716019\tTest=2.19738\n",
      "#Iter= 65\tTrain=0.715823\tTest=2.19747\n",
      "#Iter= 66\tTrain=0.715634\tTest=2.19755\n",
      "#Iter= 67\tTrain=0.715449\tTest=2.19763\n",
      "#Iter= 68\tTrain=0.715269\tTest=2.1977\n",
      "#Iter= 69\tTrain=0.715094\tTest=2.19778\n",
      "#Iter= 70\tTrain=0.714924\tTest=2.19786\n",
      "#Iter= 71\tTrain=0.714758\tTest=2.19794\n",
      "#Iter= 72\tTrain=0.714596\tTest=2.19802\n",
      "#Iter= 73\tTrain=0.714438\tTest=2.19811\n",
      "#Iter= 74\tTrain=0.714284\tTest=2.1982\n",
      "#Iter= 75\tTrain=0.714133\tTest=2.1983\n",
      "#Iter= 76\tTrain=0.713985\tTest=2.19842\n",
      "#Iter= 77\tTrain=0.71384\tTest=2.19854\n",
      "#Iter= 78\tTrain=0.713699\tTest=2.19867\n",
      "#Iter= 79\tTrain=0.713559\tTest=2.19881\n",
      "#Iter= 80\tTrain=0.713423\tTest=2.19895\n",
      "#Iter= 81\tTrain=0.713289\tTest=2.19911\n",
      "#Iter= 82\tTrain=0.713158\tTest=2.19926\n",
      "#Iter= 83\tTrain=0.713028\tTest=2.19942\n",
      "#Iter= 84\tTrain=0.712901\tTest=2.19959\n",
      "#Iter= 85\tTrain=0.712776\tTest=2.19976\n",
      "#Iter= 86\tTrain=0.712653\tTest=2.19993\n",
      "#Iter= 87\tTrain=0.712532\tTest=2.20012\n",
      "#Iter= 88\tTrain=0.712412\tTest=2.2003\n",
      "#Iter= 89\tTrain=0.712294\tTest=2.20049\n",
      "#Iter= 90\tTrain=0.712178\tTest=2.20068\n",
      "#Iter= 91\tTrain=0.712064\tTest=2.20087\n",
      "#Iter= 92\tTrain=0.71195\tTest=2.20107\n",
      "#Iter= 93\tTrain=0.711834\tTest=2.20126\n",
      "#Iter= 94\tTrain=0.711719\tTest=2.20145\n",
      "#Iter= 95\tTrain=0.711606\tTest=2.20164\n",
      "#Iter= 96\tTrain=0.711495\tTest=2.20183\n",
      "#Iter= 97\tTrain=0.711386\tTest=2.20201\n",
      "#Iter= 98\tTrain=0.71128\tTest=2.20219\n",
      "#Iter= 99\tTrain=0.711175\tTest=2.20237\n"
     ]
    }
   ],
   "source": [
    "!libFM.exe -task r -train second_train.txt -test second_test.txt -out second_result.txt -method als"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что на данной выборке алгоритм работает хуже. Похоже, что он переобучается.: <br>\n",
    "<li>для метода MCMC RMSE = 1.511\n",
    "<li>для метода ALS RMSE = 2.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id-пользователя + id-фильма + жанры фильма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mystery': 22518, 'Drama': 22513, 'Western': 22525, 'Sci-Fi': 22519, 'Short': 22526, 'Horror': 22517, 'Film-Noir': 22524, 'Crime': 22515, 'Romance': 22512, 'Fantasy': 22511, 'Musical': 22523, 'Animation': 22508, 'War': 22522, 'Adventure': 22507, 'Action': 22514, 'Comedy': 22510, 'Documentary': 22521, 'Children': 22509, 'Thriller': 22516, 'IMAX': 22520}\n",
      "{'Mystery': 22518, 'Drama': 22513, 'Western': 22525, 'Sci-Fi': 22519, 'Short': 22526, 'Horror': 22517, 'Film-Noir': 22524, 'Crime': 22515, 'Romance': 22512, 'Fantasy': 22511, 'Musical': 22523, 'Animation': 22508, 'War': 22522, 'Adventure': 22507, 'Action': 22514, 'Comedy': 22510, 'Documentary': 22521, 'Children': 22509, 'Thriller': 22516, 'IMAX': 22520}\n"
     ]
    }
   ],
   "source": [
    "genres_id = {}\n",
    "for genre in genres_df['genre'].unique():\n",
    "    genres_id[genre] = len(genres_id) + start_index\n",
    "start_index += len(genres_id)\n",
    "print genres_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_df = genres_df.groupby('movieID')\n",
    "def get_third_sample(df, file_name):\n",
    "    results = []\n",
    "    lines = []\n",
    "    with open(file_name, 'w') as fsampl:\n",
    "        for user, data in df.items():\n",
    "            for row in data.iterrows():\n",
    "                movie = int(row[1]['movieID'])\n",
    "                genres = list(grouped_df.get_group(movie)['genre'])\n",
    "                genres = ' '.join(['{}:1.0'.format(genres_id[genre]) for genre in genres])\n",
    "                example = '{0} {1}:1.0 {2}:1.0 {3}'.format(row[1]['rating'], users_id[user], movies_id[movie], genres)\n",
    "                #fsampl.write(example)\n",
    "                lines.append(example)\n",
    "                results.append(row[1]['rating'])\n",
    "        fsampl.write('\\n'.join(lines))\n",
    "        return results\n",
    "    \n",
    "get_third_sample(train_df, 'third_train.txt')\n",
    "test_results = get_third_sample(test_df, 'third_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=3921497\tnum_features=22527\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=29914\tnum_features=22526\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.914371\tTest=0.946268\n",
      "#Iter=  1\tTrain=0.809256\tTest=0.894107\n",
      "#Iter=  2\tTrain=0.789463\tTest=0.873963\n",
      "#Iter=  3\tTrain=0.778897\tTest=0.862813\n",
      "#Iter=  4\tTrain=0.771106\tTest=0.855708\n",
      "#Iter=  5\tTrain=0.764147\tTest=0.850509\n",
      "#Iter=  6\tTrain=0.758258\tTest=0.846522\n",
      "#Iter=  7\tTrain=0.7533\tTest=0.843315\n",
      "#Iter=  8\tTrain=0.748677\tTest=0.840753\n",
      "#Iter=  9\tTrain=0.745004\tTest=0.838026\n",
      "#Iter= 10\tTrain=0.741573\tTest=0.835965\n",
      "#Iter= 11\tTrain=0.738637\tTest=0.833837\n",
      "#Iter= 12\tTrain=0.735422\tTest=0.83236\n",
      "#Iter= 13\tTrain=0.732958\tTest=0.830854\n",
      "#Iter= 14\tTrain=0.730524\tTest=0.82933\n",
      "#Iter= 15\tTrain=0.728943\tTest=0.828336\n",
      "#Iter= 16\tTrain=0.72708\tTest=0.826979\n",
      "#Iter= 17\tTrain=0.725781\tTest=0.82581\n",
      "#Iter= 18\tTrain=0.724123\tTest=0.824769\n",
      "#Iter= 19\tTrain=0.723311\tTest=0.823872\n",
      "#Iter= 20\tTrain=0.722146\tTest=0.822928\n",
      "#Iter= 21\tTrain=0.721004\tTest=0.822197\n",
      "#Iter= 22\tTrain=0.719775\tTest=0.821514\n",
      "#Iter= 23\tTrain=0.719307\tTest=0.820726\n",
      "#Iter= 24\tTrain=0.71841\tTest=0.820002\n",
      "#Iter= 25\tTrain=0.717574\tTest=0.819411\n",
      "#Iter= 26\tTrain=0.716912\tTest=0.818951\n",
      "#Iter= 27\tTrain=0.71637\tTest=0.818173\n",
      "#Iter= 28\tTrain=0.715531\tTest=0.817775\n",
      "#Iter= 29\tTrain=0.715153\tTest=0.81719\n",
      "#Iter= 30\tTrain=0.714657\tTest=0.816875\n",
      "#Iter= 31\tTrain=0.714047\tTest=0.816417\n",
      "#Iter= 32\tTrain=0.71373\tTest=0.816092\n",
      "#Iter= 33\tTrain=0.713307\tTest=0.815795\n",
      "#Iter= 34\tTrain=0.71266\tTest=0.815674\n",
      "#Iter= 35\tTrain=0.712403\tTest=0.815252\n",
      "#Iter= 36\tTrain=0.711997\tTest=0.814852\n",
      "#Iter= 37\tTrain=0.711707\tTest=0.81441\n",
      "#Iter= 38\tTrain=0.711423\tTest=0.814131\n",
      "#Iter= 39\tTrain=0.711319\tTest=0.813967\n",
      "#Iter= 40\tTrain=0.710917\tTest=0.813669\n",
      "#Iter= 41\tTrain=0.710345\tTest=0.813509\n",
      "#Iter= 42\tTrain=0.71017\tTest=0.813229\n",
      "#Iter= 43\tTrain=0.710115\tTest=0.812941\n",
      "#Iter= 44\tTrain=0.709729\tTest=0.812531\n",
      "#Iter= 45\tTrain=0.709444\tTest=0.812222\n",
      "#Iter= 46\tTrain=0.709497\tTest=0.812066\n",
      "#Iter= 47\tTrain=0.709413\tTest=0.811915\n",
      "#Iter= 48\tTrain=0.708993\tTest=0.811723\n",
      "#Iter= 49\tTrain=0.708891\tTest=0.81164\n",
      "#Iter= 50\tTrain=0.708652\tTest=0.811333\n",
      "#Iter= 51\tTrain=0.708712\tTest=0.811218\n",
      "#Iter= 52\tTrain=0.708534\tTest=0.811048\n",
      "#Iter= 53\tTrain=0.708284\tTest=0.810911\n",
      "#Iter= 54\tTrain=0.708395\tTest=0.810827\n",
      "#Iter= 55\tTrain=0.708388\tTest=0.81069\n",
      "#Iter= 56\tTrain=0.708453\tTest=0.810742\n",
      "#Iter= 57\tTrain=0.707954\tTest=0.810723\n",
      "#Iter= 58\tTrain=0.707923\tTest=0.810666\n",
      "#Iter= 59\tTrain=0.707465\tTest=0.810541\n",
      "#Iter= 60\tTrain=0.707655\tTest=0.810378\n",
      "#Iter= 61\tTrain=0.707737\tTest=0.810255\n",
      "#Iter= 62\tTrain=0.707394\tTest=0.810191\n",
      "#Iter= 63\tTrain=0.707139\tTest=0.810075\n",
      "#Iter= 64\tTrain=0.707229\tTest=0.810022\n",
      "#Iter= 65\tTrain=0.707566\tTest=0.809939\n",
      "#Iter= 66\tTrain=0.707382\tTest=0.809888\n",
      "#Iter= 67\tTrain=0.707409\tTest=0.809787\n",
      "#Iter= 68\tTrain=0.707497\tTest=0.80981\n",
      "#Iter= 69\tTrain=0.707141\tTest=0.809708\n",
      "#Iter= 70\tTrain=0.707017\tTest=0.809757\n",
      "#Iter= 71\tTrain=0.707147\tTest=0.809736\n",
      "#Iter= 72\tTrain=0.707183\tTest=0.809682\n",
      "#Iter= 73\tTrain=0.707291\tTest=0.809622\n",
      "#Iter= 74\tTrain=0.707176\tTest=0.809547\n",
      "#Iter= 75\tTrain=0.706715\tTest=0.809492\n",
      "#Iter= 76\tTrain=0.707093\tTest=0.809377\n",
      "#Iter= 77\tTrain=0.70707\tTest=0.809379\n",
      "#Iter= 78\tTrain=0.706839\tTest=0.809344\n",
      "#Iter= 79\tTrain=0.70691\tTest=0.809351\n",
      "#Iter= 80\tTrain=0.706934\tTest=0.80934\n",
      "#Iter= 81\tTrain=0.706852\tTest=0.809282\n",
      "#Iter= 82\tTrain=0.706516\tTest=0.809209\n",
      "#Iter= 83\tTrain=0.706865\tTest=0.809135\n",
      "#Iter= 84\tTrain=0.707016\tTest=0.809048\n",
      "#Iter= 85\tTrain=0.707242\tTest=0.809015\n",
      "#Iter= 86\tTrain=0.707116\tTest=0.808966\n",
      "#Iter= 87\tTrain=0.706975\tTest=0.808934\n",
      "#Iter= 88\tTrain=0.706975\tTest=0.808844\n",
      "#Iter= 89\tTrain=0.706804\tTest=0.808853\n",
      "#Iter= 90\tTrain=0.706698\tTest=0.808813\n",
      "#Iter= 91\tTrain=0.706674\tTest=0.808735\n",
      "#Iter= 92\tTrain=0.706976\tTest=0.808659\n",
      "#Iter= 93\tTrain=0.70689\tTest=0.808582\n",
      "#Iter= 94\tTrain=0.706691\tTest=0.808533\n",
      "#Iter= 95\tTrain=0.706829\tTest=0.808457\n",
      "#Iter= 96\tTrain=0.706609\tTest=0.808383\n",
      "#Iter= 97\tTrain=0.706633\tTest=0.808335\n",
      "#Iter= 98\tTrain=0.706756\tTest=0.808343\n",
      "#Iter= 99\tTrain=0.706666\tTest=0.80826\n",
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=3921497\tnum_features=22527\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=29914\tnum_features=22526\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.914371\tTest=0.946268\n",
      "#Iter=  1\tTrain=0.809256\tTest=0.894107\n",
      "#Iter=  2\tTrain=0.789463\tTest=0.873963\n",
      "#Iter=  3\tTrain=0.778897\tTest=0.862813\n",
      "#Iter=  4\tTrain=0.771106\tTest=0.855708\n",
      "#Iter=  5\tTrain=0.764147\tTest=0.850509\n",
      "#Iter=  6\tTrain=0.758258\tTest=0.846522\n",
      "#Iter=  7\tTrain=0.7533\tTest=0.843315\n",
      "#Iter=  8\tTrain=0.748677\tTest=0.840753\n",
      "#Iter=  9\tTrain=0.745004\tTest=0.838026\n",
      "#Iter= 10\tTrain=0.741573\tTest=0.835965\n",
      "#Iter= 11\tTrain=0.738637\tTest=0.833837\n",
      "#Iter= 12\tTrain=0.735422\tTest=0.83236\n",
      "#Iter= 13\tTrain=0.732958\tTest=0.830854\n",
      "#Iter= 14\tTrain=0.730524\tTest=0.82933\n",
      "#Iter= 15\tTrain=0.728943\tTest=0.828336\n",
      "#Iter= 16\tTrain=0.72708\tTest=0.826979\n",
      "#Iter= 17\tTrain=0.725781\tTest=0.82581\n",
      "#Iter= 18\tTrain=0.724123\tTest=0.824769\n",
      "#Iter= 19\tTrain=0.723311\tTest=0.823872\n",
      "#Iter= 20\tTrain=0.722146\tTest=0.822928\n",
      "#Iter= 21\tTrain=0.721004\tTest=0.822197\n",
      "#Iter= 22\tTrain=0.719775\tTest=0.821514\n",
      "#Iter= 23\tTrain=0.719307\tTest=0.820726\n",
      "#Iter= 24\tTrain=0.71841\tTest=0.820002\n",
      "#Iter= 25\tTrain=0.717574\tTest=0.819411\n",
      "#Iter= 26\tTrain=0.716912\tTest=0.818951\n",
      "#Iter= 27\tTrain=0.71637\tTest=0.818173\n",
      "#Iter= 28\tTrain=0.715531\tTest=0.817775\n",
      "#Iter= 29\tTrain=0.715153\tTest=0.81719\n",
      "#Iter= 30\tTrain=0.714657\tTest=0.816875\n",
      "#Iter= 31\tTrain=0.714047\tTest=0.816417\n",
      "#Iter= 32\tTrain=0.71373\tTest=0.816092\n",
      "#Iter= 33\tTrain=0.713307\tTest=0.815795\n",
      "#Iter= 34\tTrain=0.71266\tTest=0.815674\n",
      "#Iter= 35\tTrain=0.712403\tTest=0.815252\n",
      "#Iter= 36\tTrain=0.711997\tTest=0.814852\n",
      "#Iter= 37\tTrain=0.711707\tTest=0.81441\n",
      "#Iter= 38\tTrain=0.711423\tTest=0.814131\n",
      "#Iter= 39\tTrain=0.711319\tTest=0.813967\n",
      "#Iter= 40\tTrain=0.710917\tTest=0.813669\n",
      "#Iter= 41\tTrain=0.710345\tTest=0.813509\n",
      "#Iter= 42\tTrain=0.71017\tTest=0.813229\n",
      "#Iter= 43\tTrain=0.710115\tTest=0.812941\n",
      "#Iter= 44\tTrain=0.709729\tTest=0.812531\n",
      "#Iter= 45\tTrain=0.709444\tTest=0.812222\n",
      "#Iter= 46\tTrain=0.709497\tTest=0.812066\n",
      "#Iter= 47\tTrain=0.709413\tTest=0.811915\n",
      "#Iter= 48\tTrain=0.708993\tTest=0.811723\n",
      "#Iter= 49\tTrain=0.708891\tTest=0.81164\n",
      "#Iter= 50\tTrain=0.708652\tTest=0.811333\n",
      "#Iter= 51\tTrain=0.708712\tTest=0.811218\n",
      "#Iter= 52\tTrain=0.708534\tTest=0.811048\n",
      "#Iter= 53\tTrain=0.708284\tTest=0.810911\n",
      "#Iter= 54\tTrain=0.708395\tTest=0.810827\n",
      "#Iter= 55\tTrain=0.708388\tTest=0.81069\n",
      "#Iter= 56\tTrain=0.708453\tTest=0.810742\n",
      "#Iter= 57\tTrain=0.707954\tTest=0.810723\n",
      "#Iter= 58\tTrain=0.707923\tTest=0.810666\n",
      "#Iter= 59\tTrain=0.707465\tTest=0.810541\n",
      "#Iter= 60\tTrain=0.707655\tTest=0.810378\n",
      "#Iter= 61\tTrain=0.707737\tTest=0.810255\n",
      "#Iter= 62\tTrain=0.707394\tTest=0.810191\n",
      "#Iter= 63\tTrain=0.707139\tTest=0.810075\n",
      "#Iter= 64\tTrain=0.707229\tTest=0.810022\n",
      "#Iter= 65\tTrain=0.707566\tTest=0.809939\n",
      "#Iter= 66\tTrain=0.707382\tTest=0.809888\n",
      "#Iter= 67\tTrain=0.707409\tTest=0.809787\n",
      "#Iter= 68\tTrain=0.707497\tTest=0.80981\n",
      "#Iter= 69\tTrain=0.707141\tTest=0.809708\n",
      "#Iter= 70\tTrain=0.707017\tTest=0.809757\n",
      "#Iter= 71\tTrain=0.707147\tTest=0.809736\n",
      "#Iter= 72\tTrain=0.707183\tTest=0.809682\n",
      "#Iter= 73\tTrain=0.707291\tTest=0.809622\n",
      "#Iter= 74\tTrain=0.707176\tTest=0.809547\n",
      "#Iter= 75\tTrain=0.706715\tTest=0.809492\n",
      "#Iter= 76\tTrain=0.707093\tTest=0.809377\n",
      "#Iter= 77\tTrain=0.70707\tTest=0.809379\n",
      "#Iter= 78\tTrain=0.706839\tTest=0.809344\n",
      "#Iter= 79\tTrain=0.70691\tTest=0.809351\n",
      "#Iter= 80\tTrain=0.706934\tTest=0.80934\n",
      "#Iter= 81\tTrain=0.706852\tTest=0.809282\n",
      "#Iter= 82\tTrain=0.706516\tTest=0.809209\n",
      "#Iter= 83\tTrain=0.706865\tTest=0.809135\n",
      "#Iter= 84\tTrain=0.707016\tTest=0.809048\n",
      "#Iter= 85\tTrain=0.707242\tTest=0.809015\n",
      "#Iter= 86\tTrain=0.707116\tTest=0.808966\n",
      "#Iter= 87\tTrain=0.706975\tTest=0.808934\n",
      "#Iter= 88\tTrain=0.706975\tTest=0.808844\n",
      "#Iter= 89\tTrain=0.706804\tTest=0.808853\n",
      "#Iter= 90\tTrain=0.706698\tTest=0.808813\n",
      "#Iter= 91\tTrain=0.706674\tTest=0.808735\n",
      "#Iter= 92\tTrain=0.706976\tTest=0.808659\n",
      "#Iter= 93\tTrain=0.70689\tTest=0.808582\n",
      "#Iter= 94\tTrain=0.706691\tTest=0.808533\n",
      "#Iter= 95\tTrain=0.706829\tTest=0.808457\n",
      "#Iter= 96\tTrain=0.706609\tTest=0.808383\n",
      "#Iter= 97\tTrain=0.706633\tTest=0.808335\n",
      "#Iter= 98\tTrain=0.706756\tTest=0.808343\n",
      "#Iter= 99\tTrain=0.706666\tTest=0.80826\n"
     ]
    }
   ],
   "source": [
    "!libFM.exe -task r -train third_train.txt -test third_test.txt -out third_result.txt -method mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.808\n",
      "RMSE: 0.808\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE: {:.3f}'.format(calculate_RMSE(test_results, read_results('third_result.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=3921497\tnum_features=22527\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=29914\tnum_features=22526\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.761512\tTest=0.917516\n",
      "#Iter=  1\tTrain=0.730904\tTest=0.91527\n",
      "#Iter=  2\tTrain=0.71392\tTest=0.915186\n",
      "#Iter=  3\tTrain=0.704291\tTest=0.917187\n",
      "#Iter=  4\tTrain=0.69787\tTest=0.919591\n",
      "#Iter=  5\tTrain=0.693217\tTest=0.922077\n",
      "#Iter=  6\tTrain=0.689694\tTest=0.924755\n",
      "#Iter=  7\tTrain=0.686945\tTest=0.927491\n",
      "#Iter=  8\tTrain=0.68475\tTest=0.929935\n",
      "#Iter=  9\tTrain=0.682962\tTest=0.93207\n",
      "#Iter= 10\tTrain=0.681476\tTest=0.933928\n",
      "#Iter= 11\tTrain=0.680214\tTest=0.935556\n",
      "#Iter= 12\tTrain=0.679129\tTest=0.93699\n",
      "#Iter= 13\tTrain=0.678184\tTest=0.938258\n",
      "#Iter= 14\tTrain=0.677356\tTest=0.939395\n",
      "#Iter= 15\tTrain=0.676622\tTest=0.940435\n",
      "#Iter= 16\tTrain=0.675968\tTest=0.941402\n",
      "#Iter= 17\tTrain=0.675381\tTest=0.942311\n",
      "#Iter= 18\tTrain=0.67485\tTest=0.943153\n",
      "#Iter= 19\tTrain=0.674368\tTest=0.943937\n",
      "#Iter= 20\tTrain=0.673928\tTest=0.944667\n",
      "#Iter= 21\tTrain=0.673523\tTest=0.945322\n",
      "#Iter= 22\tTrain=0.67315\tTest=0.94589\n",
      "#Iter= 23\tTrain=0.672803\tTest=0.946403\n",
      "#Iter= 24\tTrain=0.672481\tTest=0.946863\n",
      "#Iter= 25\tTrain=0.67218\tTest=0.947269\n",
      "#Iter= 26\tTrain=0.671897\tTest=0.947634\n",
      "#Iter= 27\tTrain=0.671631\tTest=0.947963\n",
      "#Iter= 28\tTrain=0.67138\tTest=0.948263\n",
      "#Iter= 29\tTrain=0.671141\tTest=0.948549\n",
      "#Iter= 30\tTrain=0.670915\tTest=0.94884\n",
      "#Iter= 31\tTrain=0.670699\tTest=0.949142\n",
      "#Iter= 32\tTrain=0.670494\tTest=0.949458\n",
      "#Iter= 33\tTrain=0.670298\tTest=0.949788\n",
      "#Iter= 34\tTrain=0.670112\tTest=0.950134\n",
      "#Iter= 35\tTrain=0.669934\tTest=0.950487\n",
      "#Iter= 36\tTrain=0.669764\tTest=0.950847\n",
      "#Iter= 37\tTrain=0.669602\tTest=0.951208\n",
      "#Iter= 38\tTrain=0.669447\tTest=0.951562\n",
      "#Iter= 39\tTrain=0.669299\tTest=0.951899\n",
      "#Iter= 40\tTrain=0.669156\tTest=0.952221\n",
      "#Iter= 41\tTrain=0.66902\tTest=0.95253\n",
      "#Iter= 42\tTrain=0.668889\tTest=0.952828\n",
      "#Iter= 43\tTrain=0.668762\tTest=0.95312\n",
      "#Iter= 44\tTrain=0.668641\tTest=0.95341\n",
      "#Iter= 45\tTrain=0.668524\tTest=0.953703\n",
      "#Iter= 46\tTrain=0.668412\tTest=0.953995\n",
      "#Iter= 47\tTrain=0.668304\tTest=0.954288\n",
      "#Iter= 48\tTrain=0.668199\tTest=0.954583\n",
      "#Iter= 49\tTrain=0.668099\tTest=0.954878\n",
      "#Iter= 50\tTrain=0.668001\tTest=0.955173\n",
      "#Iter= 51\tTrain=0.667908\tTest=0.955466\n",
      "#Iter= 52\tTrain=0.667817\tTest=0.955758\n",
      "#Iter= 53\tTrain=0.66773\tTest=0.956046\n",
      "#Iter= 54\tTrain=0.667646\tTest=0.956329\n",
      "#Iter= 55\tTrain=0.667564\tTest=0.956608\n",
      "#Iter= 56\tTrain=0.667485\tTest=0.956884\n",
      "#Iter= 57\tTrain=0.667409\tTest=0.957154\n",
      "#Iter= 58\tTrain=0.667335\tTest=0.957419\n",
      "#Iter= 59\tTrain=0.667264\tTest=0.957677\n",
      "#Iter= 60\tTrain=0.667195\tTest=0.95793\n",
      "#Iter= 61\tTrain=0.667128\tTest=0.958179\n",
      "#Iter= 62\tTrain=0.667063\tTest=0.958424\n",
      "#Iter= 63\tTrain=0.666999\tTest=0.958667\n",
      "#Iter= 64\tTrain=0.666938\tTest=0.958906\n",
      "#Iter= 65\tTrain=0.666879\tTest=0.959142\n",
      "#Iter= 66\tTrain=0.666821\tTest=0.959376\n",
      "#Iter= 67\tTrain=0.666765\tTest=0.959608\n",
      "#Iter= 68\tTrain=0.666711\tTest=0.959838\n",
      "#Iter= 69\tTrain=0.666658\tTest=0.960066\n",
      "#Iter= 70\tTrain=0.666607\tTest=0.960293\n",
      "#Iter= 71\tTrain=0.666558\tTest=0.960517\n",
      "#Iter= 72\tTrain=0.666509\tTest=0.96074\n",
      "#Iter= 73\tTrain=0.666462\tTest=0.960961\n",
      "#Iter= 74\tTrain=0.666416\tTest=0.961182\n",
      "#Iter= 75\tTrain=0.666372\tTest=0.961401\n",
      "#Iter= 76\tTrain=0.666328\tTest=0.961619\n",
      "#Iter= 77\tTrain=0.666286\tTest=0.961834\n",
      "#Iter= 78\tTrain=0.666244\tTest=0.962048\n",
      "#Iter= 79\tTrain=0.666204\tTest=0.96226\n",
      "#Iter= 80\tTrain=0.666164\tTest=0.962472\n",
      "#Iter= 81\tTrain=0.666126\tTest=0.962682\n",
      "#Iter= 82\tTrain=0.666088\tTest=0.962892\n",
      "#Iter= 83\tTrain=0.666052\tTest=0.963101\n",
      "#Iter= 84\tTrain=0.666015\tTest=0.963309\n",
      "#Iter= 85\tTrain=0.66598\tTest=0.963518\n",
      "#Iter= 86\tTrain=0.665946\tTest=0.963726\n",
      "#Iter= 87\tTrain=0.665912\tTest=0.963932\n",
      "#Iter= 88\tTrain=0.665879\tTest=0.964138\n",
      "#Iter= 89\tTrain=0.665846\tTest=0.964343\n",
      "#Iter= 90\tTrain=0.665814\tTest=0.964546\n",
      "#Iter= 91\tTrain=0.665783\tTest=0.964747\n",
      "#Iter= 92\tTrain=0.665752\tTest=0.964947\n",
      "#Iter= 93\tTrain=0.665722\tTest=0.965145\n",
      "#Iter= 94\tTrain=0.665692\tTest=0.965341\n",
      "#Iter= 95\tTrain=0.665663\tTest=0.965535\n",
      "#Iter= 96\tTrain=0.665635\tTest=0.965729\n",
      "#Iter= 97\tTrain=0.665607\tTest=0.965922\n",
      "#Iter= 98\tTrain=0.66558\tTest=0.966115\n",
      "#Iter= 99\tTrain=0.665553\tTest=0.966308\n",
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=3921497\tnum_features=22527\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=29914\tnum_features=22526\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.761512\tTest=0.917516\n",
      "#Iter=  1\tTrain=0.730904\tTest=0.91527\n",
      "#Iter=  2\tTrain=0.71392\tTest=0.915186\n",
      "#Iter=  3\tTrain=0.704291\tTest=0.917187\n",
      "#Iter=  4\tTrain=0.69787\tTest=0.919591\n",
      "#Iter=  5\tTrain=0.693217\tTest=0.922077\n",
      "#Iter=  6\tTrain=0.689694\tTest=0.924755\n",
      "#Iter=  7\tTrain=0.686945\tTest=0.927491\n",
      "#Iter=  8\tTrain=0.68475\tTest=0.929935\n",
      "#Iter=  9\tTrain=0.682962\tTest=0.93207\n",
      "#Iter= 10\tTrain=0.681476\tTest=0.933928\n",
      "#Iter= 11\tTrain=0.680214\tTest=0.935556\n",
      "#Iter= 12\tTrain=0.679129\tTest=0.93699\n",
      "#Iter= 13\tTrain=0.678184\tTest=0.938258\n",
      "#Iter= 14\tTrain=0.677356\tTest=0.939395\n",
      "#Iter= 15\tTrain=0.676622\tTest=0.940435\n",
      "#Iter= 16\tTrain=0.675968\tTest=0.941402\n",
      "#Iter= 17\tTrain=0.675381\tTest=0.942311\n",
      "#Iter= 18\tTrain=0.67485\tTest=0.943153\n",
      "#Iter= 19\tTrain=0.674368\tTest=0.943937\n",
      "#Iter= 20\tTrain=0.673928\tTest=0.944667\n",
      "#Iter= 21\tTrain=0.673523\tTest=0.945322\n",
      "#Iter= 22\tTrain=0.67315\tTest=0.94589\n",
      "#Iter= 23\tTrain=0.672803\tTest=0.946403\n",
      "#Iter= 24\tTrain=0.672481\tTest=0.946863\n",
      "#Iter= 25\tTrain=0.67218\tTest=0.947269\n",
      "#Iter= 26\tTrain=0.671897\tTest=0.947634\n",
      "#Iter= 27\tTrain=0.671631\tTest=0.947963\n",
      "#Iter= 28\tTrain=0.67138\tTest=0.948263\n",
      "#Iter= 29\tTrain=0.671141\tTest=0.948549\n",
      "#Iter= 30\tTrain=0.670915\tTest=0.94884\n",
      "#Iter= 31\tTrain=0.670699\tTest=0.949142\n",
      "#Iter= 32\tTrain=0.670494\tTest=0.949458\n",
      "#Iter= 33\tTrain=0.670298\tTest=0.949788\n",
      "#Iter= 34\tTrain=0.670112\tTest=0.950134\n",
      "#Iter= 35\tTrain=0.669934\tTest=0.950487\n",
      "#Iter= 36\tTrain=0.669764\tTest=0.950847\n",
      "#Iter= 37\tTrain=0.669602\tTest=0.951208\n",
      "#Iter= 38\tTrain=0.669447\tTest=0.951562\n",
      "#Iter= 39\tTrain=0.669299\tTest=0.951899\n",
      "#Iter= 40\tTrain=0.669156\tTest=0.952221\n",
      "#Iter= 41\tTrain=0.66902\tTest=0.95253\n",
      "#Iter= 42\tTrain=0.668889\tTest=0.952828\n",
      "#Iter= 43\tTrain=0.668762\tTest=0.95312\n",
      "#Iter= 44\tTrain=0.668641\tTest=0.95341\n",
      "#Iter= 45\tTrain=0.668524\tTest=0.953703\n",
      "#Iter= 46\tTrain=0.668412\tTest=0.953995\n",
      "#Iter= 47\tTrain=0.668304\tTest=0.954288\n",
      "#Iter= 48\tTrain=0.668199\tTest=0.954583\n",
      "#Iter= 49\tTrain=0.668099\tTest=0.954878\n",
      "#Iter= 50\tTrain=0.668001\tTest=0.955173\n",
      "#Iter= 51\tTrain=0.667908\tTest=0.955466\n",
      "#Iter= 52\tTrain=0.667817\tTest=0.955758\n",
      "#Iter= 53\tTrain=0.66773\tTest=0.956046\n",
      "#Iter= 54\tTrain=0.667646\tTest=0.956329\n",
      "#Iter= 55\tTrain=0.667564\tTest=0.956608\n",
      "#Iter= 56\tTrain=0.667485\tTest=0.956884\n",
      "#Iter= 57\tTrain=0.667409\tTest=0.957154\n",
      "#Iter= 58\tTrain=0.667335\tTest=0.957419\n",
      "#Iter= 59\tTrain=0.667264\tTest=0.957677\n",
      "#Iter= 60\tTrain=0.667195\tTest=0.95793\n",
      "#Iter= 61\tTrain=0.667128\tTest=0.958179\n",
      "#Iter= 62\tTrain=0.667063\tTest=0.958424\n",
      "#Iter= 63\tTrain=0.666999\tTest=0.958667\n",
      "#Iter= 64\tTrain=0.666938\tTest=0.958906\n",
      "#Iter= 65\tTrain=0.666879\tTest=0.959142\n",
      "#Iter= 66\tTrain=0.666821\tTest=0.959376\n",
      "#Iter= 67\tTrain=0.666765\tTest=0.959608\n",
      "#Iter= 68\tTrain=0.666711\tTest=0.959838\n",
      "#Iter= 69\tTrain=0.666658\tTest=0.960066\n",
      "#Iter= 70\tTrain=0.666607\tTest=0.960293\n",
      "#Iter= 71\tTrain=0.666558\tTest=0.960517\n",
      "#Iter= 72\tTrain=0.666509\tTest=0.96074\n",
      "#Iter= 73\tTrain=0.666462\tTest=0.960961\n",
      "#Iter= 74\tTrain=0.666416\tTest=0.961182\n",
      "#Iter= 75\tTrain=0.666372\tTest=0.961401\n",
      "#Iter= 76\tTrain=0.666328\tTest=0.961619\n",
      "#Iter= 77\tTrain=0.666286\tTest=0.961834\n",
      "#Iter= 78\tTrain=0.666244\tTest=0.962048\n",
      "#Iter= 79\tTrain=0.666204\tTest=0.96226\n",
      "#Iter= 80\tTrain=0.666164\tTest=0.962472\n",
      "#Iter= 81\tTrain=0.666126\tTest=0.962682\n",
      "#Iter= 82\tTrain=0.666088\tTest=0.962892\n",
      "#Iter= 83\tTrain=0.666052\tTest=0.963101\n",
      "#Iter= 84\tTrain=0.666015\tTest=0.963309\n",
      "#Iter= 85\tTrain=0.66598\tTest=0.963518\n",
      "#Iter= 86\tTrain=0.665946\tTest=0.963726\n",
      "#Iter= 87\tTrain=0.665912\tTest=0.963932\n",
      "#Iter= 88\tTrain=0.665879\tTest=0.964138\n",
      "#Iter= 89\tTrain=0.665846\tTest=0.964343\n",
      "#Iter= 90\tTrain=0.665814\tTest=0.964546\n",
      "#Iter= 91\tTrain=0.665783\tTest=0.964747\n",
      "#Iter= 92\tTrain=0.665752\tTest=0.964947\n",
      "#Iter= 93\tTrain=0.665722\tTest=0.965145\n",
      "#Iter= 94\tTrain=0.665692\tTest=0.965341\n",
      "#Iter= 95\tTrain=0.665663\tTest=0.965535\n",
      "#Iter= 96\tTrain=0.665635\tTest=0.965729\n",
      "#Iter= 97\tTrain=0.665607\tTest=0.965922\n",
      "#Iter= 98\tTrain=0.66558\tTest=0.966115\n",
      "#Iter= 99\tTrain=0.665553\tTest=0.966308\n"
     ]
    }
   ],
   "source": [
    "!libFM.exe -task r -train third_train.txt -test third_test.txt -out third_result.txt -method als"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жанры, не значительно, но все же повысили точность нашей модели:\n",
    "<li>для метода MCMC RMSE = 0.808\n",
    "<li>для метода ALS RMSE = 0.966"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id-пользователя + id-фильма + жанры фильма + киноперсоны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем рассматривать только актеров с самым высоким рейтингом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actors_id = {}\n",
    "for actor in actors_df['actorID'].unique():\n",
    "    actors_id[actor] = len(actors_id) + start_index\n",
    "start_index += len(actors_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actors_grouped_df = actors_df.groupby('movieID')\n",
    "genres_grouped_df = genres_df.groupby('movieID')\n",
    "def get_fourth_sample(df, file_name, prev_file_name):\n",
    "    results = []\n",
    "    lines = []\n",
    "    f_prev = open(prev_file_name, 'r')\n",
    "    with open(file_name, 'w') as fsampl:\n",
    "        for user, data in df.items():\n",
    "            for row in data.iterrows():\n",
    "                prev = f_prev.readline().strip()\n",
    "                movie = int(row[1]['movieID'])\n",
    "                actors = list(actors_grouped_df.get_group(movie).sort('ranking', ascending=False)['actorID'])[:5] if movie in actors_grouped_df.groups.keys() else []\n",
    "                actors = ' '.join(['{}:1.0'.format(actors_id[actor]) for actor in actors])\n",
    "                lines.append(prev + ' ' + actors)\n",
    "                results.append(row[1]['rating'])\n",
    "        fsampl.write('\\n'.join(lines))\n",
    "        return results\n",
    "    \n",
    "get_fourth_sample(train_df, 'fourth_train.txt', 'third_train.txt')\n",
    "test_results = get_fourth_sample(test_df, 'fourth_test.txt', 'third_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=8086490\tnum_features=117843\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=60952\tnum_features=117848\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.890209\tTest=0.940033\n",
      "#Iter=  1\tTrain=0.800588\tTest=0.889331\n",
      "#Iter=  2\tTrain=0.783927\tTest=0.873686\n",
      "#Iter=  3\tTrain=0.769235\tTest=0.865875\n",
      "#Iter=  4\tTrain=0.759988\tTest=0.859156\n",
      "#Iter=  5\tTrain=0.754087\tTest=0.854297\n",
      "#Iter=  6\tTrain=0.748968\tTest=0.850454\n",
      "#Iter=  7\tTrain=0.745354\tTest=0.84727\n",
      "#Iter=  8\tTrain=0.742148\tTest=0.844761\n",
      "#Iter=  9\tTrain=0.739311\tTest=0.842449\n",
      "#Iter= 10\tTrain=0.737018\tTest=0.840816\n",
      "#Iter= 11\tTrain=0.735105\tTest=0.839074\n",
      "#Iter= 12\tTrain=0.732933\tTest=0.837644\n",
      "#Iter= 13\tTrain=0.731611\tTest=0.83623\n",
      "#Iter= 14\tTrain=0.730214\tTest=0.834807\n",
      "#Iter= 15\tTrain=0.729042\tTest=0.833771\n",
      "#Iter= 16\tTrain=0.728\tTest=0.832904\n",
      "#Iter= 17\tTrain=0.726881\tTest=0.831757\n",
      "#Iter= 18\tTrain=0.725876\tTest=0.830716\n",
      "#Iter= 19\tTrain=0.72493\tTest=0.829885\n",
      "#Iter= 20\tTrain=0.724106\tTest=0.829164\n",
      "#Iter= 21\tTrain=0.723096\tTest=0.828358\n",
      "#Iter= 22\tTrain=0.72265\tTest=0.827575\n",
      "#Iter= 23\tTrain=0.721973\tTest=0.826896\n",
      "#Iter= 24\tTrain=0.721386\tTest=0.826289\n",
      "#Iter= 25\tTrain=0.721082\tTest=0.82551\n",
      "#Iter= 26\tTrain=0.72023\tTest=0.824807\n",
      "#Iter= 27\tTrain=0.719624\tTest=0.824326\n",
      "#Iter= 28\tTrain=0.719214\tTest=0.823471\n",
      "#Iter= 29\tTrain=0.718616\tTest=0.8231\n",
      "#Iter= 30\tTrain=0.718542\tTest=0.822667\n",
      "#Iter= 31\tTrain=0.717767\tTest=0.822177\n",
      "#Iter= 32\tTrain=0.717312\tTest=0.821706\n",
      "#Iter= 33\tTrain=0.717102\tTest=0.821285\n",
      "#Iter= 34\tTrain=0.716894\tTest=0.820914\n",
      "#Iter= 35\tTrain=0.716486\tTest=0.820491\n",
      "#Iter= 36\tTrain=0.71634\tTest=0.820148\n",
      "#Iter= 37\tTrain=0.716178\tTest=0.819743\n",
      "#Iter= 38\tTrain=0.715699\tTest=0.819378\n",
      "#Iter= 39\tTrain=0.715545\tTest=0.818997\n",
      "#Iter= 40\tTrain=0.71534\tTest=0.818588\n",
      "#Iter= 41\tTrain=0.71506\tTest=0.818405\n",
      "#Iter= 42\tTrain=0.7149\tTest=0.818198\n",
      "#Iter= 43\tTrain=0.714708\tTest=0.818029\n",
      "#Iter= 44\tTrain=0.71431\tTest=0.817746\n",
      "#Iter= 45\tTrain=0.714023\tTest=0.817388\n",
      "#Iter= 46\tTrain=0.714004\tTest=0.817143\n",
      "#Iter= 47\tTrain=0.713537\tTest=0.81688\n",
      "#Iter= 48\tTrain=0.713396\tTest=0.816677\n",
      "#Iter= 49\tTrain=0.713502\tTest=0.816402\n",
      "#Iter= 50\tTrain=0.713259\tTest=0.81614\n",
      "#Iter= 51\tTrain=0.713061\tTest=0.816002\n",
      "#Iter= 52\tTrain=0.712786\tTest=0.815807\n",
      "#Iter= 53\tTrain=0.712758\tTest=0.815725\n",
      "#Iter= 54\tTrain=0.712813\tTest=0.815622\n",
      "#Iter= 55\tTrain=0.712314\tTest=0.815501\n",
      "#Iter= 56\tTrain=0.712348\tTest=0.815323\n",
      "#Iter= 57\tTrain=0.712192\tTest=0.81514\n",
      "#Iter= 58\tTrain=0.712296\tTest=0.814943\n",
      "#Iter= 59\tTrain=0.711905\tTest=0.814773\n",
      "#Iter= 60\tTrain=0.712198\tTest=0.814621\n",
      "#Iter= 61\tTrain=0.712094\tTest=0.814417\n",
      "#Iter= 62\tTrain=0.711993\tTest=0.814235\n",
      "#Iter= 63\tTrain=0.711855\tTest=0.814166\n",
      "#Iter= 64\tTrain=0.711824\tTest=0.814008\n",
      "#Iter= 65\tTrain=0.711759\tTest=0.813885\n",
      "#Iter= 66\tTrain=0.711509\tTest=0.813688\n",
      "#Iter= 67\tTrain=0.711544\tTest=0.81354\n",
      "#Iter= 68\tTrain=0.71155\tTest=0.81342\n",
      "#Iter= 69\tTrain=0.711222\tTest=0.813356\n",
      "#Iter= 70\tTrain=0.711473\tTest=0.813175\n",
      "#Iter= 71\tTrain=0.711154\tTest=0.81297\n",
      "#Iter= 72\tTrain=0.710976\tTest=0.81278\n",
      "#Iter= 73\tTrain=0.711152\tTest=0.812701\n",
      "#Iter= 74\tTrain=0.71086\tTest=0.812564\n",
      "#Iter= 75\tTrain=0.710729\tTest=0.812405\n",
      "#Iter= 76\tTrain=0.710796\tTest=0.812257\n",
      "#Iter= 77\tTrain=0.71069\tTest=0.81215\n",
      "#Iter= 78\tTrain=0.710736\tTest=0.812052\n",
      "#Iter= 79\tTrain=0.710604\tTest=0.812003\n",
      "#Iter= 80\tTrain=0.7106\tTest=0.811944\n",
      "#Iter= 81\tTrain=0.710628\tTest=0.811835\n",
      "#Iter= 82\tTrain=0.710557\tTest=0.811687\n",
      "#Iter= 83\tTrain=0.710399\tTest=0.811617\n",
      "#Iter= 84\tTrain=0.71018\tTest=0.81153\n",
      "#Iter= 85\tTrain=0.710391\tTest=0.811472\n",
      "#Iter= 86\tTrain=0.710413\tTest=0.811479\n",
      "#Iter= 87\tTrain=0.710273\tTest=0.811413\n",
      "#Iter= 88\tTrain=0.710214\tTest=0.811389\n",
      "#Iter= 89\tTrain=0.710166\tTest=0.811322\n",
      "#Iter= 90\tTrain=0.710217\tTest=0.811258\n",
      "#Iter= 91\tTrain=0.710084\tTest=0.811217\n",
      "#Iter= 92\tTrain=0.710355\tTest=0.811088\n",
      "#Iter= 93\tTrain=0.710306\tTest=0.810999\n",
      "#Iter= 94\tTrain=0.710267\tTest=0.810938\n",
      "#Iter= 95\tTrain=0.71018\tTest=0.810885\n",
      "#Iter= 96\tTrain=0.709821\tTest=0.810878\n",
      "#Iter= 97\tTrain=0.710097\tTest=0.810859\n",
      "#Iter= 98\tTrain=0.710001\tTest=0.810876\n",
      "#Iter= 99\tTrain=0.710031\tTest=0.810808\n",
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=8086490\tnum_features=117843\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=60952\tnum_features=117848\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.890209\tTest=0.940033\n",
      "#Iter=  1\tTrain=0.800588\tTest=0.889331\n",
      "#Iter=  2\tTrain=0.783927\tTest=0.873686\n",
      "#Iter=  3\tTrain=0.769235\tTest=0.865875\n",
      "#Iter=  4\tTrain=0.759988\tTest=0.859156\n",
      "#Iter=  5\tTrain=0.754087\tTest=0.854297\n",
      "#Iter=  6\tTrain=0.748968\tTest=0.850454\n",
      "#Iter=  7\tTrain=0.745354\tTest=0.84727\n",
      "#Iter=  8\tTrain=0.742148\tTest=0.844761\n",
      "#Iter=  9\tTrain=0.739311\tTest=0.842449\n",
      "#Iter= 10\tTrain=0.737018\tTest=0.840816\n",
      "#Iter= 11\tTrain=0.735105\tTest=0.839074\n",
      "#Iter= 12\tTrain=0.732933\tTest=0.837644\n",
      "#Iter= 13\tTrain=0.731611\tTest=0.83623\n",
      "#Iter= 14\tTrain=0.730214\tTest=0.834807\n",
      "#Iter= 15\tTrain=0.729042\tTest=0.833771\n",
      "#Iter= 16\tTrain=0.728\tTest=0.832904\n",
      "#Iter= 17\tTrain=0.726881\tTest=0.831757\n",
      "#Iter= 18\tTrain=0.725876\tTest=0.830716\n",
      "#Iter= 19\tTrain=0.72493\tTest=0.829885\n",
      "#Iter= 20\tTrain=0.724106\tTest=0.829164\n",
      "#Iter= 21\tTrain=0.723096\tTest=0.828358\n",
      "#Iter= 22\tTrain=0.72265\tTest=0.827575\n",
      "#Iter= 23\tTrain=0.721973\tTest=0.826896\n",
      "#Iter= 24\tTrain=0.721386\tTest=0.826289\n",
      "#Iter= 25\tTrain=0.721082\tTest=0.82551\n",
      "#Iter= 26\tTrain=0.72023\tTest=0.824807\n",
      "#Iter= 27\tTrain=0.719624\tTest=0.824326\n",
      "#Iter= 28\tTrain=0.719214\tTest=0.823471\n",
      "#Iter= 29\tTrain=0.718616\tTest=0.8231\n",
      "#Iter= 30\tTrain=0.718542\tTest=0.822667\n",
      "#Iter= 31\tTrain=0.717767\tTest=0.822177\n",
      "#Iter= 32\tTrain=0.717312\tTest=0.821706\n",
      "#Iter= 33\tTrain=0.717102\tTest=0.821285\n",
      "#Iter= 34\tTrain=0.716894\tTest=0.820914\n",
      "#Iter= 35\tTrain=0.716486\tTest=0.820491\n",
      "#Iter= 36\tTrain=0.71634\tTest=0.820148\n",
      "#Iter= 37\tTrain=0.716178\tTest=0.819743\n",
      "#Iter= 38\tTrain=0.715699\tTest=0.819378\n",
      "#Iter= 39\tTrain=0.715545\tTest=0.818997\n",
      "#Iter= 40\tTrain=0.71534\tTest=0.818588\n",
      "#Iter= 41\tTrain=0.71506\tTest=0.818405\n",
      "#Iter= 42\tTrain=0.7149\tTest=0.818198\n",
      "#Iter= 43\tTrain=0.714708\tTest=0.818029\n",
      "#Iter= 44\tTrain=0.71431\tTest=0.817746\n",
      "#Iter= 45\tTrain=0.714023\tTest=0.817388\n",
      "#Iter= 46\tTrain=0.714004\tTest=0.817143\n",
      "#Iter= 47\tTrain=0.713537\tTest=0.81688\n",
      "#Iter= 48\tTrain=0.713396\tTest=0.816677\n",
      "#Iter= 49\tTrain=0.713502\tTest=0.816402\n",
      "#Iter= 50\tTrain=0.713259\tTest=0.81614\n",
      "#Iter= 51\tTrain=0.713061\tTest=0.816002\n",
      "#Iter= 52\tTrain=0.712786\tTest=0.815807\n",
      "#Iter= 53\tTrain=0.712758\tTest=0.815725\n",
      "#Iter= 54\tTrain=0.712813\tTest=0.815622\n",
      "#Iter= 55\tTrain=0.712314\tTest=0.815501\n",
      "#Iter= 56\tTrain=0.712348\tTest=0.815323\n",
      "#Iter= 57\tTrain=0.712192\tTest=0.81514\n",
      "#Iter= 58\tTrain=0.712296\tTest=0.814943\n",
      "#Iter= 59\tTrain=0.711905\tTest=0.814773\n",
      "#Iter= 60\tTrain=0.712198\tTest=0.814621\n",
      "#Iter= 61\tTrain=0.712094\tTest=0.814417\n",
      "#Iter= 62\tTrain=0.711993\tTest=0.814235\n",
      "#Iter= 63\tTrain=0.711855\tTest=0.814166\n",
      "#Iter= 64\tTrain=0.711824\tTest=0.814008\n",
      "#Iter= 65\tTrain=0.711759\tTest=0.813885\n",
      "#Iter= 66\tTrain=0.711509\tTest=0.813688\n",
      "#Iter= 67\tTrain=0.711544\tTest=0.81354\n",
      "#Iter= 68\tTrain=0.71155\tTest=0.81342\n",
      "#Iter= 69\tTrain=0.711222\tTest=0.813356\n",
      "#Iter= 70\tTrain=0.711473\tTest=0.813175\n",
      "#Iter= 71\tTrain=0.711154\tTest=0.81297\n",
      "#Iter= 72\tTrain=0.710976\tTest=0.81278\n",
      "#Iter= 73\tTrain=0.711152\tTest=0.812701\n",
      "#Iter= 74\tTrain=0.71086\tTest=0.812564\n",
      "#Iter= 75\tTrain=0.710729\tTest=0.812405\n",
      "#Iter= 76\tTrain=0.710796\tTest=0.812257\n",
      "#Iter= 77\tTrain=0.71069\tTest=0.81215\n",
      "#Iter= 78\tTrain=0.710736\tTest=0.812052\n",
      "#Iter= 79\tTrain=0.710604\tTest=0.812003\n",
      "#Iter= 80\tTrain=0.7106\tTest=0.811944\n",
      "#Iter= 81\tTrain=0.710628\tTest=0.811835\n",
      "#Iter= 82\tTrain=0.710557\tTest=0.811687\n",
      "#Iter= 83\tTrain=0.710399\tTest=0.811617\n",
      "#Iter= 84\tTrain=0.71018\tTest=0.81153\n",
      "#Iter= 85\tTrain=0.710391\tTest=0.811472\n",
      "#Iter= 86\tTrain=0.710413\tTest=0.811479\n",
      "#Iter= 87\tTrain=0.710273\tTest=0.811413\n",
      "#Iter= 88\tTrain=0.710214\tTest=0.811389\n",
      "#Iter= 89\tTrain=0.710166\tTest=0.811322\n",
      "#Iter= 90\tTrain=0.710217\tTest=0.811258\n",
      "#Iter= 91\tTrain=0.710084\tTest=0.811217\n",
      "#Iter= 92\tTrain=0.710355\tTest=0.811088\n",
      "#Iter= 93\tTrain=0.710306\tTest=0.810999\n",
      "#Iter= 94\tTrain=0.710267\tTest=0.810938\n",
      "#Iter= 95\tTrain=0.71018\tTest=0.810885\n",
      "#Iter= 96\tTrain=0.709821\tTest=0.810878\n",
      "#Iter= 97\tTrain=0.710097\tTest=0.810859\n",
      "#Iter= 98\tTrain=0.710001\tTest=0.810876\n",
      "#Iter= 99\tTrain=0.710031\tTest=0.810808\n"
     ]
    }
   ],
   "source": [
    "!libFM.exe -task r -train fourth_train.txt -test fourth_test.txt -out fourth_result.txt -method mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.811\n",
      "RMSE: 0.811\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE: {:.3f}'.format(calculate_RMSE(test_results, read_results('fourth_result.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=8086490\tnum_features=117843\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=60952\tnum_features=117848\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.754642\tTest=0.913609\n",
      "#Iter=  1\tTrain=0.724434\tTest=0.913127\n",
      "#Iter=  2\tTrain=0.707572\tTest=0.913302\n",
      "#Iter=  3\tTrain=0.697956\tTest=0.913994\n",
      "#Iter=  4\tTrain=0.691714\tTest=0.915314\n",
      "#Iter=  5\tTrain=0.687271\tTest=0.916584\n",
      "#Iter=  6\tTrain=0.683934\tTest=0.91795\n",
      "#Iter=  7\tTrain=0.68135\tTest=0.919196\n",
      "#Iter=  8\tTrain=0.679281\tTest=0.920453\n",
      "#Iter=  9\tTrain=0.677589\tTest=0.921552\n",
      "#Iter= 10\tTrain=0.676184\tTest=0.92241\n",
      "#Iter= 11\tTrain=0.674993\tTest=0.923183\n",
      "#Iter= 12\tTrain=0.673983\tTest=0.923889\n",
      "#Iter= 13\tTrain=0.673121\tTest=0.924553\n",
      "#Iter= 14\tTrain=0.672378\tTest=0.925167\n",
      "#Iter= 15\tTrain=0.671732\tTest=0.925733\n",
      "#Iter= 16\tTrain=0.671165\tTest=0.926292\n",
      "#Iter= 17\tTrain=0.670664\tTest=0.926842\n",
      "#Iter= 18\tTrain=0.670217\tTest=0.927381\n",
      "#Iter= 19\tTrain=0.669814\tTest=0.927923\n",
      "#Iter= 20\tTrain=0.66945\tTest=0.928483\n",
      "#Iter= 21\tTrain=0.66912\tTest=0.929024\n",
      "#Iter= 22\tTrain=0.668817\tTest=0.929567\n",
      "#Iter= 23\tTrain=0.668539\tTest=0.930112\n",
      "#Iter= 24\tTrain=0.668282\tTest=0.930659\n",
      "#Iter= 25\tTrain=0.668043\tTest=0.931212\n",
      "#Iter= 26\tTrain=0.667823\tTest=0.931759\n",
      "#Iter= 27\tTrain=0.667616\tTest=0.932282\n",
      "#Iter= 28\tTrain=0.667424\tTest=0.93279\n",
      "#Iter= 29\tTrain=0.667245\tTest=0.933286\n",
      "#Iter= 30\tTrain=0.667077\tTest=0.933771\n",
      "#Iter= 31\tTrain=0.66692\tTest=0.934244\n",
      "#Iter= 32\tTrain=0.666772\tTest=0.934704\n",
      "#Iter= 33\tTrain=0.666632\tTest=0.935155\n",
      "#Iter= 34\tTrain=0.666499\tTest=0.935604\n",
      "#Iter= 35\tTrain=0.666374\tTest=0.936048\n",
      "#Iter= 36\tTrain=0.666256\tTest=0.936469\n",
      "#Iter= 37\tTrain=0.666144\tTest=0.936891\n",
      "#Iter= 38\tTrain=0.666038\tTest=0.937313\n",
      "#Iter= 39\tTrain=0.665937\tTest=0.937742\n",
      "#Iter= 40\tTrain=0.665841\tTest=0.938174\n",
      "#Iter= 41\tTrain=0.665748\tTest=0.93861\n",
      "#Iter= 42\tTrain=0.665658\tTest=0.93905\n",
      "#Iter= 43\tTrain=0.665573\tTest=0.939492\n",
      "#Iter= 44\tTrain=0.665492\tTest=0.939934\n",
      "#Iter= 45\tTrain=0.665414\tTest=0.940376\n",
      "#Iter= 46\tTrain=0.665339\tTest=0.940816\n",
      "#Iter= 47\tTrain=0.665267\tTest=0.941256\n",
      "#Iter= 48\tTrain=0.665198\tTest=0.941694\n",
      "#Iter= 49\tTrain=0.665132\tTest=0.94213\n",
      "#Iter= 50\tTrain=0.665068\tTest=0.942564\n",
      "#Iter= 51\tTrain=0.665007\tTest=0.942994\n",
      "#Iter= 52\tTrain=0.664947\tTest=0.943422\n",
      "#Iter= 53\tTrain=0.664889\tTest=0.943846\n",
      "#Iter= 54\tTrain=0.664834\tTest=0.944267\n",
      "#Iter= 55\tTrain=0.66478\tTest=0.944684\n",
      "#Iter= 56\tTrain=0.664727\tTest=0.945098\n",
      "#Iter= 57\tTrain=0.664676\tTest=0.945509\n",
      "#Iter= 58\tTrain=0.664626\tTest=0.945916\n",
      "#Iter= 59\tTrain=0.664578\tTest=0.94632\n",
      "#Iter= 60\tTrain=0.664531\tTest=0.94672\n",
      "#Iter= 61\tTrain=0.664486\tTest=0.947113\n",
      "#Iter= 62\tTrain=0.664442\tTest=0.947482\n",
      "#Iter= 63\tTrain=0.6644\tTest=0.94783\n",
      "#Iter= 64\tTrain=0.664358\tTest=0.948175\n",
      "#Iter= 65\tTrain=0.664318\tTest=0.948518\n",
      "#Iter= 66\tTrain=0.664279\tTest=0.948858\n",
      "#Iter= 67\tTrain=0.664242\tTest=0.949195\n",
      "#Iter= 68\tTrain=0.664205\tTest=0.949531\n",
      "#Iter= 69\tTrain=0.664169\tTest=0.949864\n",
      "#Iter= 70\tTrain=0.664134\tTest=0.950195\n",
      "#Iter= 71\tTrain=0.664101\tTest=0.950523\n",
      "#Iter= 72\tTrain=0.664068\tTest=0.950849\n",
      "#Iter= 73\tTrain=0.664036\tTest=0.951172\n",
      "#Iter= 74\tTrain=0.664006\tTest=0.951493\n",
      "#Iter= 75\tTrain=0.663975\tTest=0.951811\n",
      "#Iter= 76\tTrain=0.663946\tTest=0.952127\n",
      "#Iter= 77\tTrain=0.663918\tTest=0.952442\n",
      "#Iter= 78\tTrain=0.66389\tTest=0.952751\n",
      "#Iter= 79\tTrain=0.663863\tTest=0.953058\n",
      "#Iter= 80\tTrain=0.663837\tTest=0.953362\n",
      "#Iter= 81\tTrain=0.663811\tTest=0.953664\n",
      "#Iter= 82\tTrain=0.663786\tTest=0.953962\n",
      "#Iter= 83\tTrain=0.663762\tTest=0.954258\n",
      "#Iter= 84\tTrain=0.663738\tTest=0.954549\n",
      "#Iter= 85\tTrain=0.663714\tTest=0.954835\n",
      "#Iter= 86\tTrain=0.663692\tTest=0.955116\n",
      "#Iter= 87\tTrain=0.663669\tTest=0.955396\n",
      "#Iter= 88\tTrain=0.663647\tTest=0.955673\n",
      "#Iter= 89\tTrain=0.663625\tTest=0.955947\n",
      "#Iter= 90\tTrain=0.663604\tTest=0.956218\n",
      "#Iter= 91\tTrain=0.663583\tTest=0.956486\n",
      "#Iter= 92\tTrain=0.663563\tTest=0.956751\n",
      "#Iter= 93\tTrain=0.663543\tTest=0.957005\n",
      "#Iter= 94\tTrain=0.663524\tTest=0.95726\n",
      "#Iter= 95\tTrain=0.663505\tTest=0.957512\n",
      "#Iter= 96\tTrain=0.663487\tTest=0.957759\n",
      "#Iter= 97\tTrain=0.663469\tTest=0.958004\n",
      "#Iter= 98\tTrain=0.663451\tTest=0.958245\n",
      "#Iter= 99\tTrain=0.663434\tTest=0.958483\n",
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=8086490\tnum_features=117843\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=60952\tnum_features=117848\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.754642\tTest=0.913609\n",
      "#Iter=  1\tTrain=0.724434\tTest=0.913127\n",
      "#Iter=  2\tTrain=0.707572\tTest=0.913302\n",
      "#Iter=  3\tTrain=0.697956\tTest=0.913994\n",
      "#Iter=  4\tTrain=0.691714\tTest=0.915314\n",
      "#Iter=  5\tTrain=0.687271\tTest=0.916584\n",
      "#Iter=  6\tTrain=0.683934\tTest=0.91795\n",
      "#Iter=  7\tTrain=0.68135\tTest=0.919196\n",
      "#Iter=  8\tTrain=0.679281\tTest=0.920453\n",
      "#Iter=  9\tTrain=0.677589\tTest=0.921552\n",
      "#Iter= 10\tTrain=0.676184\tTest=0.92241\n",
      "#Iter= 11\tTrain=0.674993\tTest=0.923183\n",
      "#Iter= 12\tTrain=0.673983\tTest=0.923889\n",
      "#Iter= 13\tTrain=0.673121\tTest=0.924553\n",
      "#Iter= 14\tTrain=0.672378\tTest=0.925167\n",
      "#Iter= 15\tTrain=0.671732\tTest=0.925733\n",
      "#Iter= 16\tTrain=0.671165\tTest=0.926292\n",
      "#Iter= 17\tTrain=0.670664\tTest=0.926842\n",
      "#Iter= 18\tTrain=0.670217\tTest=0.927381\n",
      "#Iter= 19\tTrain=0.669814\tTest=0.927923\n",
      "#Iter= 20\tTrain=0.66945\tTest=0.928483\n",
      "#Iter= 21\tTrain=0.66912\tTest=0.929024\n",
      "#Iter= 22\tTrain=0.668817\tTest=0.929567\n",
      "#Iter= 23\tTrain=0.668539\tTest=0.930112\n",
      "#Iter= 24\tTrain=0.668282\tTest=0.930659\n",
      "#Iter= 25\tTrain=0.668043\tTest=0.931212\n",
      "#Iter= 26\tTrain=0.667823\tTest=0.931759\n",
      "#Iter= 27\tTrain=0.667616\tTest=0.932282\n",
      "#Iter= 28\tTrain=0.667424\tTest=0.93279\n",
      "#Iter= 29\tTrain=0.667245\tTest=0.933286\n",
      "#Iter= 30\tTrain=0.667077\tTest=0.933771\n",
      "#Iter= 31\tTrain=0.66692\tTest=0.934244\n",
      "#Iter= 32\tTrain=0.666772\tTest=0.934704\n",
      "#Iter= 33\tTrain=0.666632\tTest=0.935155\n",
      "#Iter= 34\tTrain=0.666499\tTest=0.935604\n",
      "#Iter= 35\tTrain=0.666374\tTest=0.936048\n",
      "#Iter= 36\tTrain=0.666256\tTest=0.936469\n",
      "#Iter= 37\tTrain=0.666144\tTest=0.936891\n",
      "#Iter= 38\tTrain=0.666038\tTest=0.937313\n",
      "#Iter= 39\tTrain=0.665937\tTest=0.937742\n",
      "#Iter= 40\tTrain=0.665841\tTest=0.938174\n",
      "#Iter= 41\tTrain=0.665748\tTest=0.93861\n",
      "#Iter= 42\tTrain=0.665658\tTest=0.93905\n",
      "#Iter= 43\tTrain=0.665573\tTest=0.939492\n",
      "#Iter= 44\tTrain=0.665492\tTest=0.939934\n",
      "#Iter= 45\tTrain=0.665414\tTest=0.940376\n",
      "#Iter= 46\tTrain=0.665339\tTest=0.940816\n",
      "#Iter= 47\tTrain=0.665267\tTest=0.941256\n",
      "#Iter= 48\tTrain=0.665198\tTest=0.941694\n",
      "#Iter= 49\tTrain=0.665132\tTest=0.94213\n",
      "#Iter= 50\tTrain=0.665068\tTest=0.942564\n",
      "#Iter= 51\tTrain=0.665007\tTest=0.942994\n",
      "#Iter= 52\tTrain=0.664947\tTest=0.943422\n",
      "#Iter= 53\tTrain=0.664889\tTest=0.943846\n",
      "#Iter= 54\tTrain=0.664834\tTest=0.944267\n",
      "#Iter= 55\tTrain=0.66478\tTest=0.944684\n",
      "#Iter= 56\tTrain=0.664727\tTest=0.945098\n",
      "#Iter= 57\tTrain=0.664676\tTest=0.945509\n",
      "#Iter= 58\tTrain=0.664626\tTest=0.945916\n",
      "#Iter= 59\tTrain=0.664578\tTest=0.94632\n",
      "#Iter= 60\tTrain=0.664531\tTest=0.94672\n",
      "#Iter= 61\tTrain=0.664486\tTest=0.947113\n",
      "#Iter= 62\tTrain=0.664442\tTest=0.947482\n",
      "#Iter= 63\tTrain=0.6644\tTest=0.94783\n",
      "#Iter= 64\tTrain=0.664358\tTest=0.948175\n",
      "#Iter= 65\tTrain=0.664318\tTest=0.948518\n",
      "#Iter= 66\tTrain=0.664279\tTest=0.948858\n",
      "#Iter= 67\tTrain=0.664242\tTest=0.949195\n",
      "#Iter= 68\tTrain=0.664205\tTest=0.949531\n",
      "#Iter= 69\tTrain=0.664169\tTest=0.949864\n",
      "#Iter= 70\tTrain=0.664134\tTest=0.950195\n",
      "#Iter= 71\tTrain=0.664101\tTest=0.950523\n",
      "#Iter= 72\tTrain=0.664068\tTest=0.950849\n",
      "#Iter= 73\tTrain=0.664036\tTest=0.951172\n",
      "#Iter= 74\tTrain=0.664006\tTest=0.951493\n",
      "#Iter= 75\tTrain=0.663975\tTest=0.951811\n",
      "#Iter= 76\tTrain=0.663946\tTest=0.952127\n",
      "#Iter= 77\tTrain=0.663918\tTest=0.952442\n",
      "#Iter= 78\tTrain=0.66389\tTest=0.952751\n",
      "#Iter= 79\tTrain=0.663863\tTest=0.953058\n",
      "#Iter= 80\tTrain=0.663837\tTest=0.953362\n",
      "#Iter= 81\tTrain=0.663811\tTest=0.953664\n",
      "#Iter= 82\tTrain=0.663786\tTest=0.953962\n",
      "#Iter= 83\tTrain=0.663762\tTest=0.954258\n",
      "#Iter= 84\tTrain=0.663738\tTest=0.954549\n",
      "#Iter= 85\tTrain=0.663714\tTest=0.954835\n",
      "#Iter= 86\tTrain=0.663692\tTest=0.955116\n",
      "#Iter= 87\tTrain=0.663669\tTest=0.955396\n",
      "#Iter= 88\tTrain=0.663647\tTest=0.955673\n",
      "#Iter= 89\tTrain=0.663625\tTest=0.955947\n",
      "#Iter= 90\tTrain=0.663604\tTest=0.956218\n",
      "#Iter= 91\tTrain=0.663583\tTest=0.956486\n",
      "#Iter= 92\tTrain=0.663563\tTest=0.956751\n",
      "#Iter= 93\tTrain=0.663543\tTest=0.957005\n",
      "#Iter= 94\tTrain=0.663524\tTest=0.95726\n",
      "#Iter= 95\tTrain=0.663505\tTest=0.957512\n",
      "#Iter= 96\tTrain=0.663487\tTest=0.957759\n",
      "#Iter= 97\tTrain=0.663469\tTest=0.958004\n",
      "#Iter= 98\tTrain=0.663451\tTest=0.958245\n",
      "#Iter= 99\tTrain=0.663434\tTest=0.958483\n"
     ]
    }
   ],
   "source": [
    "!libFM.exe -task r -train fourth_train.txt -test fourth_test.txt -out fourth_result.txt -method als"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Актеры не оказали особого влияния на качество работы алгоритма. Может, мы взяли мало топовых актеров. Но формирование выборки и тренировка и занимают много времени. Так что остановимся на этом:\n",
    "<li>для метода MCMC RMSE = 0.811\n",
    "<li>для метода ALS RMSE = 0.958"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### id-пользователя + id-фильма + год + страна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_df = pd.DataFrame.from_csv('data/movie_countries.dat', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "country_id = {}\n",
    "for country in country_df['country'].unique():\n",
    "    country_id[country] = len(country_id) + start_index\n",
    "start_index += len(country_id)\n",
    "\n",
    "year_id = start_index\n",
    "start_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_my_sample(df, file_name):\n",
    "    results = []\n",
    "    lines = []\n",
    "    with open(file_name, 'w') as fsampl:\n",
    "        for user, data in df.items():\n",
    "            for row in data.iterrows():\n",
    "                movie = int(row[1]['movieID'])\n",
    "                country = country_id[country_df.loc[movie]['country']]\n",
    "                year = movies_df.iloc[movies_id[movie]]['year']\n",
    "                example = '{0} {1}:1.0 {2}:1.0 {3}:{4} {5}:1.0'.format(row[1]['rating'], users_id[user], \n",
    "                                                                   movies_id[movie], year_id, year, country)\n",
    "                lines.append(example)\n",
    "                results.append(row[1]['rating'])\n",
    "        fsampl.write('\\n'.join(lines))\n",
    "        return results\n",
    "    \n",
    "get_my_sample(train_df, 'my_train.txt')\n",
    "test_results = get_my_sample(test_df, 'my_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=3397036\tnum_features=117921\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=25356\tnum_features=117921\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=2.30111\tTest=2.38927\n",
      "#Iter=  1\tTrain=1.22182\tTest=1.54964\n",
      "#Iter=  2\tTrain=0.813961\tTest=1.2177\n",
      "#Iter=  3\tTrain=0.800445\tTest=1.07492\n",
      "#Iter=  4\tTrain=0.800264\tTest=1.00136\n",
      "#Iter=  5\tTrain=0.800202\tTest=0.960803\n",
      "#Iter=  6\tTrain=0.800341\tTest=0.93628\n",
      "#Iter=  7\tTrain=0.800257\tTest=0.9196\n",
      "#Iter=  8\tTrain=0.800242\tTest=0.9085\n",
      "#Iter=  9\tTrain=0.800234\tTest=0.900307\n",
      "#Iter= 10\tTrain=0.800372\tTest=0.894032\n",
      "#Iter= 11\tTrain=0.80036\tTest=0.889463\n",
      "#Iter= 12\tTrain=0.800371\tTest=0.885477\n",
      "#Iter= 13\tTrain=0.80012\tTest=0.882635\n",
      "#Iter= 14\tTrain=0.800274\tTest=0.880351\n",
      "#Iter= 15\tTrain=0.800386\tTest=0.878605\n",
      "#Iter= 16\tTrain=0.8002\tTest=0.877135\n",
      "#Iter= 17\tTrain=0.800264\tTest=0.875573\n",
      "#Iter= 18\tTrain=0.800206\tTest=0.874323\n",
      "#Iter= 19\tTrain=0.800203\tTest=0.873625\n",
      "#Iter= 20\tTrain=0.8002\tTest=0.872845\n",
      "#Iter= 21\tTrain=0.800164\tTest=0.872283\n",
      "#Iter= 22\tTrain=0.800211\tTest=0.871817\n",
      "#Iter= 23\tTrain=0.800263\tTest=0.871058\n",
      "#Iter= 24\tTrain=0.80028\tTest=0.870757\n",
      "#Iter= 25\tTrain=0.80035\tTest=0.870314\n",
      "#Iter= 26\tTrain=0.800197\tTest=0.870061\n",
      "#Iter= 27\tTrain=0.800193\tTest=0.869931\n",
      "#Iter= 28\tTrain=0.800314\tTest=0.869808\n",
      "#Iter= 29\tTrain=0.800206\tTest=0.869593\n",
      "#Iter= 30\tTrain=0.800285\tTest=0.869385\n",
      "#Iter= 31\tTrain=0.800199\tTest=0.86921\n",
      "#Iter= 32\tTrain=0.800286\tTest=0.869087\n",
      "#Iter= 33\tTrain=0.800144\tTest=0.868937\n",
      "#Iter= 34\tTrain=0.80016\tTest=0.8686\n",
      "#Iter= 35\tTrain=0.800163\tTest=0.868537\n",
      "#Iter= 36\tTrain=0.800258\tTest=0.86844\n",
      "#Iter= 37\tTrain=0.80035\tTest=0.868296\n",
      "#Iter= 38\tTrain=0.800236\tTest=0.868264\n",
      "#Iter= 39\tTrain=0.800348\tTest=0.868123\n",
      "#Iter= 40\tTrain=0.800181\tTest=0.868109\n",
      "#Iter= 41\tTrain=0.800252\tTest=0.868036\n",
      "#Iter= 42\tTrain=0.800206\tTest=0.867919\n",
      "#Iter= 43\tTrain=0.800108\tTest=0.867799\n",
      "#Iter= 44\tTrain=0.800286\tTest=0.867749\n",
      "#Iter= 45\tTrain=0.800139\tTest=0.867616\n",
      "#Iter= 46\tTrain=0.800094\tTest=0.867584\n",
      "#Iter= 47\tTrain=0.80021\tTest=0.867605\n",
      "#Iter= 48\tTrain=0.800104\tTest=0.867533\n",
      "#Iter= 49\tTrain=0.800305\tTest=0.86754\n",
      "#Iter= 50\tTrain=0.800198\tTest=0.867479\n",
      "#Iter= 51\tTrain=0.800184\tTest=0.867446\n",
      "#Iter= 52\tTrain=0.800293\tTest=0.867397\n",
      "#Iter= 53\tTrain=0.800177\tTest=0.867464\n",
      "#Iter= 54\tTrain=0.800308\tTest=0.867526\n",
      "#Iter= 55\tTrain=0.80018\tTest=0.867508\n",
      "#Iter= 56\tTrain=0.800092\tTest=0.867462\n",
      "#Iter= 57\tTrain=0.800259\tTest=0.867403\n",
      "#Iter= 58\tTrain=0.800239\tTest=0.867479\n",
      "#Iter= 59\tTrain=0.800315\tTest=0.867525\n",
      "#Iter= 60\tTrain=0.800268\tTest=0.867532\n",
      "#Iter= 61\tTrain=0.800181\tTest=0.867539\n",
      "#Iter= 62\tTrain=0.800227\tTest=0.867544\n",
      "#Iter= 63\tTrain=0.800306\tTest=0.867579\n",
      "#Iter= 64\tTrain=0.800306\tTest=0.867598\n",
      "#Iter= 65\tTrain=0.800262\tTest=0.8676\n",
      "#Iter= 66\tTrain=0.800191\tTest=0.867506\n",
      "#Iter= 67\tTrain=0.800239\tTest=0.867468\n",
      "#Iter= 68\tTrain=0.800149\tTest=0.867563\n",
      "#Iter= 69\tTrain=0.800066\tTest=0.8675\n",
      "#Iter= 70\tTrain=0.800326\tTest=0.867433\n",
      "#Iter= 71\tTrain=0.800253\tTest=0.867406\n",
      "#Iter= 72\tTrain=0.800161\tTest=0.86742\n",
      "#Iter= 73\tTrain=0.800347\tTest=0.867486\n",
      "#Iter= 74\tTrain=0.800161\tTest=0.867556\n",
      "#Iter= 75\tTrain=0.800036\tTest=0.867562\n",
      "#Iter= 76\tTrain=0.800171\tTest=0.8676\n",
      "#Iter= 77\tTrain=0.800099\tTest=0.86761\n",
      "#Iter= 78\tTrain=0.800106\tTest=0.867577\n",
      "#Iter= 79\tTrain=0.800084\tTest=0.867587\n",
      "#Iter= 80\tTrain=0.800274\tTest=0.867607\n",
      "#Iter= 81\tTrain=0.80016\tTest=0.867586\n",
      "#Iter= 82\tTrain=0.800112\tTest=0.867567\n",
      "#Iter= 83\tTrain=0.800208\tTest=0.867571\n",
      "#Iter= 84\tTrain=0.800183\tTest=0.867531\n",
      "#Iter= 85\tTrain=0.800197\tTest=0.867538\n",
      "#Iter= 86\tTrain=0.800329\tTest=0.867528\n",
      "#Iter= 87\tTrain=0.800144\tTest=0.867531\n",
      "#Iter= 88\tTrain=0.800249\tTest=0.867551\n",
      "#Iter= 89\tTrain=0.800235\tTest=0.867542\n",
      "#Iter= 90\tTrain=0.800102\tTest=0.867527\n",
      "#Iter= 91\tTrain=0.800235\tTest=0.867532\n",
      "#Iter= 92\tTrain=0.800243\tTest=0.867512\n",
      "#Iter= 93\tTrain=0.800249\tTest=0.867534\n",
      "#Iter= 94\tTrain=0.800061\tTest=0.867508\n",
      "#Iter= 95\tTrain=0.80022\tTest=0.8675\n",
      "#Iter= 96\tTrain=0.800155\tTest=0.867471\n",
      "#Iter= 97\tTrain=0.800255\tTest=0.867475\n",
      "#Iter= 98\tTrain=0.800214\tTest=0.867482\n",
      "#Iter= 99\tTrain=0.800207\tTest=0.867447\n"
     ]
    }
   ],
   "source": [
    "!libFM.exe -task r -train my_train.txt -test my_test.txt -out my_result.txt -method mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.867\n"
     ]
    }
   ],
   "source": [
    "print 'RMSE: {:.3f}'.format(calculate_RMSE(test_results, read_results('my_result.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "libFM\n",
      "  Version: 1.40\n",
      "  Author:  Steffen Rendle, steffen.rendle@uni-konstanz.de\n",
      "  WWW:     http://www.libfm.org/\n",
      "  License: Free for academic use. See license.txt.\n",
      "----------------------------------------------------------------------------\n",
      "Loading train...\t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=849259\tnum_values=3397036\tnum_features=117921\tmin_target=0.5\tmax_target=5\n",
      "Loading test... \t\n",
      "has x = 0\n",
      "has xt = 1\n",
      "num_rows=6339\tnum_values=25356\tnum_features=117921\tmin_target=0.5\tmax_target=5\n",
      "#relations: 0\n",
      "Loading meta data...\t\n",
      "#Iter=  0\tTrain=0.974735\tTest=1.07504\n",
      "#Iter=  1\tTrain=0.97472\tTest=1.07503\n",
      "#Iter=  2\tTrain=0.974704\tTest=1.07502\n",
      "#Iter=  3\tTrain=0.974689\tTest=1.07501\n",
      "#Iter=  4\tTrain=0.974674\tTest=1.07501\n",
      "#Iter=  5\tTrain=0.974659\tTest=1.075\n",
      "#Iter=  6\tTrain=0.974643\tTest=1.07499\n",
      "#Iter=  7\tTrain=0.974628\tTest=1.07498\n",
      "#Iter=  8\tTrain=0.974613\tTest=1.07498\n",
      "#Iter=  9\tTrain=0.974598\tTest=1.07497\n",
      "#Iter= 10\tTrain=0.974583\tTest=1.07496\n",
      "#Iter= 11\tTrain=0.974567\tTest=1.07495\n",
      "#Iter= 12\tTrain=0.974552\tTest=1.07495\n",
      "#Iter= 13\tTrain=0.974537\tTest=1.07494\n",
      "#Iter= 14\tTrain=0.974522\tTest=1.07493\n",
      "#Iter= 15\tTrain=0.974506\tTest=1.07492\n",
      "#Iter= 16\tTrain=0.974491\tTest=1.07492\n",
      "#Iter= 17\tTrain=0.974476\tTest=1.07491\n",
      "#Iter= 18\tTrain=0.974461\tTest=1.0749\n",
      "#Iter= 19\tTrain=0.974446\tTest=1.07489\n",
      "#Iter= 20\tTrain=0.97443\tTest=1.07489\n",
      "#Iter= 21\tTrain=0.974415\tTest=1.07488\n",
      "#Iter= 22\tTrain=0.9744\tTest=1.07487\n",
      "#Iter= 23\tTrain=0.974385\tTest=1.07486\n",
      "#Iter= 24\tTrain=0.97437\tTest=1.07486\n",
      "#Iter= 25\tTrain=0.974354\tTest=1.07485\n",
      "#Iter= 26\tTrain=0.974339\tTest=1.07484\n",
      "#Iter= 27\tTrain=0.974324\tTest=1.07483\n",
      "#Iter= 28\tTrain=0.974309\tTest=1.07483\n",
      "#Iter= 29\tTrain=0.974293\tTest=1.07482\n",
      "#Iter= 30\tTrain=0.974278\tTest=1.07481\n",
      "#Iter= 31\tTrain=0.974263\tTest=1.0748\n",
      "#Iter= 32\tTrain=0.974248\tTest=1.0748\n",
      "#Iter= 33\tTrain=0.974233\tTest=1.07479\n",
      "#Iter= 34\tTrain=0.974217\tTest=1.07478\n",
      "#Iter= 35\tTrain=0.974202\tTest=1.07477\n",
      "#Iter= 36\tTrain=0.974187\tTest=1.07477\n",
      "#Iter= 37\tTrain=0.974172\tTest=1.07476\n",
      "#Iter= 38\tTrain=0.974157\tTest=1.07475\n",
      "#Iter= 39\tTrain=0.974141\tTest=1.07474\n",
      "#Iter= 40\tTrain=0.974126\tTest=1.07474\n",
      "#Iter= 41\tTrain=0.974111\tTest=1.07473\n",
      "#Iter= 42\tTrain=0.974096\tTest=1.07472\n",
      "#Iter= 43\tTrain=0.974081\tTest=1.07471\n",
      "#Iter= 44\tTrain=0.974065\tTest=1.07471\n",
      "#Iter= 45\tTrain=0.97405\tTest=1.0747\n",
      "#Iter= 46\tTrain=0.974035\tTest=1.07469\n",
      "#Iter= 47\tTrain=0.97402\tTest=1.07468\n",
      "#Iter= 48\tTrain=0.974005\tTest=1.07468\n",
      "#Iter= 49\tTrain=0.97399\tTest=1.07467\n",
      "#Iter= 50\tTrain=0.973974\tTest=1.07466\n",
      "#Iter= 51\tTrain=0.973959\tTest=1.07465\n",
      "#Iter= 52\tTrain=0.973944\tTest=1.07465\n",
      "#Iter= 53\tTrain=0.973929\tTest=1.07464\n",
      "#Iter= 54\tTrain=0.973914\tTest=1.07463\n",
      "#Iter= 55\tTrain=0.973898\tTest=1.07462\n",
      "#Iter= 56\tTrain=0.973883\tTest=1.07462\n",
      "#Iter= 57\tTrain=0.973868\tTest=1.07461\n",
      "#Iter= 58\tTrain=0.973853\tTest=1.0746\n",
      "#Iter= 59\tTrain=0.973838\tTest=1.07459\n",
      "#Iter= 60\tTrain=0.973823\tTest=1.07459\n",
      "#Iter= 61\tTrain=0.973807\tTest=1.07458\n",
      "#Iter= 62\tTrain=0.973792\tTest=1.07457\n",
      "#Iter= 63\tTrain=0.973777\tTest=1.07456\n",
      "#Iter= 64\tTrain=0.973762\tTest=1.07456\n",
      "#Iter= 65\tTrain=0.973747\tTest=1.07455\n",
      "#Iter= 66\tTrain=0.973732\tTest=1.07454\n",
      "#Iter= 67\tTrain=0.973716\tTest=1.07453\n",
      "#Iter= 68\tTrain=0.973701\tTest=1.07453\n",
      "#Iter= 69\tTrain=0.973686\tTest=1.07452\n",
      "#Iter= 70\tTrain=0.973671\tTest=1.07451\n",
      "#Iter= 71\tTrain=0.973656\tTest=1.0745\n",
      "#Iter= 72\tTrain=0.973641\tTest=1.0745\n",
      "#Iter= 73\tTrain=0.973626\tTest=1.07449\n",
      "#Iter= 74\tTrain=0.97361\tTest=1.07448\n",
      "#Iter= 75\tTrain=0.973595\tTest=1.07447\n",
      "#Iter= 76\tTrain=0.97358\tTest=1.07447\n",
      "#Iter= 77\tTrain=0.973565\tTest=1.07446\n",
      "#Iter= 78\tTrain=0.97355\tTest=1.07445\n",
      "#Iter= 79\tTrain=0.973535\tTest=1.07444\n",
      "#Iter= 80\tTrain=0.973519\tTest=1.07444\n",
      "#Iter= 81\tTrain=0.973504\tTest=1.07443\n",
      "#Iter= 82\tTrain=0.973489\tTest=1.07442\n",
      "#Iter= 83\tTrain=0.973474\tTest=1.07442\n",
      "#Iter= 84\tTrain=0.973459\tTest=1.07441\n",
      "#Iter= 85\tTrain=0.973444\tTest=1.0744\n",
      "#Iter= 86\tTrain=0.973429\tTest=1.07439\n",
      "#Iter= 87\tTrain=0.973413\tTest=1.07439\n",
      "#Iter= 88\tTrain=0.973398\tTest=1.07438\n",
      "#Iter= 89\tTrain=0.973383\tTest=1.07437\n",
      "#Iter= 90\tTrain=0.973368\tTest=1.07436\n",
      "#Iter= 91\tTrain=0.973353\tTest=1.07436\n",
      "#Iter= 92\tTrain=0.973338\tTest=1.07435\n",
      "#Iter= 93\tTrain=0.973323\tTest=1.07434\n",
      "#Iter= 94\tTrain=0.973307\tTest=1.07433\n",
      "#Iter= 95\tTrain=0.973292\tTest=1.07433\n",
      "#Iter= 96\tTrain=0.973277\tTest=1.07432\n",
      "#Iter= 97\tTrain=0.973262\tTest=1.07431\n",
      "#Iter= 98\tTrain=0.973247\tTest=1.0743\n",
      "#Iter= 99\tTrain=0.973232\tTest=1.0743\n"
     ]
    }
   ],
   "source": [
    "!libFM.exe -task r -train my_train.txt -test my_test.txt -out my_result.txt -method als"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: год и страна фильма не помогли повысить точность.\n",
    "<li>для метода MCMC RMSE = 0.867\n",
    "<li>для метода ALS RMSE = 1.0743"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: LIbFM работает быстрее, чем Vowal Wabbit, и позволяет добиться лучшего качества. Наиболее эффективная выборка состоит из id пользователей и фильмов и жанров. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
