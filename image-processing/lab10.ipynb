{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cats vs. Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "import cPickle as pickle\n",
    "from time import time\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "import random\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Классификация с использованием гистограмм визуальных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70652173913\n"
     ]
    }
   ],
   "source": [
    "#calclulate descriptors of the images generated by image_generator\n",
    "def get_descriptors(image_generator, images):\n",
    "    descriptors = []\n",
    "    sift = cv2.SIFT(nfeatures=100)\n",
    "    for image, cls in image_generator(images):\n",
    "        keys, desc = sift.detectAndCompute(image, None)\n",
    "        for d, k in zip(desc, keys):\n",
    "            descriptors.append(d)\n",
    "    return descriptors\n",
    "\n",
    "def read_results_set(filename):\n",
    "    y_set = {}\n",
    "    with open(filename, 'r') as fin:\n",
    "        for line in fin.readlines():\n",
    "            image_name, cls = tuple(line.split(','))\n",
    "            y_set[image_name] = cls\n",
    "    return y_set\n",
    "\n",
    "#generator of train images for the first task\n",
    "def train_image_generator(image_names):\n",
    "    train_dir = \"train_images\\\\train_images\"\n",
    "    y_set = read_results_set('train_final.csv')\n",
    "    for image_name in image_names:\n",
    "        image = cv2.imread(train_dir+\"\\\\\"+ image_name)\n",
    "        cls = y_set[image_name.split('.')[0]]\n",
    "        yield cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), cls\n",
    "\n",
    "#construct the visual dictionary\n",
    "def get_visual_dictionary(clusters_number, image_generator, images):\n",
    "    descriptors = get_descriptors(image_generator, images)\n",
    "    cls = KMeans(n_clusters=clusters_number)\n",
    "    cls.fit(descriptors)\n",
    "    return cls\n",
    "\n",
    "train_images_names = os.listdir(\"train_images\\\\train_images\")\n",
    "validate_images_names = train_images_names[int(len(train_images_names)*0.9):]\n",
    "train_image_names = train_images_names[:int(len(train_images_names)*0.9)]\n",
    "\n",
    "visual_dict_size = 50\n",
    "visual_dict = get_visual_dictionary(visual_dict_size, train_image_generator, train_images_names)\n",
    "pickle.dump(visual_dict, open('visual_dict.pkl', 'wb'))\n",
    "visual_dict = pickle.load(open('visual_dict.pkl', 'rb'))\n",
    "\n",
    "#generator of the train images for the second task\n",
    "def test_image_generator():\n",
    "    train_dir = \"test_images\\\\test_images\"\n",
    "    for image_name in os.listdir(train_dir):\n",
    "        image = cv2.imread(train_dir+\"\\\\\"+ image_name)\n",
    "        yield cv2.cvtColor(image, cv2.COLOR_BGR2GRAY), image_name\n",
    "\n",
    "#calculate histogram Bag-of-Words\n",
    "def get_Bag_of_Words(image, visual_dict, features):\n",
    "    hist_size = visual_dict.get_params()['n_clusters']\n",
    "    hist = np.zeros(hist_size)\n",
    "    sift = cv2.SIFT(nfeatures=features)\n",
    "    keys, desc = sift.detectAndCompute(image, None)\n",
    "    for d in desc:\n",
    "        y = visual_dict.predict(d)\n",
    "        hist[y-1] = hist[y-1] + 1\n",
    "    max_val = max(hist)\n",
    "    return [val / max_val for val in hist]\n",
    "\n",
    "def get_data_set(image_generator, images, visual_dict):\n",
    "    X = []\n",
    "    y =[]\n",
    "    for image, cls in image_generator(images):\n",
    "        X.append(get_Bag_of_Words(image, visual_dict, 100))\n",
    "        y.append(cls)\n",
    "    return X, y\n",
    "\n",
    "def get_result_file(X_train, y_train, visual_dict, image_generator):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    with open(\"result.csv\", 'w') as fout:\n",
    "        fout.write('Id,Prediction\\n')\n",
    "        for image, name in image_generator():\n",
    "            y = clf.predict(get_Bag_of_Words(image, visual_dict, 100))\n",
    "            fout.write(name.split('.')[0] +','+str(y[0]))\n",
    "            \n",
    "#solve the second task: train SVM classifier and measure its accuracy\n",
    "def solve(visual_dict):\n",
    "    X_train, y_train = get_data_set(train_image_generator, train_image_names, visual_dict)\n",
    "    X_validate, y_validate = get_data_set(train_image_generator, validate_images_names, visual_dict)\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_validate, y_validate)\n",
    "    print \"Accuracy: {}\".format(accuracy)\n",
    "    return clf\n",
    "    \n",
    "clf = solve(visual_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_data_set(train_image_generator, train_image_names, visual_dict)\n",
    "X_validate, y_validate = get_data_set(train_image_generator, validate_images_names, visual_dict)\n",
    "\n",
    "X_train = X_train + X_validate\n",
    "y_train = y_train + y_validate\n",
    "get_result_file(X_train, y_train, visual_dict, test_image_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат сабмита:0.54356"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Дескрипторы fc7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.810\n"
     ]
    }
   ],
   "source": [
    "#generator of train images for the first task\n",
    "def get_train_data(image_names):\n",
    "    train_dir = \"train_fc7\\\\train_fc7\"\n",
    "    y_set = read_results_set('train_final.csv')\n",
    "    X = []\n",
    "    y = []\n",
    "    for image_name in image_names:\n",
    "        desc_name = image_name.split('.')[0] +'.desc'\n",
    "        X.append(np.loadtxt(train_dir+\"\\\\\"+ desc_name))\n",
    "        y.append(y_set[image_name.split('.')[0]])\n",
    "    return X, y\n",
    "\n",
    "#generator of train images for the first task\n",
    "def test_data_generator():\n",
    "    train_dir = \"test_fc7\\\\test_fc7\"\n",
    "    for image_name in os.listdir(train_dir):\n",
    "        desc_name = image_name.split('.')[0] +'.desc'\n",
    "        desc = np.loadtxt(train_dir+\"\\\\\"+ desc_name)\n",
    "        yield desc, image_name     \n",
    "\n",
    "def get_result_file(X_train, y_train, image_generator):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    with open(\"fc7_result.csv\", 'w') as fout:\n",
    "        fout.write('Id,Prediction\\n')\n",
    "        for desc, name in image_generator():\n",
    "            y = clf.predict(desc)\n",
    "            fout.write(name.split('.')[0] +','+str(y[0]))\n",
    "            \n",
    "#solve the second task: train SVM classifier and measure its accuracy\n",
    "def solve():\n",
    "    X_train, y_train = get_train_data(train_image_names)\n",
    "    X_validate, y_validate = get_train_data(validate_images_names)\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_validate, y_validate)\n",
    "    print \"Accuracy: {0:0.3f}\".format(accuracy)\n",
    "    return clf\n",
    "    \n",
    "clf = solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_train_data(train_image_names)\n",
    "X_validate, y_validate = get_train_data(validate_images_names)\n",
    "X_train = X_train + X_validate\n",
    "y_train = y_train + y_validate\n",
    "get_result_file(X_train, y_train, test_data_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат сабмита: 0.6241"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_train_data(train_image_names)\n",
    "X_validate, y_validate = get_train_data(validate_images_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training..\n",
      "Classifying..\n",
      "Accuracy: 0.821\n"
     ]
    }
   ],
   "source": [
    "pca = PCA()\n",
    "train_pca = [desc[:1500] for desc in pca.fit_transform(X_train)]\n",
    "test_pca = [desc[:1500] for desc in pca.transform(X_validate)]\n",
    "clf = svm.SVC()\n",
    "print 'Training..'\n",
    "clf.fit(train_pca, y_train)\n",
    "print 'Classifying..'\n",
    "accuracy = clf.score(test_pca, y_validate)\n",
    "print \"Accuracy: {0:0.3f}\".format(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training..\n",
      "Classifying..\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train + X_validate\n",
    "y_train = y_train + y_validate\n",
    "def get_result_file(X_train, y_train, image_generator):\n",
    "    pca = PCA()\n",
    "    train_pca = [desc[:1500] for desc in pca.fit_transform(X_train)]\n",
    "    clf = svm.SVC()\n",
    "    print 'Training..'\n",
    "    clf.fit(train_pca, y_train)\n",
    "    print 'Classifying..'\n",
    "    with open(\"fc7_result.csv\", 'w') as fout:\n",
    "        fout.write('Id,Prediction\\n')\n",
    "        for desc, name in image_generator():\n",
    "            desc = pca.transform(desc)[0][:1500]\n",
    "            y = clf.predict(desc)\n",
    "            fout.write(name.split('.')[0] +','+str(y[0]))\n",
    "get_result_file(X_train, y_train, test_data_generator)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат сабмита: 0.76407"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
